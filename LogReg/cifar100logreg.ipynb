{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar100logreg.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d5ccfe86273c468287f1bf5ef2e6b0d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_546371c68dd04e958a2fe81b95ec797c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d3f7e25e136349e984be022d6920a417",
              "IPY_MODEL_ffb7bf1df04b4b3e82b29665cf257808"
            ]
          }
        },
        "546371c68dd04e958a2fe81b95ec797c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d3f7e25e136349e984be022d6920a417": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_534774e4c3734ba9bb1883c311ef4198",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c64e3ea00a34de7a9cdb9b5ee67c3e9"
          }
        },
        "ffb7bf1df04b4b3e82b29665cf257808": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_df2b61ccfbc34dca81973e329277ebfe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169009152/? [00:05&lt;00:00, 29078715.98it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0f9b4c8ca434ff98ed137494f5bb8c3"
          }
        },
        "534774e4c3734ba9bb1883c311ef4198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c64e3ea00a34de7a9cdb9b5ee67c3e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df2b61ccfbc34dca81973e329277ebfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0f9b4c8ca434ff98ed137494f5bb8c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM7PkFudMW9T"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "from torchvision.datasets import CIFAR100\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from torch.utils.data import TensorDataset\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPeiWwA5NYqK"
      },
      "source": [
        "class LogisticRegression(torch.nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = self.linear(x)\n",
        "        return outputs"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "d5ccfe86273c468287f1bf5ef2e6b0d6",
            "546371c68dd04e958a2fe81b95ec797c",
            "d3f7e25e136349e984be022d6920a417",
            "ffb7bf1df04b4b3e82b29665cf257808",
            "534774e4c3734ba9bb1883c311ef4198",
            "2c64e3ea00a34de7a9cdb9b5ee67c3e9",
            "df2b61ccfbc34dca81973e329277ebfe",
            "d0f9b4c8ca434ff98ed137494f5bb8c3"
          ]
        },
        "id": "Hc7J8t-FNP5i",
        "outputId": "50c7d02a-7e25-4a26-b97d-e6e9e2bc1541"
      },
      "source": [
        "train_dataset = CIFAR100(root='./data', train=True, transform=transforms.Compose([\n",
        "                                      transforms.Resize(32),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                                    ]), download=True)\n",
        "test_dataset = CIFAR100(root='./data', train=False, transform=transforms.Compose([\n",
        "                                      transforms.Resize(32),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                                    ]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5ccfe86273c468287f1bf5ef2e6b0d6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1JttydXtGRb"
      },
      "source": [
        "batch_size = 64\n",
        "n_iters = 1000000\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_ZjA1lmtKeX"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=len(train_dataset), \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=len(test_dataset), \n",
        "                                          shuffle=False)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjmNhlVTOXV1"
      },
      "source": [
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model.to(device)\n",
        "# input_dim = 3*32*32\n",
        "# output_dim = 100\n",
        "\n",
        "# model = LogisticRegression(input_dim, output_dim)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YoKrj_H0l4G",
        "outputId": "9aa62f5d-b5b4-47c3-da88-4c18a1c3cec6"
      },
      "source": [
        "for images, labels in train_loader:  \n",
        "    print('Image batch dimensions:', images.shape)\n",
        "    print('Image label dimensions:', labels.shape)\n",
        "    break\n",
        "\n",
        "X_train = np.array(images.reshape(50000, 3*32*32))\n",
        "y_labels = np.array(labels)\n",
        "\n",
        "for images, labels in test_loader:  \n",
        "    print('Image batch dimensions:', images.shape)\n",
        "    print('Image label dimensions:', labels.shape)\n",
        "    break\n",
        "\n",
        "X_test = np.array(images.reshape(10000,3*32*32))\n",
        "y_test_labs = np.array(labels)\n",
        "\n",
        "\n",
        "ncomps = 256\n",
        "\n",
        "\n",
        "pca = PCA(n_components=ncomps)  \n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "\n",
        "#TSNE\n",
        "#X_train_pca = TSNE(n_components=3).fit_transform(X_train_pca)\n",
        "\n",
        "X_train_pca = torch.from_numpy(np.float32(X_train_pca))\n",
        "X_train_pca = torch.tensor(X_train_pca)\n",
        "y_train = torch.tensor(y_labels, dtype=torch.long)\n",
        "\n",
        "\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "#TSNE\n",
        "#X_test_pca = TSNE(n_components=3).fit_transform(X_test_pca)\n",
        "\n",
        "\n",
        "X_test_pca = torch.from_numpy(np.float32(X_test_pca))\n",
        "X_test_pca = torch.tensor(X_test_pca)\n",
        "y_test = torch.tensor(y_test_labs, dtype=torch.long)\n",
        "\n",
        "\n",
        "\n",
        "train_ds = TensorDataset(X_train_pca, y_train)\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size)\n",
        "\n",
        "test_ds = TensorDataset(X_test_pca, y_test)\n",
        "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=batch_size)\n",
        "\n",
        "for images, labels in train_dl:\n",
        "  print('Image batch dimensions:', images.shape)\n",
        "  print('Image label dimensions:', labels.shape)\n",
        "  break\n",
        "\n",
        "\n",
        "for images, labels in test_dl:\n",
        "  print('Image batch dimensions:', images.shape)\n",
        "  print('Image label dimensions:', labels.shape)\n",
        "  break\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Image batch dimensions: torch.Size([50000, 3, 32, 32])\n",
            "Image label dimensions: torch.Size([50000])\n",
            "Image batch dimensions: torch.Size([10000, 3, 32, 32])\n",
            "Image label dimensions: torch.Size([10000])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image batch dimensions: torch.Size([64, 256])\n",
            "Image label dimensions: torch.Size([64])\n",
            "Image batch dimensions: torch.Size([64, 256])\n",
            "Image label dimensions: torch.Size([64])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wnh_ANAg0l6d",
        "outputId": "dfaa3a46-1b6d-4a52-b53d-b026ab349589"
      },
      "source": [
        "input_dim = ncomps\n",
        "output_dim = 100\n",
        "\n",
        "model = LogisticRegression(input_dim, output_dim)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(\n",
              "  (linear): Linear(in_features=256, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCprt8TIsuKz"
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7zjMPG4sZoU"
      },
      "source": [
        "train_dataloader = train_dl\n",
        "test_dataloader = test_dl"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgdYPm_esuNG",
        "outputId": "a267ed18-d373-42a0-b96f-81dabda9ef45"
      },
      "source": [
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "  print(\"Epoch: \", epoch)\n",
        "  for i, (images, labels) in enumerate(train_dataloader):\n",
        "\n",
        "      #######################\n",
        "      #  USE GPU FOR MODEL  #\n",
        "      #######################\n",
        "      images = images.view(-1, ncomps).requires_grad_().to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # Clear gradients w.r.t. parameters\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Forward pass to get output/logits\n",
        "      outputs = model(images)\n",
        "\n",
        "      # Calculate Loss: softmax --> cross entropy loss\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      # Getting gradients w.r.t. parameters\n",
        "      loss.backward()\n",
        "\n",
        "      # Updating parameters\n",
        "      optimizer.step()\n",
        "\n",
        "      iter += 1\n",
        "\n",
        "      if iter % 500 == 0:\n",
        "          # Calculate Accuracy         \n",
        "          correct = 0\n",
        "          total = 0\n",
        "          #Iterate through train dataset\n",
        "          for images, labels in train_dataloader:\n",
        "              #######################\n",
        "              #  USE GPU FOR MODEL  #\n",
        "              #######################\n",
        "              images = images.view(-1, ncomps).to(device)\n",
        "\n",
        "              # Forward pass only to get logits/output\n",
        "              outputs = model(images)\n",
        "\n",
        "              # Get predictions from the maximum value\n",
        "              _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "              # Total number of labels\n",
        "              total += labels.size(0)\n",
        "\n",
        "              #######################\n",
        "              #  USE GPU FOR MODEL  #\n",
        "              #######################\n",
        "              # Total correct predictions\n",
        "              if torch.cuda.is_available():\n",
        "                  correct += (predicted.cpu() == labels.cpu()).sum()\n",
        "              else:\n",
        "                  correct += (predicted == labels).sum()\n",
        "\n",
        "          accuracy = 100 * correct.item() / total\n",
        "\n",
        "          # Print Loss\n",
        "          print('Training: Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))\n",
        "          correct = 0\n",
        "          total = 0\n",
        "          # Iterate through test dataset\n",
        "          for images, labels in test_dataloader:\n",
        "              #######################\n",
        "              #  USE GPU FOR MODEL  #\n",
        "              #######################\n",
        "              images = images.view(-1, ncomps).to(device)\n",
        "\n",
        "              # Forward pass only to get logits/output\n",
        "              outputs = model(images)\n",
        "\n",
        "              # Get predictions from the maximum value\n",
        "              _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "              # Total number of labels\n",
        "              total += labels.size(0)\n",
        "\n",
        "              #######################\n",
        "              #  USE GPU FOR MODEL  #\n",
        "              #######################\n",
        "              # Total correct predictions\n",
        "              if torch.cuda.is_available():\n",
        "                  correct += (predicted.cpu() == labels.cpu()).sum()\n",
        "              else:\n",
        "                  correct += (predicted == labels).sum()\n",
        "\n",
        "          accuracy = 100 * correct.item() / total\n",
        "\n",
        "          # Print Loss\n",
        "          print('Testing: Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Testing: Iteration: 53500. Loss: 3.724705696105957. Accuracy: 17.76\n",
            "Epoch:  69\n",
            "Training: Iteration: 54000. Loss: 3.597198247909546. Accuracy: 20.93\n",
            "Testing: Iteration: 54000. Loss: 3.597198247909546. Accuracy: 17.84\n",
            "Training: Iteration: 54500. Loss: 3.537090301513672. Accuracy: 20.91\n",
            "Testing: Iteration: 54500. Loss: 3.537090301513672. Accuracy: 17.86\n",
            "Epoch:  70\n",
            "Training: Iteration: 55000. Loss: 3.3210771083831787. Accuracy: 20.93\n",
            "Testing: Iteration: 55000. Loss: 3.3210771083831787. Accuracy: 17.8\n",
            "Training: Iteration: 55500. Loss: 3.3136143684387207. Accuracy: 20.99\n",
            "Testing: Iteration: 55500. Loss: 3.3136143684387207. Accuracy: 17.97\n",
            "Epoch:  71\n",
            "Training: Iteration: 56000. Loss: 3.2296078205108643. Accuracy: 21.016\n",
            "Testing: Iteration: 56000. Loss: 3.2296078205108643. Accuracy: 17.91\n",
            "Epoch:  72\n",
            "Training: Iteration: 56500. Loss: 3.3641257286071777. Accuracy: 21.076\n",
            "Testing: Iteration: 56500. Loss: 3.3641257286071777. Accuracy: 17.85\n",
            "Training: Iteration: 57000. Loss: 3.619546413421631. Accuracy: 21.018\n",
            "Testing: Iteration: 57000. Loss: 3.619546413421631. Accuracy: 18.01\n",
            "Epoch:  73\n",
            "Training: Iteration: 57500. Loss: 3.415073871612549. Accuracy: 21.102\n",
            "Testing: Iteration: 57500. Loss: 3.415073871612549. Accuracy: 17.79\n",
            "Epoch:  74\n",
            "Training: Iteration: 58000. Loss: 3.422004461288452. Accuracy: 21.194\n",
            "Testing: Iteration: 58000. Loss: 3.422004461288452. Accuracy: 17.9\n",
            "Training: Iteration: 58500. Loss: 3.683471918106079. Accuracy: 21.148\n",
            "Testing: Iteration: 58500. Loss: 3.683471918106079. Accuracy: 17.97\n",
            "Epoch:  75\n",
            "Training: Iteration: 59000. Loss: 3.6315672397613525. Accuracy: 21.156\n",
            "Testing: Iteration: 59000. Loss: 3.6315672397613525. Accuracy: 17.9\n",
            "Epoch:  76\n",
            "Training: Iteration: 59500. Loss: 3.4320247173309326. Accuracy: 21.192\n",
            "Testing: Iteration: 59500. Loss: 3.4320247173309326. Accuracy: 17.86\n",
            "Training: Iteration: 60000. Loss: 3.111804246902466. Accuracy: 21.218\n",
            "Testing: Iteration: 60000. Loss: 3.111804246902466. Accuracy: 17.98\n",
            "Epoch:  77\n",
            "Training: Iteration: 60500. Loss: 3.4563660621643066. Accuracy: 21.228\n",
            "Testing: Iteration: 60500. Loss: 3.4563660621643066. Accuracy: 17.85\n",
            "Epoch:  78\n",
            "Training: Iteration: 61000. Loss: 3.3740015029907227. Accuracy: 21.284\n",
            "Testing: Iteration: 61000. Loss: 3.3740015029907227. Accuracy: 17.97\n",
            "Training: Iteration: 61500. Loss: 3.6601381301879883. Accuracy: 21.256\n",
            "Testing: Iteration: 61500. Loss: 3.6601381301879883. Accuracy: 17.86\n",
            "Epoch:  79\n",
            "Training: Iteration: 62000. Loss: 3.4105818271636963. Accuracy: 21.378\n",
            "Testing: Iteration: 62000. Loss: 3.4105818271636963. Accuracy: 17.92\n",
            "Training: Iteration: 62500. Loss: 3.3683910369873047. Accuracy: 21.314\n",
            "Testing: Iteration: 62500. Loss: 3.3683910369873047. Accuracy: 18.08\n",
            "Epoch:  80\n",
            "Training: Iteration: 63000. Loss: 3.7998433113098145. Accuracy: 21.348\n",
            "Testing: Iteration: 63000. Loss: 3.7998433113098145. Accuracy: 18.01\n",
            "Epoch:  81\n",
            "Training: Iteration: 63500. Loss: 3.5647459030151367. Accuracy: 21.448\n",
            "Testing: Iteration: 63500. Loss: 3.5647459030151367. Accuracy: 17.83\n",
            "Training: Iteration: 64000. Loss: 3.425417184829712. Accuracy: 21.362\n",
            "Testing: Iteration: 64000. Loss: 3.425417184829712. Accuracy: 18.0\n",
            "Epoch:  82\n",
            "Training: Iteration: 64500. Loss: 3.468548536300659. Accuracy: 21.43\n",
            "Testing: Iteration: 64500. Loss: 3.468548536300659. Accuracy: 17.99\n",
            "Epoch:  83\n",
            "Training: Iteration: 65000. Loss: 3.6460330486297607. Accuracy: 21.49\n",
            "Testing: Iteration: 65000. Loss: 3.6460330486297607. Accuracy: 17.97\n",
            "Training: Iteration: 65500. Loss: 3.5019891262054443. Accuracy: 21.492\n",
            "Testing: Iteration: 65500. Loss: 3.5019891262054443. Accuracy: 18.05\n",
            "Epoch:  84\n",
            "Training: Iteration: 66000. Loss: 3.6001830101013184. Accuracy: 21.526\n",
            "Testing: Iteration: 66000. Loss: 3.6001830101013184. Accuracy: 17.95\n",
            "Epoch:  85\n",
            "Training: Iteration: 66500. Loss: 3.667818307876587. Accuracy: 21.51\n",
            "Testing: Iteration: 66500. Loss: 3.667818307876587. Accuracy: 17.97\n",
            "Training: Iteration: 67000. Loss: 3.462703227996826. Accuracy: 21.532\n",
            "Testing: Iteration: 67000. Loss: 3.462703227996826. Accuracy: 18.01\n",
            "Epoch:  86\n",
            "Training: Iteration: 67500. Loss: 3.4478414058685303. Accuracy: 21.594\n",
            "Testing: Iteration: 67500. Loss: 3.4478414058685303. Accuracy: 18.04\n",
            "Training: Iteration: 68000. Loss: 3.6897857189178467. Accuracy: 21.62\n",
            "Testing: Iteration: 68000. Loss: 3.6897857189178467. Accuracy: 18.08\n",
            "Epoch:  87\n",
            "Training: Iteration: 68500. Loss: 3.3527133464813232. Accuracy: 21.632\n",
            "Testing: Iteration: 68500. Loss: 3.3527133464813232. Accuracy: 18.14\n",
            "Epoch:  88\n",
            "Training: Iteration: 69000. Loss: 3.411648750305176. Accuracy: 21.724\n",
            "Testing: Iteration: 69000. Loss: 3.411648750305176. Accuracy: 17.95\n",
            "Training: Iteration: 69500. Loss: 3.648663282394409. Accuracy: 21.672\n",
            "Testing: Iteration: 69500. Loss: 3.648663282394409. Accuracy: 18.16\n",
            "Epoch:  89\n",
            "Training: Iteration: 70000. Loss: 3.3758316040039062. Accuracy: 21.686\n",
            "Testing: Iteration: 70000. Loss: 3.3758316040039062. Accuracy: 18.0\n",
            "Epoch:  90\n",
            "Training: Iteration: 70500. Loss: 3.1780879497528076. Accuracy: 21.782\n",
            "Testing: Iteration: 70500. Loss: 3.1780879497528076. Accuracy: 18.07\n",
            "Training: Iteration: 71000. Loss: 3.438352584838867. Accuracy: 21.712\n",
            "Testing: Iteration: 71000. Loss: 3.438352584838867. Accuracy: 18.25\n",
            "Epoch:  91\n",
            "Training: Iteration: 71500. Loss: 3.761737823486328. Accuracy: 21.796\n",
            "Testing: Iteration: 71500. Loss: 3.761737823486328. Accuracy: 18.07\n",
            "Epoch:  92\n",
            "Training: Iteration: 72000. Loss: 3.5506181716918945. Accuracy: 21.844\n",
            "Testing: Iteration: 72000. Loss: 3.5506181716918945. Accuracy: 18.05\n",
            "Training: Iteration: 72500. Loss: 3.597579002380371. Accuracy: 21.784\n",
            "Testing: Iteration: 72500. Loss: 3.597579002380371. Accuracy: 18.18\n",
            "Epoch:  93\n",
            "Training: Iteration: 73000. Loss: 3.6880900859832764. Accuracy: 21.85\n",
            "Testing: Iteration: 73000. Loss: 3.6880900859832764. Accuracy: 18.08\n",
            "Training: Iteration: 73500. Loss: 3.5954160690307617. Accuracy: 21.892\n",
            "Testing: Iteration: 73500. Loss: 3.5954160690307617. Accuracy: 18.24\n",
            "Epoch:  94\n",
            "Training: Iteration: 74000. Loss: 3.2665748596191406. Accuracy: 21.846\n",
            "Testing: Iteration: 74000. Loss: 3.2665748596191406. Accuracy: 18.17\n",
            "Epoch:  95\n",
            "Training: Iteration: 74500. Loss: 3.0681190490722656. Accuracy: 21.936\n",
            "Testing: Iteration: 74500. Loss: 3.0681190490722656. Accuracy: 18.13\n",
            "Training: Iteration: 75000. Loss: 3.450878381729126. Accuracy: 21.856\n",
            "Testing: Iteration: 75000. Loss: 3.450878381729126. Accuracy: 18.2\n",
            "Epoch:  96\n",
            "Training: Iteration: 75500. Loss: 3.529080867767334. Accuracy: 21.896\n",
            "Testing: Iteration: 75500. Loss: 3.529080867767334. Accuracy: 18.11\n",
            "Epoch:  97\n",
            "Training: Iteration: 76000. Loss: 3.7304325103759766. Accuracy: 22.044\n",
            "Testing: Iteration: 76000. Loss: 3.7304325103759766. Accuracy: 18.13\n",
            "Training: Iteration: 76500. Loss: 3.4141318798065186. Accuracy: 21.942\n",
            "Testing: Iteration: 76500. Loss: 3.4141318798065186. Accuracy: 18.25\n",
            "Epoch:  98\n",
            "Training: Iteration: 77000. Loss: 3.51538348197937. Accuracy: 21.972\n",
            "Testing: Iteration: 77000. Loss: 3.51538348197937. Accuracy: 18.11\n",
            "Epoch:  99\n",
            "Training: Iteration: 77500. Loss: 3.5335452556610107. Accuracy: 22.03\n",
            "Testing: Iteration: 77500. Loss: 3.5335452556610107. Accuracy: 18.13\n",
            "Training: Iteration: 78000. Loss: 3.155150890350342. Accuracy: 22.008\n",
            "Testing: Iteration: 78000. Loss: 3.155150890350342. Accuracy: 18.31\n",
            "Epoch:  100\n",
            "Training: Iteration: 78500. Loss: 3.690760374069214. Accuracy: 22.006\n",
            "Testing: Iteration: 78500. Loss: 3.690760374069214. Accuracy: 18.21\n",
            "Epoch:  101\n",
            "Training: Iteration: 79000. Loss: 3.281769275665283. Accuracy: 22.038\n",
            "Testing: Iteration: 79000. Loss: 3.281769275665283. Accuracy: 18.26\n",
            "Training: Iteration: 79500. Loss: 3.2022924423217773. Accuracy: 22.006\n",
            "Testing: Iteration: 79500. Loss: 3.2022924423217773. Accuracy: 18.29\n",
            "Epoch:  102\n",
            "Training: Iteration: 80000. Loss: 3.5564558506011963. Accuracy: 22.108\n",
            "Testing: Iteration: 80000. Loss: 3.5564558506011963. Accuracy: 18.3\n",
            "Training: Iteration: 80500. Loss: 3.225733757019043. Accuracy: 22.07\n",
            "Testing: Iteration: 80500. Loss: 3.225733757019043. Accuracy: 18.32\n",
            "Epoch:  103\n",
            "Training: Iteration: 81000. Loss: 3.504842758178711. Accuracy: 22.064\n",
            "Testing: Iteration: 81000. Loss: 3.504842758178711. Accuracy: 18.25\n",
            "Epoch:  104\n",
            "Training: Iteration: 81500. Loss: 3.164062261581421. Accuracy: 22.218\n",
            "Testing: Iteration: 81500. Loss: 3.164062261581421. Accuracy: 18.28\n",
            "Training: Iteration: 82000. Loss: 3.6043782234191895. Accuracy: 22.08\n",
            "Testing: Iteration: 82000. Loss: 3.6043782234191895. Accuracy: 18.33\n",
            "Epoch:  105\n",
            "Training: Iteration: 82500. Loss: 3.452228307723999. Accuracy: 22.136\n",
            "Testing: Iteration: 82500. Loss: 3.452228307723999. Accuracy: 18.23\n",
            "Epoch:  106\n",
            "Training: Iteration: 83000. Loss: 3.3346381187438965. Accuracy: 22.24\n",
            "Testing: Iteration: 83000. Loss: 3.3346381187438965. Accuracy: 18.28\n",
            "Training: Iteration: 83500. Loss: 3.5199246406555176. Accuracy: 22.202\n",
            "Testing: Iteration: 83500. Loss: 3.5199246406555176. Accuracy: 18.47\n",
            "Epoch:  107\n",
            "Training: Iteration: 84000. Loss: 3.135843276977539. Accuracy: 22.226\n",
            "Testing: Iteration: 84000. Loss: 3.135843276977539. Accuracy: 18.26\n",
            "Epoch:  108\n",
            "Training: Iteration: 84500. Loss: 3.286634683609009. Accuracy: 22.218\n",
            "Testing: Iteration: 84500. Loss: 3.286634683609009. Accuracy: 18.35\n",
            "Training: Iteration: 85000. Loss: 3.3497800827026367. Accuracy: 22.214\n",
            "Testing: Iteration: 85000. Loss: 3.3497800827026367. Accuracy: 18.37\n",
            "Epoch:  109\n",
            "Training: Iteration: 85500. Loss: 3.2832090854644775. Accuracy: 22.282\n",
            "Testing: Iteration: 85500. Loss: 3.2832090854644775. Accuracy: 18.32\n",
            "Training: Iteration: 86000. Loss: 3.227834701538086. Accuracy: 22.282\n",
            "Testing: Iteration: 86000. Loss: 3.227834701538086. Accuracy: 18.37\n",
            "Epoch:  110\n",
            "Training: Iteration: 86500. Loss: 3.433016777038574. Accuracy: 22.28\n",
            "Testing: Iteration: 86500. Loss: 3.433016777038574. Accuracy: 18.3\n",
            "Epoch:  111\n",
            "Training: Iteration: 87000. Loss: 3.5705018043518066. Accuracy: 22.386\n",
            "Testing: Iteration: 87000. Loss: 3.5705018043518066. Accuracy: 18.31\n",
            "Training: Iteration: 87500. Loss: 3.478055477142334. Accuracy: 22.238\n",
            "Testing: Iteration: 87500. Loss: 3.478055477142334. Accuracy: 18.28\n",
            "Epoch:  112\n",
            "Training: Iteration: 88000. Loss: 3.2663567066192627. Accuracy: 22.33\n",
            "Testing: Iteration: 88000. Loss: 3.2663567066192627. Accuracy: 18.27\n",
            "Epoch:  113\n",
            "Training: Iteration: 88500. Loss: 3.4735634326934814. Accuracy: 22.418\n",
            "Testing: Iteration: 88500. Loss: 3.4735634326934814. Accuracy: 18.3\n",
            "Training: Iteration: 89000. Loss: 3.250614643096924. Accuracy: 22.37\n",
            "Testing: Iteration: 89000. Loss: 3.250614643096924. Accuracy: 18.41\n",
            "Epoch:  114\n",
            "Training: Iteration: 89500. Loss: 3.3403961658477783. Accuracy: 22.372\n",
            "Testing: Iteration: 89500. Loss: 3.3403961658477783. Accuracy: 18.25\n",
            "Epoch:  115\n",
            "Training: Iteration: 90000. Loss: 3.8700356483459473. Accuracy: 22.458\n",
            "Testing: Iteration: 90000. Loss: 3.8700356483459473. Accuracy: 18.35\n",
            "Training: Iteration: 90500. Loss: 3.7986114025115967. Accuracy: 22.398\n",
            "Testing: Iteration: 90500. Loss: 3.7986114025115967. Accuracy: 18.4\n",
            "Epoch:  116\n",
            "Training: Iteration: 91000. Loss: 3.213728427886963. Accuracy: 22.414\n",
            "Testing: Iteration: 91000. Loss: 3.213728427886963. Accuracy: 18.37\n",
            "Epoch:  117\n",
            "Training: Iteration: 91500. Loss: 3.2982780933380127. Accuracy: 22.456\n",
            "Testing: Iteration: 91500. Loss: 3.2982780933380127. Accuracy: 18.33\n",
            "Training: Iteration: 92000. Loss: 3.099297046661377. Accuracy: 22.412\n",
            "Testing: Iteration: 92000. Loss: 3.099297046661377. Accuracy: 18.33\n",
            "Epoch:  118\n",
            "Training: Iteration: 92500. Loss: 3.561378002166748. Accuracy: 22.512\n",
            "Testing: Iteration: 92500. Loss: 3.561378002166748. Accuracy: 18.4\n",
            "Training: Iteration: 93000. Loss: 3.364513874053955. Accuracy: 22.448\n",
            "Testing: Iteration: 93000. Loss: 3.364513874053955. Accuracy: 18.36\n",
            "Epoch:  119\n",
            "Training: Iteration: 93500. Loss: 3.534736156463623. Accuracy: 22.468\n",
            "Testing: Iteration: 93500. Loss: 3.534736156463623. Accuracy: 18.21\n",
            "Epoch:  120\n",
            "Training: Iteration: 94000. Loss: 3.5030405521392822. Accuracy: 22.564\n",
            "Testing: Iteration: 94000. Loss: 3.5030405521392822. Accuracy: 18.36\n",
            "Training: Iteration: 94500. Loss: 3.2694811820983887. Accuracy: 22.454\n",
            "Testing: Iteration: 94500. Loss: 3.2694811820983887. Accuracy: 18.32\n",
            "Epoch:  121\n",
            "Training: Iteration: 95000. Loss: 3.77146315574646. Accuracy: 22.498\n",
            "Testing: Iteration: 95000. Loss: 3.77146315574646. Accuracy: 18.39\n",
            "Epoch:  122\n",
            "Training: Iteration: 95500. Loss: 3.5015411376953125. Accuracy: 22.584\n",
            "Testing: Iteration: 95500. Loss: 3.5015411376953125. Accuracy: 18.39\n",
            "Training: Iteration: 96000. Loss: 3.559159994125366. Accuracy: 22.566\n",
            "Testing: Iteration: 96000. Loss: 3.559159994125366. Accuracy: 18.45\n",
            "Epoch:  123\n",
            "Training: Iteration: 96500. Loss: 3.476928234100342. Accuracy: 22.568\n",
            "Testing: Iteration: 96500. Loss: 3.476928234100342. Accuracy: 18.38\n",
            "Epoch:  124\n",
            "Training: Iteration: 97000. Loss: 3.383448600769043. Accuracy: 22.614\n",
            "Testing: Iteration: 97000. Loss: 3.383448600769043. Accuracy: 18.38\n",
            "Training: Iteration: 97500. Loss: 3.2958855628967285. Accuracy: 22.534\n",
            "Testing: Iteration: 97500. Loss: 3.2958855628967285. Accuracy: 18.41\n",
            "Epoch:  125\n",
            "Training: Iteration: 98000. Loss: 3.246195077896118. Accuracy: 22.588\n",
            "Testing: Iteration: 98000. Loss: 3.246195077896118. Accuracy: 18.39\n",
            "Training: Iteration: 98500. Loss: 3.057795286178589. Accuracy: 22.6\n",
            "Testing: Iteration: 98500. Loss: 3.057795286178589. Accuracy: 18.42\n",
            "Epoch:  126\n",
            "Training: Iteration: 99000. Loss: 3.4961259365081787. Accuracy: 22.622\n",
            "Testing: Iteration: 99000. Loss: 3.4961259365081787. Accuracy: 18.41\n",
            "Epoch:  127\n",
            "Training: Iteration: 99500. Loss: 3.194690465927124. Accuracy: 22.71\n",
            "Testing: Iteration: 99500. Loss: 3.194690465927124. Accuracy: 18.41\n",
            "Training: Iteration: 100000. Loss: 3.801278591156006. Accuracy: 22.638\n",
            "Testing: Iteration: 100000. Loss: 3.801278591156006. Accuracy: 18.41\n",
            "Epoch:  128\n",
            "Training: Iteration: 100500. Loss: 3.28585147857666. Accuracy: 22.674\n",
            "Testing: Iteration: 100500. Loss: 3.28585147857666. Accuracy: 18.41\n",
            "Epoch:  129\n",
            "Training: Iteration: 101000. Loss: 3.397505283355713. Accuracy: 22.746\n",
            "Testing: Iteration: 101000. Loss: 3.397505283355713. Accuracy: 18.45\n",
            "Training: Iteration: 101500. Loss: 3.4604604244232178. Accuracy: 22.684\n",
            "Testing: Iteration: 101500. Loss: 3.4604604244232178. Accuracy: 18.41\n",
            "Epoch:  130\n",
            "Training: Iteration: 102000. Loss: 3.5015881061553955. Accuracy: 22.666\n",
            "Testing: Iteration: 102000. Loss: 3.5015881061553955. Accuracy: 18.31\n",
            "Epoch:  131\n",
            "Training: Iteration: 102500. Loss: 3.62947940826416. Accuracy: 22.792\n",
            "Testing: Iteration: 102500. Loss: 3.62947940826416. Accuracy: 18.45\n",
            "Training: Iteration: 103000. Loss: 3.273883819580078. Accuracy: 22.684\n",
            "Testing: Iteration: 103000. Loss: 3.273883819580078. Accuracy: 18.44\n",
            "Epoch:  132\n",
            "Training: Iteration: 103500. Loss: 3.250728130340576. Accuracy: 22.702\n",
            "Testing: Iteration: 103500. Loss: 3.250728130340576. Accuracy: 18.31\n",
            "Training: Iteration: 104000. Loss: 3.877455234527588. Accuracy: 22.762\n",
            "Testing: Iteration: 104000. Loss: 3.877455234527588. Accuracy: 18.47\n",
            "Epoch:  133\n",
            "Training: Iteration: 104500. Loss: 3.4022374153137207. Accuracy: 22.728\n",
            "Testing: Iteration: 104500. Loss: 3.4022374153137207. Accuracy: 18.36\n",
            "Epoch:  134\n",
            "Training: Iteration: 105000. Loss: 3.370547294616699. Accuracy: 22.818\n",
            "Testing: Iteration: 105000. Loss: 3.370547294616699. Accuracy: 18.34\n",
            "Training: Iteration: 105500. Loss: 3.3269710540771484. Accuracy: 22.772\n",
            "Testing: Iteration: 105500. Loss: 3.3269710540771484. Accuracy: 18.4\n",
            "Epoch:  135\n",
            "Training: Iteration: 106000. Loss: 3.299868106842041. Accuracy: 22.81\n",
            "Testing: Iteration: 106000. Loss: 3.299868106842041. Accuracy: 18.33\n",
            "Epoch:  136\n",
            "Training: Iteration: 106500. Loss: 3.4271137714385986. Accuracy: 22.854\n",
            "Testing: Iteration: 106500. Loss: 3.4271137714385986. Accuracy: 18.43\n",
            "Training: Iteration: 107000. Loss: 3.247735023498535. Accuracy: 22.81\n",
            "Testing: Iteration: 107000. Loss: 3.247735023498535. Accuracy: 18.41\n",
            "Epoch:  137\n",
            "Training: Iteration: 107500. Loss: 3.374613046646118. Accuracy: 22.824\n",
            "Testing: Iteration: 107500. Loss: 3.374613046646118. Accuracy: 18.34\n",
            "Epoch:  138\n",
            "Training: Iteration: 108000. Loss: 3.4551281929016113. Accuracy: 22.898\n",
            "Testing: Iteration: 108000. Loss: 3.4551281929016113. Accuracy: 18.48\n",
            "Training: Iteration: 108500. Loss: 3.4780869483947754. Accuracy: 22.816\n",
            "Testing: Iteration: 108500. Loss: 3.4780869483947754. Accuracy: 18.49\n",
            "Epoch:  139\n",
            "Training: Iteration: 109000. Loss: 3.2088117599487305. Accuracy: 22.844\n",
            "Testing: Iteration: 109000. Loss: 3.2088117599487305. Accuracy: 18.38\n",
            "Epoch:  140\n",
            "Training: Iteration: 109500. Loss: 3.342593193054199. Accuracy: 22.92\n",
            "Testing: Iteration: 109500. Loss: 3.342593193054199. Accuracy: 18.46\n",
            "Training: Iteration: 110000. Loss: 3.3339099884033203. Accuracy: 22.874\n",
            "Testing: Iteration: 110000. Loss: 3.3339099884033203. Accuracy: 18.46\n",
            "Epoch:  141\n",
            "Training: Iteration: 110500. Loss: 3.2814176082611084. Accuracy: 22.95\n",
            "Testing: Iteration: 110500. Loss: 3.2814176082611084. Accuracy: 18.5\n",
            "Training: Iteration: 111000. Loss: 3.971855640411377. Accuracy: 22.928\n",
            "Testing: Iteration: 111000. Loss: 3.971855640411377. Accuracy: 18.52\n",
            "Epoch:  142\n",
            "Training: Iteration: 111500. Loss: 3.1232614517211914. Accuracy: 22.894\n",
            "Testing: Iteration: 111500. Loss: 3.1232614517211914. Accuracy: 18.4\n",
            "Epoch:  143\n",
            "Training: Iteration: 112000. Loss: 3.055868148803711. Accuracy: 22.998\n",
            "Testing: Iteration: 112000. Loss: 3.055868148803711. Accuracy: 18.46\n",
            "Training: Iteration: 112500. Loss: 3.3757517337799072. Accuracy: 22.928\n",
            "Testing: Iteration: 112500. Loss: 3.3757517337799072. Accuracy: 18.42\n",
            "Epoch:  144\n",
            "Training: Iteration: 113000. Loss: 3.6177620887756348. Accuracy: 22.952\n",
            "Testing: Iteration: 113000. Loss: 3.6177620887756348. Accuracy: 18.42\n",
            "Epoch:  145\n",
            "Training: Iteration: 113500. Loss: 3.244155168533325. Accuracy: 23.07\n",
            "Testing: Iteration: 113500. Loss: 3.244155168533325. Accuracy: 18.5\n",
            "Training: Iteration: 114000. Loss: 3.2697384357452393. Accuracy: 22.986\n",
            "Testing: Iteration: 114000. Loss: 3.2697384357452393. Accuracy: 18.52\n",
            "Epoch:  146\n",
            "Training: Iteration: 114500. Loss: 3.092237949371338. Accuracy: 23.008\n",
            "Testing: Iteration: 114500. Loss: 3.092237949371338. Accuracy: 18.39\n",
            "Epoch:  147\n",
            "Training: Iteration: 115000. Loss: 3.5845425128936768. Accuracy: 23.116\n",
            "Testing: Iteration: 115000. Loss: 3.5845425128936768. Accuracy: 18.57\n",
            "Training: Iteration: 115500. Loss: 3.7073276042938232. Accuracy: 22.972\n",
            "Testing: Iteration: 115500. Loss: 3.7073276042938232. Accuracy: 18.51\n",
            "Epoch:  148\n",
            "Training: Iteration: 116000. Loss: 3.166532516479492. Accuracy: 23.042\n",
            "Testing: Iteration: 116000. Loss: 3.166532516479492. Accuracy: 18.54\n",
            "Training: Iteration: 116500. Loss: 3.395479202270508. Accuracy: 23.106\n",
            "Testing: Iteration: 116500. Loss: 3.395479202270508. Accuracy: 18.55\n",
            "Epoch:  149\n",
            "Training: Iteration: 117000. Loss: 2.997390031814575. Accuracy: 23.056\n",
            "Testing: Iteration: 117000. Loss: 2.997390031814575. Accuracy: 18.49\n",
            "Epoch:  150\n",
            "Training: Iteration: 117500. Loss: 3.5385568141937256. Accuracy: 23.116\n",
            "Testing: Iteration: 117500. Loss: 3.5385568141937256. Accuracy: 18.46\n",
            "Training: Iteration: 118000. Loss: 3.554780960083008. Accuracy: 23.056\n",
            "Testing: Iteration: 118000. Loss: 3.554780960083008. Accuracy: 18.47\n",
            "Epoch:  151\n",
            "Training: Iteration: 118500. Loss: 3.516078233718872. Accuracy: 23.12\n",
            "Testing: Iteration: 118500. Loss: 3.516078233718872. Accuracy: 18.45\n",
            "Epoch:  152\n",
            "Training: Iteration: 119000. Loss: 3.442751884460449. Accuracy: 23.198\n",
            "Testing: Iteration: 119000. Loss: 3.442751884460449. Accuracy: 18.56\n",
            "Training: Iteration: 119500. Loss: 3.0288760662078857. Accuracy: 23.12\n",
            "Testing: Iteration: 119500. Loss: 3.0288760662078857. Accuracy: 18.53\n",
            "Epoch:  153\n",
            "Training: Iteration: 120000. Loss: 3.333544969558716. Accuracy: 23.14\n",
            "Testing: Iteration: 120000. Loss: 3.333544969558716. Accuracy: 18.44\n",
            "Epoch:  154\n",
            "Training: Iteration: 120500. Loss: 3.2697198390960693. Accuracy: 23.23\n",
            "Testing: Iteration: 120500. Loss: 3.2697198390960693. Accuracy: 18.62\n",
            "Training: Iteration: 121000. Loss: 3.4384162425994873. Accuracy: 23.124\n",
            "Testing: Iteration: 121000. Loss: 3.4384162425994873. Accuracy: 18.51\n",
            "Epoch:  155\n",
            "Training: Iteration: 121500. Loss: 3.511362314224243. Accuracy: 23.176\n",
            "Testing: Iteration: 121500. Loss: 3.511362314224243. Accuracy: 18.5\n",
            "Epoch:  156\n",
            "Training: Iteration: 122000. Loss: 3.1998019218444824. Accuracy: 23.212\n",
            "Testing: Iteration: 122000. Loss: 3.1998019218444824. Accuracy: 18.64\n",
            "Training: Iteration: 122500. Loss: 3.546999216079712. Accuracy: 23.15\n",
            "Testing: Iteration: 122500. Loss: 3.546999216079712. Accuracy: 18.44\n",
            "Epoch:  157\n",
            "Training: Iteration: 123000. Loss: 3.562427282333374. Accuracy: 23.224\n",
            "Testing: Iteration: 123000. Loss: 3.562427282333374. Accuracy: 18.54\n",
            "Training: Iteration: 123500. Loss: 3.449734926223755. Accuracy: 23.23\n",
            "Testing: Iteration: 123500. Loss: 3.449734926223755. Accuracy: 18.6\n",
            "Epoch:  158\n",
            "Training: Iteration: 124000. Loss: 3.4504923820495605. Accuracy: 23.24\n",
            "Testing: Iteration: 124000. Loss: 3.4504923820495605. Accuracy: 18.44\n",
            "Epoch:  159\n",
            "Training: Iteration: 124500. Loss: 3.1345906257629395. Accuracy: 23.294\n",
            "Testing: Iteration: 124500. Loss: 3.1345906257629395. Accuracy: 18.57\n",
            "Training: Iteration: 125000. Loss: 3.4371707439422607. Accuracy: 23.26\n",
            "Testing: Iteration: 125000. Loss: 3.4371707439422607. Accuracy: 18.53\n",
            "Epoch:  160\n",
            "Training: Iteration: 125500. Loss: 3.296674966812134. Accuracy: 23.306\n",
            "Testing: Iteration: 125500. Loss: 3.296674966812134. Accuracy: 18.48\n",
            "Epoch:  161\n",
            "Training: Iteration: 126000. Loss: 3.6228952407836914. Accuracy: 23.36\n",
            "Testing: Iteration: 126000. Loss: 3.6228952407836914. Accuracy: 18.67\n",
            "Training: Iteration: 126500. Loss: 3.229271650314331. Accuracy: 23.334\n",
            "Testing: Iteration: 126500. Loss: 3.229271650314331. Accuracy: 18.49\n",
            "Epoch:  162\n",
            "Training: Iteration: 127000. Loss: 3.825399398803711. Accuracy: 23.304\n",
            "Testing: Iteration: 127000. Loss: 3.825399398803711. Accuracy: 18.54\n",
            "Epoch:  163\n",
            "Training: Iteration: 127500. Loss: 3.251716375350952. Accuracy: 23.354\n",
            "Testing: Iteration: 127500. Loss: 3.251716375350952. Accuracy: 18.55\n",
            "Training: Iteration: 128000. Loss: 3.095362424850464. Accuracy: 23.312\n",
            "Testing: Iteration: 128000. Loss: 3.095362424850464. Accuracy: 18.45\n",
            "Epoch:  164\n",
            "Training: Iteration: 128500. Loss: 3.8063857555389404. Accuracy: 23.33\n",
            "Testing: Iteration: 128500. Loss: 3.8063857555389404. Accuracy: 18.55\n",
            "Training: Iteration: 129000. Loss: 3.6665263175964355. Accuracy: 23.372\n",
            "Testing: Iteration: 129000. Loss: 3.6665263175964355. Accuracy: 18.64\n",
            "Epoch:  165\n",
            "Training: Iteration: 129500. Loss: 3.2462410926818848. Accuracy: 23.346\n",
            "Testing: Iteration: 129500. Loss: 3.2462410926818848. Accuracy: 18.49\n",
            "Epoch:  166\n",
            "Training: Iteration: 130000. Loss: 3.683712959289551. Accuracy: 23.41\n",
            "Testing: Iteration: 130000. Loss: 3.683712959289551. Accuracy: 18.66\n",
            "Training: Iteration: 130500. Loss: 3.229339838027954. Accuracy: 23.42\n",
            "Testing: Iteration: 130500. Loss: 3.229339838027954. Accuracy: 18.62\n",
            "Epoch:  167\n",
            "Training: Iteration: 131000. Loss: 3.885509490966797. Accuracy: 23.374\n",
            "Testing: Iteration: 131000. Loss: 3.885509490966797. Accuracy: 18.61\n",
            "Epoch:  168\n",
            "Training: Iteration: 131500. Loss: 3.3856306076049805. Accuracy: 23.456\n",
            "Testing: Iteration: 131500. Loss: 3.3856306076049805. Accuracy: 18.58\n",
            "Training: Iteration: 132000. Loss: 3.1547796726226807. Accuracy: 23.398\n",
            "Testing: Iteration: 132000. Loss: 3.1547796726226807. Accuracy: 18.58\n",
            "Epoch:  169\n",
            "Training: Iteration: 132500. Loss: 3.620551824569702. Accuracy: 23.388\n",
            "Testing: Iteration: 132500. Loss: 3.620551824569702. Accuracy: 18.43\n",
            "Epoch:  170\n",
            "Training: Iteration: 133000. Loss: 3.1401751041412354. Accuracy: 23.488\n",
            "Testing: Iteration: 133000. Loss: 3.1401751041412354. Accuracy: 18.59\n",
            "Training: Iteration: 133500. Loss: 3.4139492511749268. Accuracy: 23.386\n",
            "Testing: Iteration: 133500. Loss: 3.4139492511749268. Accuracy: 18.53\n",
            "Epoch:  171\n",
            "Training: Iteration: 134000. Loss: 3.5720157623291016. Accuracy: 23.436\n",
            "Testing: Iteration: 134000. Loss: 3.5720157623291016. Accuracy: 18.65\n",
            "Training: Iteration: 134500. Loss: 3.3713204860687256. Accuracy: 23.472\n",
            "Testing: Iteration: 134500. Loss: 3.3713204860687256. Accuracy: 18.65\n",
            "Epoch:  172\n",
            "Training: Iteration: 135000. Loss: 3.507429838180542. Accuracy: 23.44\n",
            "Testing: Iteration: 135000. Loss: 3.507429838180542. Accuracy: 18.46\n",
            "Epoch:  173\n",
            "Training: Iteration: 135500. Loss: 3.607215404510498. Accuracy: 23.464\n",
            "Testing: Iteration: 135500. Loss: 3.607215404510498. Accuracy: 18.63\n",
            "Training: Iteration: 136000. Loss: 3.421076774597168. Accuracy: 23.494\n",
            "Testing: Iteration: 136000. Loss: 3.421076774597168. Accuracy: 18.67\n",
            "Epoch:  174\n",
            "Training: Iteration: 136500. Loss: 3.784867525100708. Accuracy: 23.5\n",
            "Testing: Iteration: 136500. Loss: 3.784867525100708. Accuracy: 18.52\n",
            "Epoch:  175\n",
            "Training: Iteration: 137000. Loss: 3.5119380950927734. Accuracy: 23.568\n",
            "Testing: Iteration: 137000. Loss: 3.5119380950927734. Accuracy: 18.6\n",
            "Training: Iteration: 137500. Loss: 3.4731037616729736. Accuracy: 23.496\n",
            "Testing: Iteration: 137500. Loss: 3.4731037616729736. Accuracy: 18.59\n",
            "Epoch:  176\n",
            "Training: Iteration: 138000. Loss: 3.408205986022949. Accuracy: 23.51\n",
            "Testing: Iteration: 138000. Loss: 3.408205986022949. Accuracy: 18.55\n",
            "Epoch:  177\n",
            "Training: Iteration: 138500. Loss: 3.4720511436462402. Accuracy: 23.588\n",
            "Testing: Iteration: 138500. Loss: 3.4720511436462402. Accuracy: 18.61\n",
            "Training: Iteration: 139000. Loss: 3.2705745697021484. Accuracy: 23.51\n",
            "Testing: Iteration: 139000. Loss: 3.2705745697021484. Accuracy: 18.59\n",
            "Epoch:  178\n",
            "Training: Iteration: 139500. Loss: 3.6357524394989014. Accuracy: 23.56\n",
            "Testing: Iteration: 139500. Loss: 3.6357524394989014. Accuracy: 18.6\n",
            "Epoch:  179\n",
            "Training: Iteration: 140000. Loss: 3.649294853210449. Accuracy: 23.57\n",
            "Testing: Iteration: 140000. Loss: 3.649294853210449. Accuracy: 18.61\n",
            "Training: Iteration: 140500. Loss: 3.1636128425598145. Accuracy: 23.504\n",
            "Testing: Iteration: 140500. Loss: 3.1636128425598145. Accuracy: 18.58\n",
            "Epoch:  180\n",
            "Training: Iteration: 141000. Loss: 3.35129714012146. Accuracy: 23.56\n",
            "Testing: Iteration: 141000. Loss: 3.35129714012146. Accuracy: 18.62\n",
            "Training: Iteration: 141500. Loss: 3.3524181842803955. Accuracy: 23.598\n",
            "Testing: Iteration: 141500. Loss: 3.3524181842803955. Accuracy: 18.73\n",
            "Epoch:  181\n",
            "Training: Iteration: 142000. Loss: 3.2403082847595215. Accuracy: 23.566\n",
            "Testing: Iteration: 142000. Loss: 3.2403082847595215. Accuracy: 18.55\n",
            "Epoch:  182\n",
            "Training: Iteration: 142500. Loss: 3.3938088417053223. Accuracy: 23.656\n",
            "Testing: Iteration: 142500. Loss: 3.3938088417053223. Accuracy: 18.58\n",
            "Training: Iteration: 143000. Loss: 3.311300754547119. Accuracy: 23.568\n",
            "Testing: Iteration: 143000. Loss: 3.311300754547119. Accuracy: 18.64\n",
            "Epoch:  183\n",
            "Training: Iteration: 143500. Loss: 3.3834362030029297. Accuracy: 23.572\n",
            "Testing: Iteration: 143500. Loss: 3.3834362030029297. Accuracy: 18.63\n",
            "Epoch:  184\n",
            "Training: Iteration: 144000. Loss: 3.1813173294067383. Accuracy: 23.62\n",
            "Testing: Iteration: 144000. Loss: 3.1813173294067383. Accuracy: 18.72\n",
            "Training: Iteration: 144500. Loss: 3.3985211849212646. Accuracy: 23.57\n",
            "Testing: Iteration: 144500. Loss: 3.3985211849212646. Accuracy: 18.66\n",
            "Epoch:  185\n",
            "Training: Iteration: 145000. Loss: 3.190866470336914. Accuracy: 23.62\n",
            "Testing: Iteration: 145000. Loss: 3.190866470336914. Accuracy: 18.52\n",
            "Epoch:  186\n",
            "Training: Iteration: 145500. Loss: 3.498281717300415. Accuracy: 23.686\n",
            "Testing: Iteration: 145500. Loss: 3.498281717300415. Accuracy: 18.59\n",
            "Training: Iteration: 146000. Loss: 3.543675661087036. Accuracy: 23.568\n",
            "Testing: Iteration: 146000. Loss: 3.543675661087036. Accuracy: 18.66\n",
            "Epoch:  187\n",
            "Training: Iteration: 146500. Loss: 3.5554592609405518. Accuracy: 23.646\n",
            "Testing: Iteration: 146500. Loss: 3.5554592609405518. Accuracy: 18.64\n",
            "Training: Iteration: 147000. Loss: 3.4504916667938232. Accuracy: 23.652\n",
            "Testing: Iteration: 147000. Loss: 3.4504916667938232. Accuracy: 18.67\n",
            "Epoch:  188\n",
            "Training: Iteration: 147500. Loss: 3.7660324573516846. Accuracy: 23.668\n",
            "Testing: Iteration: 147500. Loss: 3.7660324573516846. Accuracy: 18.7\n",
            "Epoch:  189\n",
            "Training: Iteration: 148000. Loss: 3.347210168838501. Accuracy: 23.74\n",
            "Testing: Iteration: 148000. Loss: 3.347210168838501. Accuracy: 18.73\n",
            "Training: Iteration: 148500. Loss: 3.462770700454712. Accuracy: 23.69\n",
            "Testing: Iteration: 148500. Loss: 3.462770700454712. Accuracy: 18.74\n",
            "Epoch:  190\n",
            "Training: Iteration: 149000. Loss: 3.165421485900879. Accuracy: 23.656\n",
            "Testing: Iteration: 149000. Loss: 3.165421485900879. Accuracy: 18.61\n",
            "Epoch:  191\n",
            "Training: Iteration: 149500. Loss: 3.2571489810943604. Accuracy: 23.732\n",
            "Testing: Iteration: 149500. Loss: 3.2571489810943604. Accuracy: 18.69\n",
            "Training: Iteration: 150000. Loss: 3.4661953449249268. Accuracy: 23.686\n",
            "Testing: Iteration: 150000. Loss: 3.4661953449249268. Accuracy: 18.67\n",
            "Epoch:  192\n",
            "Training: Iteration: 150500. Loss: 2.92587947845459. Accuracy: 23.69\n",
            "Testing: Iteration: 150500. Loss: 2.92587947845459. Accuracy: 18.59\n",
            "Epoch:  193\n",
            "Training: Iteration: 151000. Loss: 3.442354202270508. Accuracy: 23.774\n",
            "Testing: Iteration: 151000. Loss: 3.442354202270508. Accuracy: 18.72\n",
            "Training: Iteration: 151500. Loss: 3.4129629135131836. Accuracy: 23.7\n",
            "Testing: Iteration: 151500. Loss: 3.4129629135131836. Accuracy: 18.68\n",
            "Epoch:  194\n",
            "Training: Iteration: 152000. Loss: 3.2682905197143555. Accuracy: 23.73\n",
            "Testing: Iteration: 152000. Loss: 3.2682905197143555. Accuracy: 18.75\n",
            "Epoch:  195\n",
            "Training: Iteration: 152500. Loss: 3.067610025405884. Accuracy: 23.764\n",
            "Testing: Iteration: 152500. Loss: 3.067610025405884. Accuracy: 18.7\n",
            "Training: Iteration: 153000. Loss: 3.4724340438842773. Accuracy: 23.762\n",
            "Testing: Iteration: 153000. Loss: 3.4724340438842773. Accuracy: 18.66\n",
            "Epoch:  196\n",
            "Training: Iteration: 153500. Loss: 3.4423105716705322. Accuracy: 23.76\n",
            "Testing: Iteration: 153500. Loss: 3.4423105716705322. Accuracy: 18.71\n",
            "Training: Iteration: 154000. Loss: 3.3752191066741943. Accuracy: 23.76\n",
            "Testing: Iteration: 154000. Loss: 3.3752191066741943. Accuracy: 18.76\n",
            "Epoch:  197\n",
            "Training: Iteration: 154500. Loss: 3.35042142868042. Accuracy: 23.75\n",
            "Testing: Iteration: 154500. Loss: 3.35042142868042. Accuracy: 18.67\n",
            "Epoch:  198\n",
            "Training: Iteration: 155000. Loss: 3.31782603263855. Accuracy: 23.886\n",
            "Testing: Iteration: 155000. Loss: 3.31782603263855. Accuracy: 18.62\n",
            "Training: Iteration: 155500. Loss: 3.3850595951080322. Accuracy: 23.78\n",
            "Testing: Iteration: 155500. Loss: 3.3850595951080322. Accuracy: 18.64\n",
            "Epoch:  199\n",
            "Training: Iteration: 156000. Loss: 3.2984731197357178. Accuracy: 23.77\n",
            "Testing: Iteration: 156000. Loss: 3.2984731197357178. Accuracy: 18.68\n",
            "Epoch:  200\n",
            "Training: Iteration: 156500. Loss: 3.5009593963623047. Accuracy: 23.876\n",
            "Testing: Iteration: 156500. Loss: 3.5009593963623047. Accuracy: 18.69\n",
            "Training: Iteration: 157000. Loss: 3.182011842727661. Accuracy: 23.746\n",
            "Testing: Iteration: 157000. Loss: 3.182011842727661. Accuracy: 18.72\n",
            "Epoch:  201\n",
            "Training: Iteration: 157500. Loss: 3.1067168712615967. Accuracy: 23.784\n",
            "Testing: Iteration: 157500. Loss: 3.1067168712615967. Accuracy: 18.69\n",
            "Epoch:  202\n",
            "Training: Iteration: 158000. Loss: 3.4760701656341553. Accuracy: 23.886\n",
            "Testing: Iteration: 158000. Loss: 3.4760701656341553. Accuracy: 18.7\n",
            "Training: Iteration: 158500. Loss: 3.407555341720581. Accuracy: 23.808\n",
            "Testing: Iteration: 158500. Loss: 3.407555341720581. Accuracy: 18.66\n",
            "Epoch:  203\n",
            "Training: Iteration: 159000. Loss: 3.2463109493255615. Accuracy: 23.85\n",
            "Testing: Iteration: 159000. Loss: 3.2463109493255615. Accuracy: 18.81\n",
            "Training: Iteration: 159500. Loss: 3.047281503677368. Accuracy: 23.88\n",
            "Testing: Iteration: 159500. Loss: 3.047281503677368. Accuracy: 18.71\n",
            "Epoch:  204\n",
            "Training: Iteration: 160000. Loss: 3.428412675857544. Accuracy: 23.888\n",
            "Testing: Iteration: 160000. Loss: 3.428412675857544. Accuracy: 18.7\n",
            "Epoch:  205\n",
            "Training: Iteration: 160500. Loss: 3.4370899200439453. Accuracy: 23.9\n",
            "Testing: Iteration: 160500. Loss: 3.4370899200439453. Accuracy: 18.74\n",
            "Training: Iteration: 161000. Loss: 3.790210485458374. Accuracy: 23.886\n",
            "Testing: Iteration: 161000. Loss: 3.790210485458374. Accuracy: 18.66\n",
            "Epoch:  206\n",
            "Training: Iteration: 161500. Loss: 3.502511501312256. Accuracy: 23.88\n",
            "Testing: Iteration: 161500. Loss: 3.502511501312256. Accuracy: 18.7\n",
            "Epoch:  207\n",
            "Training: Iteration: 162000. Loss: 3.203260898590088. Accuracy: 23.96\n",
            "Testing: Iteration: 162000. Loss: 3.203260898590088. Accuracy: 18.68\n",
            "Training: Iteration: 162500. Loss: 3.461566925048828. Accuracy: 23.924\n",
            "Testing: Iteration: 162500. Loss: 3.461566925048828. Accuracy: 18.78\n",
            "Epoch:  208\n",
            "Training: Iteration: 163000. Loss: 3.3666632175445557. Accuracy: 23.874\n",
            "Testing: Iteration: 163000. Loss: 3.3666632175445557. Accuracy: 18.67\n",
            "Epoch:  209\n",
            "Training: Iteration: 163500. Loss: 3.664574384689331. Accuracy: 23.952\n",
            "Testing: Iteration: 163500. Loss: 3.664574384689331. Accuracy: 18.71\n",
            "Training: Iteration: 164000. Loss: 3.296898365020752. Accuracy: 23.898\n",
            "Testing: Iteration: 164000. Loss: 3.296898365020752. Accuracy: 18.7\n",
            "Epoch:  210\n",
            "Training: Iteration: 164500. Loss: 3.1184635162353516. Accuracy: 23.964\n",
            "Testing: Iteration: 164500. Loss: 3.1184635162353516. Accuracy: 18.77\n",
            "Training: Iteration: 165000. Loss: 3.3011298179626465. Accuracy: 23.976\n",
            "Testing: Iteration: 165000. Loss: 3.3011298179626465. Accuracy: 18.68\n",
            "Epoch:  211\n",
            "Training: Iteration: 165500. Loss: 3.463667154312134. Accuracy: 23.952\n",
            "Testing: Iteration: 165500. Loss: 3.463667154312134. Accuracy: 18.74\n",
            "Epoch:  212\n",
            "Training: Iteration: 166000. Loss: 3.3621110916137695. Accuracy: 23.988\n",
            "Testing: Iteration: 166000. Loss: 3.3621110916137695. Accuracy: 18.68\n",
            "Training: Iteration: 166500. Loss: 3.027449131011963. Accuracy: 23.978\n",
            "Testing: Iteration: 166500. Loss: 3.027449131011963. Accuracy: 18.72\n",
            "Epoch:  213\n",
            "Training: Iteration: 167000. Loss: 3.5036706924438477. Accuracy: 23.966\n",
            "Testing: Iteration: 167000. Loss: 3.5036706924438477. Accuracy: 18.77\n",
            "Epoch:  214\n",
            "Training: Iteration: 167500. Loss: 3.060161828994751. Accuracy: 24.016\n",
            "Testing: Iteration: 167500. Loss: 3.060161828994751. Accuracy: 18.62\n",
            "Training: Iteration: 168000. Loss: 3.581991195678711. Accuracy: 23.98\n",
            "Testing: Iteration: 168000. Loss: 3.581991195678711. Accuracy: 18.73\n",
            "Epoch:  215\n",
            "Training: Iteration: 168500. Loss: 3.2313754558563232. Accuracy: 24.02\n",
            "Testing: Iteration: 168500. Loss: 3.2313754558563232. Accuracy: 18.84\n",
            "Epoch:  216\n",
            "Training: Iteration: 169000. Loss: 3.251504421234131. Accuracy: 24.036\n",
            "Testing: Iteration: 169000. Loss: 3.251504421234131. Accuracy: 18.6\n",
            "Training: Iteration: 169500. Loss: 3.095027208328247. Accuracy: 23.958\n",
            "Testing: Iteration: 169500. Loss: 3.095027208328247. Accuracy: 18.76\n",
            "Epoch:  217\n",
            "Training: Iteration: 170000. Loss: 3.5715267658233643. Accuracy: 23.998\n",
            "Testing: Iteration: 170000. Loss: 3.5715267658233643. Accuracy: 18.88\n",
            "Epoch:  218\n",
            "Training: Iteration: 170500. Loss: 3.0394299030303955. Accuracy: 24.02\n",
            "Testing: Iteration: 170500. Loss: 3.0394299030303955. Accuracy: 18.73\n",
            "Training: Iteration: 171000. Loss: 3.4383058547973633. Accuracy: 24.008\n",
            "Testing: Iteration: 171000. Loss: 3.4383058547973633. Accuracy: 18.78\n",
            "Epoch:  219\n",
            "Training: Iteration: 171500. Loss: 3.1310505867004395. Accuracy: 24.036\n",
            "Testing: Iteration: 171500. Loss: 3.1310505867004395. Accuracy: 18.85\n",
            "Training: Iteration: 172000. Loss: 3.762542486190796. Accuracy: 24.052\n",
            "Testing: Iteration: 172000. Loss: 3.762542486190796. Accuracy: 18.82\n",
            "Epoch:  220\n",
            "Training: Iteration: 172500. Loss: 3.4479432106018066. Accuracy: 24.06\n",
            "Testing: Iteration: 172500. Loss: 3.4479432106018066. Accuracy: 18.77\n",
            "Epoch:  221\n",
            "Training: Iteration: 173000. Loss: 3.2333872318267822. Accuracy: 24.104\n",
            "Testing: Iteration: 173000. Loss: 3.2333872318267822. Accuracy: 18.8\n",
            "Training: Iteration: 173500. Loss: 3.542004346847534. Accuracy: 24.042\n",
            "Testing: Iteration: 173500. Loss: 3.542004346847534. Accuracy: 18.82\n",
            "Epoch:  222\n",
            "Training: Iteration: 174000. Loss: 3.4212701320648193. Accuracy: 24.034\n",
            "Testing: Iteration: 174000. Loss: 3.4212701320648193. Accuracy: 18.79\n",
            "Epoch:  223\n",
            "Training: Iteration: 174500. Loss: 3.1621904373168945. Accuracy: 24.132\n",
            "Testing: Iteration: 174500. Loss: 3.1621904373168945. Accuracy: 18.65\n",
            "Training: Iteration: 175000. Loss: 3.3890693187713623. Accuracy: 24.04\n",
            "Testing: Iteration: 175000. Loss: 3.3890693187713623. Accuracy: 18.86\n",
            "Epoch:  224\n",
            "Training: Iteration: 175500. Loss: 3.3699958324432373. Accuracy: 24.086\n",
            "Testing: Iteration: 175500. Loss: 3.3699958324432373. Accuracy: 18.72\n",
            "Epoch:  225\n",
            "Training: Iteration: 176000. Loss: 3.2563061714172363. Accuracy: 24.154\n",
            "Testing: Iteration: 176000. Loss: 3.2563061714172363. Accuracy: 18.7\n",
            "Training: Iteration: 176500. Loss: 3.3817737102508545. Accuracy: 24.084\n",
            "Testing: Iteration: 176500. Loss: 3.3817737102508545. Accuracy: 18.79\n",
            "Epoch:  226\n",
            "Training: Iteration: 177000. Loss: 3.410247802734375. Accuracy: 24.1\n",
            "Testing: Iteration: 177000. Loss: 3.410247802734375. Accuracy: 18.86\n",
            "Training: Iteration: 177500. Loss: 3.4603829383850098. Accuracy: 24.108\n",
            "Testing: Iteration: 177500. Loss: 3.4603829383850098. Accuracy: 18.78\n",
            "Epoch:  227\n",
            "Training: Iteration: 178000. Loss: 3.245398998260498. Accuracy: 24.098\n",
            "Testing: Iteration: 178000. Loss: 3.245398998260498. Accuracy: 18.87\n",
            "Epoch:  228\n",
            "Training: Iteration: 178500. Loss: 3.6996517181396484. Accuracy: 24.17\n",
            "Testing: Iteration: 178500. Loss: 3.6996517181396484. Accuracy: 18.77\n",
            "Training: Iteration: 179000. Loss: 2.9750680923461914. Accuracy: 24.092\n",
            "Testing: Iteration: 179000. Loss: 2.9750680923461914. Accuracy: 18.73\n",
            "Epoch:  229\n",
            "Training: Iteration: 179500. Loss: 3.38996958732605. Accuracy: 24.118\n",
            "Testing: Iteration: 179500. Loss: 3.38996958732605. Accuracy: 18.78\n",
            "Epoch:  230\n",
            "Training: Iteration: 180000. Loss: 3.594073534011841. Accuracy: 24.178\n",
            "Testing: Iteration: 180000. Loss: 3.594073534011841. Accuracy: 18.72\n",
            "Training: Iteration: 180500. Loss: 3.4121809005737305. Accuracy: 24.13\n",
            "Testing: Iteration: 180500. Loss: 3.4121809005737305. Accuracy: 18.82\n",
            "Epoch:  231\n",
            "Training: Iteration: 181000. Loss: 3.486851692199707. Accuracy: 24.152\n",
            "Testing: Iteration: 181000. Loss: 3.486851692199707. Accuracy: 18.84\n",
            "Epoch:  232\n",
            "Training: Iteration: 181500. Loss: 3.475679636001587. Accuracy: 24.158\n",
            "Testing: Iteration: 181500. Loss: 3.475679636001587. Accuracy: 18.77\n",
            "Training: Iteration: 182000. Loss: 3.292658805847168. Accuracy: 24.118\n",
            "Testing: Iteration: 182000. Loss: 3.292658805847168. Accuracy: 18.77\n",
            "Epoch:  233\n",
            "Training: Iteration: 182500. Loss: 3.5128350257873535. Accuracy: 24.14\n",
            "Testing: Iteration: 182500. Loss: 3.5128350257873535. Accuracy: 18.85\n",
            "Epoch:  234\n",
            "Training: Iteration: 183000. Loss: 3.422191619873047. Accuracy: 24.206\n",
            "Testing: Iteration: 183000. Loss: 3.422191619873047. Accuracy: 18.79\n",
            "Training: Iteration: 183500. Loss: 3.7424380779266357. Accuracy: 24.164\n",
            "Testing: Iteration: 183500. Loss: 3.7424380779266357. Accuracy: 18.81\n",
            "Epoch:  235\n",
            "Training: Iteration: 184000. Loss: 3.328019142150879. Accuracy: 24.176\n",
            "Testing: Iteration: 184000. Loss: 3.328019142150879. Accuracy: 18.79\n",
            "Training: Iteration: 184500. Loss: 3.361860990524292. Accuracy: 24.138\n",
            "Testing: Iteration: 184500. Loss: 3.361860990524292. Accuracy: 18.88\n",
            "Epoch:  236\n",
            "Training: Iteration: 185000. Loss: 3.3779118061065674. Accuracy: 24.206\n",
            "Testing: Iteration: 185000. Loss: 3.3779118061065674. Accuracy: 18.83\n",
            "Epoch:  237\n",
            "Training: Iteration: 185500. Loss: 3.0235440731048584. Accuracy: 24.24\n",
            "Testing: Iteration: 185500. Loss: 3.0235440731048584. Accuracy: 18.79\n",
            "Training: Iteration: 186000. Loss: 3.386368989944458. Accuracy: 24.172\n",
            "Testing: Iteration: 186000. Loss: 3.386368989944458. Accuracy: 18.78\n",
            "Epoch:  238\n",
            "Training: Iteration: 186500. Loss: 3.3894147872924805. Accuracy: 24.21\n",
            "Testing: Iteration: 186500. Loss: 3.3894147872924805. Accuracy: 18.88\n",
            "Epoch:  239\n",
            "Training: Iteration: 187000. Loss: 3.764538526535034. Accuracy: 24.266\n",
            "Testing: Iteration: 187000. Loss: 3.764538526535034. Accuracy: 18.78\n",
            "Training: Iteration: 187500. Loss: 3.4284989833831787. Accuracy: 24.21\n",
            "Testing: Iteration: 187500. Loss: 3.4284989833831787. Accuracy: 18.85\n",
            "Epoch:  240\n",
            "Training: Iteration: 188000. Loss: 3.2944893836975098. Accuracy: 24.17\n",
            "Testing: Iteration: 188000. Loss: 3.2944893836975098. Accuracy: 18.83\n",
            "Epoch:  241\n",
            "Training: Iteration: 188500. Loss: 3.3855509757995605. Accuracy: 24.262\n",
            "Testing: Iteration: 188500. Loss: 3.3855509757995605. Accuracy: 18.93\n",
            "Training: Iteration: 189000. Loss: 3.530857801437378. Accuracy: 24.21\n",
            "Testing: Iteration: 189000. Loss: 3.530857801437378. Accuracy: 18.83\n",
            "Epoch:  242\n",
            "Training: Iteration: 189500. Loss: 3.091942310333252. Accuracy: 24.246\n",
            "Testing: Iteration: 189500. Loss: 3.091942310333252. Accuracy: 18.86\n",
            "Training: Iteration: 190000. Loss: 3.3400392532348633. Accuracy: 24.258\n",
            "Testing: Iteration: 190000. Loss: 3.3400392532348633. Accuracy: 18.84\n",
            "Epoch:  243\n",
            "Training: Iteration: 190500. Loss: 3.341015100479126. Accuracy: 24.244\n",
            "Testing: Iteration: 190500. Loss: 3.341015100479126. Accuracy: 18.85\n",
            "Epoch:  244\n",
            "Training: Iteration: 191000. Loss: 2.9381704330444336. Accuracy: 24.294\n",
            "Testing: Iteration: 191000. Loss: 2.9381704330444336. Accuracy: 18.83\n",
            "Training: Iteration: 191500. Loss: 3.4086949825286865. Accuracy: 24.254\n",
            "Testing: Iteration: 191500. Loss: 3.4086949825286865. Accuracy: 18.85\n",
            "Epoch:  245\n",
            "Training: Iteration: 192000. Loss: 3.3977465629577637. Accuracy: 24.246\n",
            "Testing: Iteration: 192000. Loss: 3.3977465629577637. Accuracy: 18.86\n",
            "Epoch:  246\n",
            "Training: Iteration: 192500. Loss: 3.5090198516845703. Accuracy: 24.332\n",
            "Testing: Iteration: 192500. Loss: 3.5090198516845703. Accuracy: 18.78\n",
            "Training: Iteration: 193000. Loss: 3.7240023612976074. Accuracy: 24.268\n",
            "Testing: Iteration: 193000. Loss: 3.7240023612976074. Accuracy: 18.9\n",
            "Epoch:  247\n",
            "Training: Iteration: 193500. Loss: 3.1647510528564453. Accuracy: 24.222\n",
            "Testing: Iteration: 193500. Loss: 3.1647510528564453. Accuracy: 18.76\n",
            "Epoch:  248\n",
            "Training: Iteration: 194000. Loss: 3.066781520843506. Accuracy: 24.288\n",
            "Testing: Iteration: 194000. Loss: 3.066781520843506. Accuracy: 18.83\n",
            "Training: Iteration: 194500. Loss: 3.327648162841797. Accuracy: 24.3\n",
            "Testing: Iteration: 194500. Loss: 3.327648162841797. Accuracy: 18.84\n",
            "Epoch:  249\n",
            "Training: Iteration: 195000. Loss: 3.516378879547119. Accuracy: 24.26\n",
            "Testing: Iteration: 195000. Loss: 3.516378879547119. Accuracy: 18.91\n",
            "Training: Iteration: 195500. Loss: 3.32757568359375. Accuracy: 24.334\n",
            "Testing: Iteration: 195500. Loss: 3.32757568359375. Accuracy: 18.87\n",
            "Epoch:  250\n",
            "Training: Iteration: 196000. Loss: 3.3562769889831543. Accuracy: 24.298\n",
            "Testing: Iteration: 196000. Loss: 3.3562769889831543. Accuracy: 18.9\n",
            "Epoch:  251\n",
            "Training: Iteration: 196500. Loss: 3.0476603507995605. Accuracy: 24.31\n",
            "Testing: Iteration: 196500. Loss: 3.0476603507995605. Accuracy: 18.82\n",
            "Training: Iteration: 197000. Loss: 2.907968759536743. Accuracy: 24.326\n",
            "Testing: Iteration: 197000. Loss: 2.907968759536743. Accuracy: 18.96\n",
            "Epoch:  252\n",
            "Training: Iteration: 197500. Loss: 3.431267023086548. Accuracy: 24.32\n",
            "Testing: Iteration: 197500. Loss: 3.431267023086548. Accuracy: 18.85\n",
            "Epoch:  253\n",
            "Training: Iteration: 198000. Loss: 3.4789605140686035. Accuracy: 24.354\n",
            "Testing: Iteration: 198000. Loss: 3.4789605140686035. Accuracy: 18.86\n",
            "Training: Iteration: 198500. Loss: 3.208094835281372. Accuracy: 24.324\n",
            "Testing: Iteration: 198500. Loss: 3.208094835281372. Accuracy: 18.86\n",
            "Epoch:  254\n",
            "Training: Iteration: 199000. Loss: 3.35661244392395. Accuracy: 24.348\n",
            "Testing: Iteration: 199000. Loss: 3.35661244392395. Accuracy: 18.81\n",
            "Epoch:  255\n",
            "Training: Iteration: 199500. Loss: 3.1653504371643066. Accuracy: 24.36\n",
            "Testing: Iteration: 199500. Loss: 3.1653504371643066. Accuracy: 18.78\n",
            "Training: Iteration: 200000. Loss: 3.190304756164551. Accuracy: 24.352\n",
            "Testing: Iteration: 200000. Loss: 3.190304756164551. Accuracy: 18.99\n",
            "Epoch:  256\n",
            "Training: Iteration: 200500. Loss: 3.5780012607574463. Accuracy: 24.352\n",
            "Testing: Iteration: 200500. Loss: 3.5780012607574463. Accuracy: 18.84\n",
            "Epoch:  257\n",
            "Training: Iteration: 201000. Loss: 3.3672189712524414. Accuracy: 24.374\n",
            "Testing: Iteration: 201000. Loss: 3.3672189712524414. Accuracy: 18.9\n",
            "Training: Iteration: 201500. Loss: 3.592902421951294. Accuracy: 24.342\n",
            "Testing: Iteration: 201500. Loss: 3.592902421951294. Accuracy: 18.9\n",
            "Epoch:  258\n",
            "Training: Iteration: 202000. Loss: 3.3888564109802246. Accuracy: 24.382\n",
            "Testing: Iteration: 202000. Loss: 3.3888564109802246. Accuracy: 18.97\n",
            "Training: Iteration: 202500. Loss: 3.177901029586792. Accuracy: 24.364\n",
            "Testing: Iteration: 202500. Loss: 3.177901029586792. Accuracy: 19.0\n",
            "Epoch:  259\n",
            "Training: Iteration: 203000. Loss: 3.494107246398926. Accuracy: 24.364\n",
            "Testing: Iteration: 203000. Loss: 3.494107246398926. Accuracy: 18.86\n",
            "Epoch:  260\n",
            "Training: Iteration: 203500. Loss: 3.2110342979431152. Accuracy: 24.424\n",
            "Testing: Iteration: 203500. Loss: 3.2110342979431152. Accuracy: 18.86\n",
            "Training: Iteration: 204000. Loss: 3.3794538974761963. Accuracy: 24.386\n",
            "Testing: Iteration: 204000. Loss: 3.3794538974761963. Accuracy: 18.99\n",
            "Epoch:  261\n",
            "Training: Iteration: 204500. Loss: 3.298102378845215. Accuracy: 24.322\n",
            "Testing: Iteration: 204500. Loss: 3.298102378845215. Accuracy: 18.77\n",
            "Epoch:  262\n",
            "Training: Iteration: 205000. Loss: 3.3922176361083984. Accuracy: 24.414\n",
            "Testing: Iteration: 205000. Loss: 3.3922176361083984. Accuracy: 18.75\n",
            "Training: Iteration: 205500. Loss: 3.147152900695801. Accuracy: 24.37\n",
            "Testing: Iteration: 205500. Loss: 3.147152900695801. Accuracy: 18.85\n",
            "Epoch:  263\n",
            "Training: Iteration: 206000. Loss: 3.0044031143188477. Accuracy: 24.354\n",
            "Testing: Iteration: 206000. Loss: 3.0044031143188477. Accuracy: 18.77\n",
            "Epoch:  264\n",
            "Training: Iteration: 206500. Loss: 3.0765984058380127. Accuracy: 24.426\n",
            "Testing: Iteration: 206500. Loss: 3.0765984058380127. Accuracy: 18.9\n",
            "Training: Iteration: 207000. Loss: 3.2551486492156982. Accuracy: 24.384\n",
            "Testing: Iteration: 207000. Loss: 3.2551486492156982. Accuracy: 18.96\n",
            "Epoch:  265\n",
            "Training: Iteration: 207500. Loss: 3.337953805923462. Accuracy: 24.428\n",
            "Testing: Iteration: 207500. Loss: 3.337953805923462. Accuracy: 18.88\n",
            "Training: Iteration: 208000. Loss: 3.4628891944885254. Accuracy: 24.416\n",
            "Testing: Iteration: 208000. Loss: 3.4628891944885254. Accuracy: 18.91\n",
            "Epoch:  266\n",
            "Training: Iteration: 208500. Loss: 3.412217140197754. Accuracy: 24.418\n",
            "Testing: Iteration: 208500. Loss: 3.412217140197754. Accuracy: 18.87\n",
            "Epoch:  267\n",
            "Training: Iteration: 209000. Loss: 3.0860626697540283. Accuracy: 24.43\n",
            "Testing: Iteration: 209000. Loss: 3.0860626697540283. Accuracy: 18.87\n",
            "Training: Iteration: 209500. Loss: 3.5439157485961914. Accuracy: 24.448\n",
            "Testing: Iteration: 209500. Loss: 3.5439157485961914. Accuracy: 18.91\n",
            "Epoch:  268\n",
            "Training: Iteration: 210000. Loss: 3.405972957611084. Accuracy: 24.436\n",
            "Testing: Iteration: 210000. Loss: 3.405972957611084. Accuracy: 18.84\n",
            "Epoch:  269\n",
            "Training: Iteration: 210500. Loss: 3.171323776245117. Accuracy: 24.438\n",
            "Testing: Iteration: 210500. Loss: 3.171323776245117. Accuracy: 18.83\n",
            "Training: Iteration: 211000. Loss: 3.0470311641693115. Accuracy: 24.442\n",
            "Testing: Iteration: 211000. Loss: 3.0470311641693115. Accuracy: 18.92\n",
            "Epoch:  270\n",
            "Training: Iteration: 211500. Loss: 2.9398581981658936. Accuracy: 24.402\n",
            "Testing: Iteration: 211500. Loss: 2.9398581981658936. Accuracy: 18.87\n",
            "Epoch:  271\n",
            "Training: Iteration: 212000. Loss: 3.161283254623413. Accuracy: 24.48\n",
            "Testing: Iteration: 212000. Loss: 3.161283254623413. Accuracy: 18.83\n",
            "Training: Iteration: 212500. Loss: 3.4083075523376465. Accuracy: 24.432\n",
            "Testing: Iteration: 212500. Loss: 3.4083075523376465. Accuracy: 18.91\n",
            "Epoch:  272\n",
            "Training: Iteration: 213000. Loss: 3.2567875385284424. Accuracy: 24.452\n",
            "Testing: Iteration: 213000. Loss: 3.2567875385284424. Accuracy: 18.83\n",
            "Epoch:  273\n",
            "Training: Iteration: 213500. Loss: 3.2332146167755127. Accuracy: 24.486\n",
            "Testing: Iteration: 213500. Loss: 3.2332146167755127. Accuracy: 18.91\n",
            "Training: Iteration: 214000. Loss: 3.437751054763794. Accuracy: 24.432\n",
            "Testing: Iteration: 214000. Loss: 3.437751054763794. Accuracy: 18.91\n",
            "Epoch:  274\n",
            "Training: Iteration: 214500. Loss: 3.1422791481018066. Accuracy: 24.444\n",
            "Testing: Iteration: 214500. Loss: 3.1422791481018066. Accuracy: 18.91\n",
            "Training: Iteration: 215000. Loss: 3.294814348220825. Accuracy: 24.482\n",
            "Testing: Iteration: 215000. Loss: 3.294814348220825. Accuracy: 19.0\n",
            "Epoch:  275\n",
            "Training: Iteration: 215500. Loss: 3.00431752204895. Accuracy: 24.44\n",
            "Testing: Iteration: 215500. Loss: 3.00431752204895. Accuracy: 18.86\n",
            "Epoch:  276\n",
            "Training: Iteration: 216000. Loss: 3.249175786972046. Accuracy: 24.488\n",
            "Testing: Iteration: 216000. Loss: 3.249175786972046. Accuracy: 18.83\n",
            "Training: Iteration: 216500. Loss: 3.58408784866333. Accuracy: 24.462\n",
            "Testing: Iteration: 216500. Loss: 3.58408784866333. Accuracy: 18.94\n",
            "Epoch:  277\n",
            "Training: Iteration: 217000. Loss: 3.020240545272827. Accuracy: 24.42\n",
            "Testing: Iteration: 217000. Loss: 3.020240545272827. Accuracy: 18.82\n",
            "Epoch:  278\n",
            "Training: Iteration: 217500. Loss: 3.432157278060913. Accuracy: 24.55\n",
            "Testing: Iteration: 217500. Loss: 3.432157278060913. Accuracy: 18.9\n",
            "Training: Iteration: 218000. Loss: 3.3938210010528564. Accuracy: 24.516\n",
            "Testing: Iteration: 218000. Loss: 3.3938210010528564. Accuracy: 18.92\n",
            "Epoch:  279\n",
            "Training: Iteration: 218500. Loss: 3.3285300731658936. Accuracy: 24.422\n",
            "Testing: Iteration: 218500. Loss: 3.3285300731658936. Accuracy: 18.84\n",
            "Epoch:  280\n",
            "Training: Iteration: 219000. Loss: 3.1299610137939453. Accuracy: 24.518\n",
            "Testing: Iteration: 219000. Loss: 3.1299610137939453. Accuracy: 18.91\n",
            "Training: Iteration: 219500. Loss: 3.4299607276916504. Accuracy: 24.524\n",
            "Testing: Iteration: 219500. Loss: 3.4299607276916504. Accuracy: 18.82\n",
            "Epoch:  281\n",
            "Training: Iteration: 220000. Loss: 3.1568737030029297. Accuracy: 24.484\n",
            "Testing: Iteration: 220000. Loss: 3.1568737030029297. Accuracy: 18.94\n",
            "Training: Iteration: 220500. Loss: 3.8034486770629883. Accuracy: 24.484\n",
            "Testing: Iteration: 220500. Loss: 3.8034486770629883. Accuracy: 18.91\n",
            "Epoch:  282\n",
            "Training: Iteration: 221000. Loss: 3.6440045833587646. Accuracy: 24.522\n",
            "Testing: Iteration: 221000. Loss: 3.6440045833587646. Accuracy: 18.8\n",
            "Epoch:  283\n",
            "Training: Iteration: 221500. Loss: 3.1707937717437744. Accuracy: 24.498\n",
            "Testing: Iteration: 221500. Loss: 3.1707937717437744. Accuracy: 18.94\n",
            "Training: Iteration: 222000. Loss: 3.5664029121398926. Accuracy: 24.512\n",
            "Testing: Iteration: 222000. Loss: 3.5664029121398926. Accuracy: 18.96\n",
            "Epoch:  284\n",
            "Training: Iteration: 222500. Loss: 3.374887704849243. Accuracy: 24.504\n",
            "Testing: Iteration: 222500. Loss: 3.374887704849243. Accuracy: 18.82\n",
            "Epoch:  285\n",
            "Training: Iteration: 223000. Loss: 3.3448646068573. Accuracy: 24.536\n",
            "Testing: Iteration: 223000. Loss: 3.3448646068573. Accuracy: 18.92\n",
            "Training: Iteration: 223500. Loss: 3.418470621109009. Accuracy: 24.514\n",
            "Testing: Iteration: 223500. Loss: 3.418470621109009. Accuracy: 18.99\n",
            "Epoch:  286\n",
            "Training: Iteration: 224000. Loss: 3.562798023223877. Accuracy: 24.502\n",
            "Testing: Iteration: 224000. Loss: 3.562798023223877. Accuracy: 18.83\n",
            "Epoch:  287\n",
            "Training: Iteration: 224500. Loss: 3.1823623180389404. Accuracy: 24.512\n",
            "Testing: Iteration: 224500. Loss: 3.1823623180389404. Accuracy: 18.87\n",
            "Training: Iteration: 225000. Loss: 3.124397039413452. Accuracy: 24.566\n",
            "Testing: Iteration: 225000. Loss: 3.124397039413452. Accuracy: 18.9\n",
            "Epoch:  288\n",
            "Training: Iteration: 225500. Loss: 3.358525514602661. Accuracy: 24.53\n",
            "Testing: Iteration: 225500. Loss: 3.358525514602661. Accuracy: 18.87\n",
            "Epoch:  289\n",
            "Training: Iteration: 226000. Loss: 3.3157591819763184. Accuracy: 24.558\n",
            "Testing: Iteration: 226000. Loss: 3.3157591819763184. Accuracy: 18.93\n",
            "Training: Iteration: 226500. Loss: 3.228273630142212. Accuracy: 24.534\n",
            "Testing: Iteration: 226500. Loss: 3.228273630142212. Accuracy: 18.92\n",
            "Epoch:  290\n",
            "Training: Iteration: 227000. Loss: 3.659383535385132. Accuracy: 24.492\n",
            "Testing: Iteration: 227000. Loss: 3.659383535385132. Accuracy: 18.94\n",
            "Training: Iteration: 227500. Loss: 3.289186954498291. Accuracy: 24.532\n",
            "Testing: Iteration: 227500. Loss: 3.289186954498291. Accuracy: 19.03\n",
            "Epoch:  291\n",
            "Training: Iteration: 228000. Loss: 3.1693551540374756. Accuracy: 24.57\n",
            "Testing: Iteration: 228000. Loss: 3.1693551540374756. Accuracy: 18.86\n",
            "Epoch:  292\n",
            "Training: Iteration: 228500. Loss: 3.5942001342773438. Accuracy: 24.542\n",
            "Testing: Iteration: 228500. Loss: 3.5942001342773438. Accuracy: 18.95\n",
            "Training: Iteration: 229000. Loss: 3.281942367553711. Accuracy: 24.528\n",
            "Testing: Iteration: 229000. Loss: 3.281942367553711. Accuracy: 18.95\n",
            "Epoch:  293\n",
            "Training: Iteration: 229500. Loss: 3.208277463912964. Accuracy: 24.542\n",
            "Testing: Iteration: 229500. Loss: 3.208277463912964. Accuracy: 18.83\n",
            "Epoch:  294\n",
            "Training: Iteration: 230000. Loss: 3.597804307937622. Accuracy: 24.652\n",
            "Testing: Iteration: 230000. Loss: 3.597804307937622. Accuracy: 18.9\n",
            "Training: Iteration: 230500. Loss: 3.6670444011688232. Accuracy: 24.588\n",
            "Testing: Iteration: 230500. Loss: 3.6670444011688232. Accuracy: 18.92\n",
            "Epoch:  295\n",
            "Training: Iteration: 231000. Loss: 3.3498034477233887. Accuracy: 24.548\n",
            "Testing: Iteration: 231000. Loss: 3.3498034477233887. Accuracy: 18.93\n",
            "Epoch:  296\n",
            "Training: Iteration: 231500. Loss: 3.4945523738861084. Accuracy: 24.616\n",
            "Testing: Iteration: 231500. Loss: 3.4945523738861084. Accuracy: 18.89\n",
            "Training: Iteration: 232000. Loss: 3.625267267227173. Accuracy: 24.586\n",
            "Testing: Iteration: 232000. Loss: 3.625267267227173. Accuracy: 18.82\n",
            "Epoch:  297\n",
            "Training: Iteration: 232500. Loss: 2.872253894805908. Accuracy: 24.546\n",
            "Testing: Iteration: 232500. Loss: 2.872253894805908. Accuracy: 19.0\n",
            "Training: Iteration: 233000. Loss: 3.2671279907226562. Accuracy: 24.562\n",
            "Testing: Iteration: 233000. Loss: 3.2671279907226562. Accuracy: 19.0\n",
            "Epoch:  298\n",
            "Training: Iteration: 233500. Loss: 3.099952220916748. Accuracy: 24.566\n",
            "Testing: Iteration: 233500. Loss: 3.099952220916748. Accuracy: 18.84\n",
            "Epoch:  299\n",
            "Training: Iteration: 234000. Loss: 3.521350383758545. Accuracy: 24.598\n",
            "Testing: Iteration: 234000. Loss: 3.521350383758545. Accuracy: 18.96\n",
            "Training: Iteration: 234500. Loss: 2.827352523803711. Accuracy: 24.574\n",
            "Testing: Iteration: 234500. Loss: 2.827352523803711. Accuracy: 18.94\n",
            "Epoch:  300\n",
            "Training: Iteration: 235000. Loss: 3.8686985969543457. Accuracy: 24.526\n",
            "Testing: Iteration: 235000. Loss: 3.8686985969543457. Accuracy: 18.88\n",
            "Epoch:  301\n",
            "Training: Iteration: 235500. Loss: 2.7622954845428467. Accuracy: 24.618\n",
            "Testing: Iteration: 235500. Loss: 2.7622954845428467. Accuracy: 18.91\n",
            "Training: Iteration: 236000. Loss: 3.5366077423095703. Accuracy: 24.596\n",
            "Testing: Iteration: 236000. Loss: 3.5366077423095703. Accuracy: 19.0\n",
            "Epoch:  302\n",
            "Training: Iteration: 236500. Loss: 3.4263734817504883. Accuracy: 24.532\n",
            "Testing: Iteration: 236500. Loss: 3.4263734817504883. Accuracy: 18.89\n",
            "Epoch:  303\n",
            "Training: Iteration: 237000. Loss: 3.0268678665161133. Accuracy: 24.646\n",
            "Testing: Iteration: 237000. Loss: 3.0268678665161133. Accuracy: 18.99\n",
            "Training: Iteration: 237500. Loss: 3.244189977645874. Accuracy: 24.598\n",
            "Testing: Iteration: 237500. Loss: 3.244189977645874. Accuracy: 18.97\n",
            "Epoch:  304\n",
            "Training: Iteration: 238000. Loss: 3.2136542797088623. Accuracy: 24.584\n",
            "Testing: Iteration: 238000. Loss: 3.2136542797088623. Accuracy: 18.92\n",
            "Training: Iteration: 238500. Loss: 3.663054943084717. Accuracy: 24.666\n",
            "Testing: Iteration: 238500. Loss: 3.663054943084717. Accuracy: 19.03\n",
            "Epoch:  305\n",
            "Training: Iteration: 239000. Loss: 3.2179017066955566. Accuracy: 24.618\n",
            "Testing: Iteration: 239000. Loss: 3.2179017066955566. Accuracy: 18.88\n",
            "Epoch:  306\n",
            "Training: Iteration: 239500. Loss: 3.388007640838623. Accuracy: 24.61\n",
            "Testing: Iteration: 239500. Loss: 3.388007640838623. Accuracy: 19.0\n",
            "Training: Iteration: 240000. Loss: 3.183117151260376. Accuracy: 24.624\n",
            "Testing: Iteration: 240000. Loss: 3.183117151260376. Accuracy: 19.01\n",
            "Epoch:  307\n",
            "Training: Iteration: 240500. Loss: 3.195251703262329. Accuracy: 24.616\n",
            "Testing: Iteration: 240500. Loss: 3.195251703262329. Accuracy: 18.94\n",
            "Epoch:  308\n",
            "Training: Iteration: 241000. Loss: 3.221452236175537. Accuracy: 24.622\n",
            "Testing: Iteration: 241000. Loss: 3.221452236175537. Accuracy: 19.03\n",
            "Training: Iteration: 241500. Loss: 3.5275046825408936. Accuracy: 24.598\n",
            "Testing: Iteration: 241500. Loss: 3.5275046825408936. Accuracy: 18.93\n",
            "Epoch:  309\n",
            "Training: Iteration: 242000. Loss: 3.4188737869262695. Accuracy: 24.582\n",
            "Testing: Iteration: 242000. Loss: 3.4188737869262695. Accuracy: 18.92\n",
            "Epoch:  310\n",
            "Training: Iteration: 242500. Loss: 3.2450661659240723. Accuracy: 24.72\n",
            "Testing: Iteration: 242500. Loss: 3.2450661659240723. Accuracy: 19.0\n",
            "Training: Iteration: 243000. Loss: 3.220093250274658. Accuracy: 24.65\n",
            "Testing: Iteration: 243000. Loss: 3.220093250274658. Accuracy: 18.91\n",
            "Epoch:  311\n",
            "Training: Iteration: 243500. Loss: 2.7881078720092773. Accuracy: 24.63\n",
            "Testing: Iteration: 243500. Loss: 2.7881078720092773. Accuracy: 18.91\n",
            "Epoch:  312\n",
            "Training: Iteration: 244000. Loss: 3.168811082839966. Accuracy: 24.702\n",
            "Testing: Iteration: 244000. Loss: 3.168811082839966. Accuracy: 18.98\n",
            "Training: Iteration: 244500. Loss: 3.4005305767059326. Accuracy: 24.68\n",
            "Testing: Iteration: 244500. Loss: 3.4005305767059326. Accuracy: 18.96\n",
            "Epoch:  313\n",
            "Training: Iteration: 245000. Loss: 3.4922547340393066. Accuracy: 24.66\n",
            "Testing: Iteration: 245000. Loss: 3.4922547340393066. Accuracy: 19.07\n",
            "Training: Iteration: 245500. Loss: 3.5000433921813965. Accuracy: 24.658\n",
            "Testing: Iteration: 245500. Loss: 3.5000433921813965. Accuracy: 19.12\n",
            "Epoch:  314\n",
            "Training: Iteration: 246000. Loss: 3.5005757808685303. Accuracy: 24.674\n",
            "Testing: Iteration: 246000. Loss: 3.5005757808685303. Accuracy: 18.87\n",
            "Epoch:  315\n",
            "Training: Iteration: 246500. Loss: 3.34004545211792. Accuracy: 24.646\n",
            "Testing: Iteration: 246500. Loss: 3.34004545211792. Accuracy: 19.07\n",
            "Training: Iteration: 247000. Loss: 3.243654251098633. Accuracy: 24.658\n",
            "Testing: Iteration: 247000. Loss: 3.243654251098633. Accuracy: 18.96\n",
            "Epoch:  316\n",
            "Training: Iteration: 247500. Loss: 3.5813748836517334. Accuracy: 24.64\n",
            "Testing: Iteration: 247500. Loss: 3.5813748836517334. Accuracy: 19.03\n",
            "Epoch:  317\n",
            "Training: Iteration: 248000. Loss: 3.2062859535217285. Accuracy: 24.724\n",
            "Testing: Iteration: 248000. Loss: 3.2062859535217285. Accuracy: 19.08\n",
            "Training: Iteration: 248500. Loss: 3.601853609085083. Accuracy: 24.7\n",
            "Testing: Iteration: 248500. Loss: 3.601853609085083. Accuracy: 19.03\n",
            "Epoch:  318\n",
            "Training: Iteration: 249000. Loss: 3.458284616470337. Accuracy: 24.62\n",
            "Testing: Iteration: 249000. Loss: 3.458284616470337. Accuracy: 18.92\n",
            "Epoch:  319\n",
            "Training: Iteration: 249500. Loss: 3.4232265949249268. Accuracy: 24.746\n",
            "Testing: Iteration: 249500. Loss: 3.4232265949249268. Accuracy: 19.03\n",
            "Training: Iteration: 250000. Loss: 3.3773086071014404. Accuracy: 24.7\n",
            "Testing: Iteration: 250000. Loss: 3.3773086071014404. Accuracy: 18.99\n",
            "Epoch:  320\n",
            "Training: Iteration: 250500. Loss: 3.137619972229004. Accuracy: 24.704\n",
            "Testing: Iteration: 250500. Loss: 3.137619972229004. Accuracy: 19.04\n",
            "Training: Iteration: 251000. Loss: 3.033759117126465. Accuracy: 24.754\n",
            "Testing: Iteration: 251000. Loss: 3.033759117126465. Accuracy: 19.04\n",
            "Epoch:  321\n",
            "Training: Iteration: 251500. Loss: 2.976478338241577. Accuracy: 24.712\n",
            "Testing: Iteration: 251500. Loss: 2.976478338241577. Accuracy: 18.88\n",
            "Epoch:  322\n",
            "Training: Iteration: 252000. Loss: 3.11183500289917. Accuracy: 24.712\n",
            "Testing: Iteration: 252000. Loss: 3.11183500289917. Accuracy: 19.07\n",
            "Training: Iteration: 252500. Loss: 3.550142765045166. Accuracy: 24.732\n",
            "Testing: Iteration: 252500. Loss: 3.550142765045166. Accuracy: 19.07\n",
            "Epoch:  323\n",
            "Training: Iteration: 253000. Loss: 3.2317142486572266. Accuracy: 24.69\n",
            "Testing: Iteration: 253000. Loss: 3.2317142486572266. Accuracy: 18.98\n",
            "Epoch:  324\n",
            "Training: Iteration: 253500. Loss: 3.2920002937316895. Accuracy: 24.748\n",
            "Testing: Iteration: 253500. Loss: 3.2920002937316895. Accuracy: 19.13\n",
            "Training: Iteration: 254000. Loss: 3.526374578475952. Accuracy: 24.7\n",
            "Testing: Iteration: 254000. Loss: 3.526374578475952. Accuracy: 18.92\n",
            "Epoch:  325\n",
            "Training: Iteration: 254500. Loss: 3.5146491527557373. Accuracy: 24.696\n",
            "Testing: Iteration: 254500. Loss: 3.5146491527557373. Accuracy: 18.9\n",
            "Epoch:  326\n",
            "Training: Iteration: 255000. Loss: 3.328294038772583. Accuracy: 24.784\n",
            "Testing: Iteration: 255000. Loss: 3.328294038772583. Accuracy: 19.04\n",
            "Training: Iteration: 255500. Loss: 2.9072844982147217. Accuracy: 24.728\n",
            "Testing: Iteration: 255500. Loss: 2.9072844982147217. Accuracy: 18.99\n",
            "Epoch:  327\n",
            "Training: Iteration: 256000. Loss: 3.2028322219848633. Accuracy: 24.738\n",
            "Testing: Iteration: 256000. Loss: 3.2028322219848633. Accuracy: 18.93\n",
            "Epoch:  328\n",
            "Training: Iteration: 256500. Loss: 3.201059103012085. Accuracy: 24.806\n",
            "Testing: Iteration: 256500. Loss: 3.201059103012085. Accuracy: 19.06\n",
            "Training: Iteration: 257000. Loss: 3.6059234142303467. Accuracy: 24.766\n",
            "Testing: Iteration: 257000. Loss: 3.6059234142303467. Accuracy: 18.96\n",
            "Epoch:  329\n",
            "Training: Iteration: 257500. Loss: 3.189652442932129. Accuracy: 24.728\n",
            "Testing: Iteration: 257500. Loss: 3.189652442932129. Accuracy: 19.06\n",
            "Training: Iteration: 258000. Loss: 3.0946450233459473. Accuracy: 24.79\n",
            "Testing: Iteration: 258000. Loss: 3.0946450233459473. Accuracy: 19.1\n",
            "Epoch:  330\n",
            "Training: Iteration: 258500. Loss: 3.6220364570617676. Accuracy: 24.788\n",
            "Testing: Iteration: 258500. Loss: 3.6220364570617676. Accuracy: 18.95\n",
            "Epoch:  331\n",
            "Training: Iteration: 259000. Loss: 3.3313348293304443. Accuracy: 24.818\n",
            "Testing: Iteration: 259000. Loss: 3.3313348293304443. Accuracy: 19.11\n",
            "Training: Iteration: 259500. Loss: 3.2072670459747314. Accuracy: 24.756\n",
            "Testing: Iteration: 259500. Loss: 3.2072670459747314. Accuracy: 18.91\n",
            "Epoch:  332\n",
            "Training: Iteration: 260000. Loss: 3.197439670562744. Accuracy: 24.744\n",
            "Testing: Iteration: 260000. Loss: 3.197439670562744. Accuracy: 19.01\n",
            "Epoch:  333\n",
            "Training: Iteration: 260500. Loss: 3.477313756942749. Accuracy: 24.854\n",
            "Testing: Iteration: 260500. Loss: 3.477313756942749. Accuracy: 19.15\n",
            "Training: Iteration: 261000. Loss: 3.2643115520477295. Accuracy: 24.744\n",
            "Testing: Iteration: 261000. Loss: 3.2643115520477295. Accuracy: 19.0\n",
            "Epoch:  334\n",
            "Training: Iteration: 261500. Loss: 3.4191973209381104. Accuracy: 24.784\n",
            "Testing: Iteration: 261500. Loss: 3.4191973209381104. Accuracy: 18.93\n",
            "Epoch:  335\n",
            "Training: Iteration: 262000. Loss: 3.493726968765259. Accuracy: 24.82\n",
            "Testing: Iteration: 262000. Loss: 3.493726968765259. Accuracy: 19.0\n",
            "Training: Iteration: 262500. Loss: 3.337139129638672. Accuracy: 24.786\n",
            "Testing: Iteration: 262500. Loss: 3.337139129638672. Accuracy: 18.98\n",
            "Epoch:  336\n",
            "Training: Iteration: 263000. Loss: 3.304248571395874. Accuracy: 24.798\n",
            "Testing: Iteration: 263000. Loss: 3.304248571395874. Accuracy: 19.14\n",
            "Training: Iteration: 263500. Loss: 3.5792317390441895. Accuracy: 24.822\n",
            "Testing: Iteration: 263500. Loss: 3.5792317390441895. Accuracy: 19.04\n",
            "Epoch:  337\n",
            "Training: Iteration: 264000. Loss: 3.1975371837615967. Accuracy: 24.808\n",
            "Testing: Iteration: 264000. Loss: 3.1975371837615967. Accuracy: 18.95\n",
            "Epoch:  338\n",
            "Training: Iteration: 264500. Loss: 3.2418131828308105. Accuracy: 24.856\n",
            "Testing: Iteration: 264500. Loss: 3.2418131828308105. Accuracy: 19.13\n",
            "Training: Iteration: 265000. Loss: 3.4870166778564453. Accuracy: 24.83\n",
            "Testing: Iteration: 265000. Loss: 3.4870166778564453. Accuracy: 19.03\n",
            "Epoch:  339\n",
            "Training: Iteration: 265500. Loss: 3.259483814239502. Accuracy: 24.776\n",
            "Testing: Iteration: 265500. Loss: 3.259483814239502. Accuracy: 19.06\n",
            "Epoch:  340\n",
            "Training: Iteration: 266000. Loss: 3.0163865089416504. Accuracy: 24.87\n",
            "Testing: Iteration: 266000. Loss: 3.0163865089416504. Accuracy: 19.14\n",
            "Training: Iteration: 266500. Loss: 3.2500600814819336. Accuracy: 24.822\n",
            "Testing: Iteration: 266500. Loss: 3.2500600814819336. Accuracy: 19.03\n",
            "Epoch:  341\n",
            "Training: Iteration: 267000. Loss: 3.540734052658081. Accuracy: 24.77\n",
            "Testing: Iteration: 267000. Loss: 3.540734052658081. Accuracy: 18.97\n",
            "Epoch:  342\n",
            "Training: Iteration: 267500. Loss: 3.4073357582092285. Accuracy: 24.872\n",
            "Testing: Iteration: 267500. Loss: 3.4073357582092285. Accuracy: 19.02\n",
            "Training: Iteration: 268000. Loss: 3.438455104827881. Accuracy: 24.81\n",
            "Testing: Iteration: 268000. Loss: 3.438455104827881. Accuracy: 19.09\n",
            "Epoch:  343\n",
            "Training: Iteration: 268500. Loss: 3.470369338989258. Accuracy: 24.822\n",
            "Testing: Iteration: 268500. Loss: 3.470369338989258. Accuracy: 19.01\n",
            "Training: Iteration: 269000. Loss: 3.351655960083008. Accuracy: 24.9\n",
            "Testing: Iteration: 269000. Loss: 3.351655960083008. Accuracy: 19.09\n",
            "Epoch:  344\n",
            "Training: Iteration: 269500. Loss: 3.095677375793457. Accuracy: 24.866\n",
            "Testing: Iteration: 269500. Loss: 3.095677375793457. Accuracy: 18.94\n",
            "Epoch:  345\n",
            "Training: Iteration: 270000. Loss: 2.8375487327575684. Accuracy: 24.832\n",
            "Testing: Iteration: 270000. Loss: 2.8375487327575684. Accuracy: 19.08\n",
            "Training: Iteration: 270500. Loss: 3.3076674938201904. Accuracy: 24.9\n",
            "Testing: Iteration: 270500. Loss: 3.3076674938201904. Accuracy: 19.01\n",
            "Epoch:  346\n",
            "Training: Iteration: 271000. Loss: 3.3538501262664795. Accuracy: 24.86\n",
            "Testing: Iteration: 271000. Loss: 3.3538501262664795. Accuracy: 19.01\n",
            "Epoch:  347\n",
            "Training: Iteration: 271500. Loss: 3.572950601577759. Accuracy: 24.87\n",
            "Testing: Iteration: 271500. Loss: 3.572950601577759. Accuracy: 19.05\n",
            "Training: Iteration: 272000. Loss: 3.256911516189575. Accuracy: 24.874\n",
            "Testing: Iteration: 272000. Loss: 3.256911516189575. Accuracy: 18.98\n",
            "Epoch:  348\n",
            "Training: Iteration: 272500. Loss: 3.4180798530578613. Accuracy: 24.842\n",
            "Testing: Iteration: 272500. Loss: 3.4180798530578613. Accuracy: 19.01\n",
            "Epoch:  349\n",
            "Training: Iteration: 273000. Loss: 3.3700053691864014. Accuracy: 24.914\n",
            "Testing: Iteration: 273000. Loss: 3.3700053691864014. Accuracy: 19.13\n",
            "Training: Iteration: 273500. Loss: 2.995310068130493. Accuracy: 24.86\n",
            "Testing: Iteration: 273500. Loss: 2.995310068130493. Accuracy: 18.98\n",
            "Epoch:  350\n",
            "Training: Iteration: 274000. Loss: 3.4965837001800537. Accuracy: 24.858\n",
            "Testing: Iteration: 274000. Loss: 3.4965837001800537. Accuracy: 18.98\n",
            "Epoch:  351\n",
            "Training: Iteration: 274500. Loss: 3.0902960300445557. Accuracy: 24.892\n",
            "Testing: Iteration: 274500. Loss: 3.0902960300445557. Accuracy: 19.03\n",
            "Training: Iteration: 275000. Loss: 2.970525026321411. Accuracy: 24.868\n",
            "Testing: Iteration: 275000. Loss: 2.970525026321411. Accuracy: 18.89\n",
            "Epoch:  352\n",
            "Training: Iteration: 275500. Loss: 3.3169236183166504. Accuracy: 24.94\n",
            "Testing: Iteration: 275500. Loss: 3.3169236183166504. Accuracy: 19.16\n",
            "Training: Iteration: 276000. Loss: 3.047163724899292. Accuracy: 24.886\n",
            "Testing: Iteration: 276000. Loss: 3.047163724899292. Accuracy: 19.07\n",
            "Epoch:  353\n",
            "Training: Iteration: 276500. Loss: 3.3469555377960205. Accuracy: 24.884\n",
            "Testing: Iteration: 276500. Loss: 3.3469555377960205. Accuracy: 18.92\n",
            "Epoch:  354\n",
            "Training: Iteration: 277000. Loss: 2.9429681301116943. Accuracy: 24.95\n",
            "Testing: Iteration: 277000. Loss: 2.9429681301116943. Accuracy: 19.12\n",
            "Training: Iteration: 277500. Loss: 3.428689479827881. Accuracy: 24.884\n",
            "Testing: Iteration: 277500. Loss: 3.428689479827881. Accuracy: 19.01\n",
            "Epoch:  355\n",
            "Training: Iteration: 278000. Loss: 3.2899084091186523. Accuracy: 24.89\n",
            "Testing: Iteration: 278000. Loss: 3.2899084091186523. Accuracy: 19.1\n",
            "Epoch:  356\n",
            "Training: Iteration: 278500. Loss: 3.1762869358062744. Accuracy: 24.942\n",
            "Testing: Iteration: 278500. Loss: 3.1762869358062744. Accuracy: 19.2\n",
            "Training: Iteration: 279000. Loss: 3.4114739894866943. Accuracy: 24.924\n",
            "Testing: Iteration: 279000. Loss: 3.4114739894866943. Accuracy: 19.03\n",
            "Epoch:  357\n",
            "Training: Iteration: 279500. Loss: 2.9671385288238525. Accuracy: 24.854\n",
            "Testing: Iteration: 279500. Loss: 2.9671385288238525. Accuracy: 19.0\n",
            "Epoch:  358\n",
            "Training: Iteration: 280000. Loss: 3.114715099334717. Accuracy: 24.948\n",
            "Testing: Iteration: 280000. Loss: 3.114715099334717. Accuracy: 19.02\n",
            "Training: Iteration: 280500. Loss: 3.194031238555908. Accuracy: 24.916\n",
            "Testing: Iteration: 280500. Loss: 3.194031238555908. Accuracy: 18.98\n",
            "Epoch:  359\n",
            "Training: Iteration: 281000. Loss: 3.148799419403076. Accuracy: 24.962\n",
            "Testing: Iteration: 281000. Loss: 3.148799419403076. Accuracy: 19.09\n",
            "Training: Iteration: 281500. Loss: 3.0355336666107178. Accuracy: 25.014\n",
            "Testing: Iteration: 281500. Loss: 3.0355336666107178. Accuracy: 19.11\n",
            "Epoch:  360\n",
            "Training: Iteration: 282000. Loss: 3.2897584438323975. Accuracy: 24.954\n",
            "Testing: Iteration: 282000. Loss: 3.2897584438323975. Accuracy: 18.97\n",
            "Epoch:  361\n",
            "Training: Iteration: 282500. Loss: 3.4157063961029053. Accuracy: 24.91\n",
            "Testing: Iteration: 282500. Loss: 3.4157063961029053. Accuracy: 19.15\n",
            "Training: Iteration: 283000. Loss: 3.293745756149292. Accuracy: 24.934\n",
            "Testing: Iteration: 283000. Loss: 3.293745756149292. Accuracy: 19.07\n",
            "Epoch:  362\n",
            "Training: Iteration: 283500. Loss: 3.131681203842163. Accuracy: 24.902\n",
            "Testing: Iteration: 283500. Loss: 3.131681203842163. Accuracy: 19.02\n",
            "Epoch:  363\n",
            "Training: Iteration: 284000. Loss: 3.3535335063934326. Accuracy: 24.992\n",
            "Testing: Iteration: 284000. Loss: 3.3535335063934326. Accuracy: 19.19\n",
            "Training: Iteration: 284500. Loss: 3.1100735664367676. Accuracy: 24.938\n",
            "Testing: Iteration: 284500. Loss: 3.1100735664367676. Accuracy: 18.97\n",
            "Epoch:  364\n",
            "Training: Iteration: 285000. Loss: 3.1732137203216553. Accuracy: 24.92\n",
            "Testing: Iteration: 285000. Loss: 3.1732137203216553. Accuracy: 18.97\n",
            "Epoch:  365\n",
            "Training: Iteration: 285500. Loss: 3.7189903259277344. Accuracy: 24.97\n",
            "Testing: Iteration: 285500. Loss: 3.7189903259277344. Accuracy: 19.05\n",
            "Training: Iteration: 286000. Loss: 3.7674241065979004. Accuracy: 24.932\n",
            "Testing: Iteration: 286000. Loss: 3.7674241065979004. Accuracy: 19.04\n",
            "Epoch:  366\n",
            "Training: Iteration: 286500. Loss: 3.1213979721069336. Accuracy: 24.918\n",
            "Testing: Iteration: 286500. Loss: 3.1213979721069336. Accuracy: 19.01\n",
            "Epoch:  367\n",
            "Training: Iteration: 287000. Loss: 3.1534807682037354. Accuracy: 25.044\n",
            "Testing: Iteration: 287000. Loss: 3.1534807682037354. Accuracy: 18.98\n",
            "Training: Iteration: 287500. Loss: 2.9918057918548584. Accuracy: 24.904\n",
            "Testing: Iteration: 287500. Loss: 2.9918057918548584. Accuracy: 19.04\n",
            "Epoch:  368\n",
            "Training: Iteration: 288000. Loss: 3.41485595703125. Accuracy: 24.944\n",
            "Testing: Iteration: 288000. Loss: 3.41485595703125. Accuracy: 19.07\n",
            "Training: Iteration: 288500. Loss: 3.2361485958099365. Accuracy: 24.966\n",
            "Testing: Iteration: 288500. Loss: 3.2361485958099365. Accuracy: 19.14\n",
            "Epoch:  369\n",
            "Training: Iteration: 289000. Loss: 3.37249493598938. Accuracy: 24.974\n",
            "Testing: Iteration: 289000. Loss: 3.37249493598938. Accuracy: 19.01\n",
            "Epoch:  370\n",
            "Training: Iteration: 289500. Loss: 3.427546501159668. Accuracy: 25.006\n",
            "Testing: Iteration: 289500. Loss: 3.427546501159668. Accuracy: 19.11\n",
            "Training: Iteration: 290000. Loss: 3.09504771232605. Accuracy: 24.94\n",
            "Testing: Iteration: 290000. Loss: 3.09504771232605. Accuracy: 18.99\n",
            "Epoch:  371\n",
            "Training: Iteration: 290500. Loss: 3.64501690864563. Accuracy: 24.982\n",
            "Testing: Iteration: 290500. Loss: 3.64501690864563. Accuracy: 19.02\n",
            "Epoch:  372\n",
            "Training: Iteration: 291000. Loss: 3.4111509323120117. Accuracy: 25.01\n",
            "Testing: Iteration: 291000. Loss: 3.4111509323120117. Accuracy: 19.12\n",
            "Training: Iteration: 291500. Loss: 3.4637291431427. Accuracy: 24.962\n",
            "Testing: Iteration: 291500. Loss: 3.4637291431427. Accuracy: 18.92\n",
            "Epoch:  373\n",
            "Training: Iteration: 292000. Loss: 3.331273317337036. Accuracy: 24.974\n",
            "Testing: Iteration: 292000. Loss: 3.331273317337036. Accuracy: 18.97\n",
            "Epoch:  374\n",
            "Training: Iteration: 292500. Loss: 3.2753167152404785. Accuracy: 25.004\n",
            "Testing: Iteration: 292500. Loss: 3.2753167152404785. Accuracy: 18.98\n",
            "Training: Iteration: 293000. Loss: 3.1791207790374756. Accuracy: 24.93\n",
            "Testing: Iteration: 293000. Loss: 3.1791207790374756. Accuracy: 19.03\n",
            "Epoch:  375\n",
            "Training: Iteration: 293500. Loss: 3.117839813232422. Accuracy: 24.98\n",
            "Testing: Iteration: 293500. Loss: 3.117839813232422. Accuracy: 19.05\n",
            "Training: Iteration: 294000. Loss: 2.921863555908203. Accuracy: 25.016\n",
            "Testing: Iteration: 294000. Loss: 2.921863555908203. Accuracy: 19.03\n",
            "Epoch:  376\n",
            "Training: Iteration: 294500. Loss: 3.3974480628967285. Accuracy: 24.968\n",
            "Testing: Iteration: 294500. Loss: 3.3974480628967285. Accuracy: 19.01\n",
            "Epoch:  377\n",
            "Training: Iteration: 295000. Loss: 3.091181993484497. Accuracy: 25.042\n",
            "Testing: Iteration: 295000. Loss: 3.091181993484497. Accuracy: 19.2\n",
            "Training: Iteration: 295500. Loss: 3.6163525581359863. Accuracy: 25.012\n",
            "Testing: Iteration: 295500. Loss: 3.6163525581359863. Accuracy: 19.02\n",
            "Epoch:  378\n",
            "Training: Iteration: 296000. Loss: 3.190535306930542. Accuracy: 24.968\n",
            "Testing: Iteration: 296000. Loss: 3.190535306930542. Accuracy: 19.1\n",
            "Epoch:  379\n",
            "Training: Iteration: 296500. Loss: 3.2792446613311768. Accuracy: 25.004\n",
            "Testing: Iteration: 296500. Loss: 3.2792446613311768. Accuracy: 19.14\n",
            "Training: Iteration: 297000. Loss: 3.317654609680176. Accuracy: 24.994\n",
            "Testing: Iteration: 297000. Loss: 3.317654609680176. Accuracy: 18.98\n",
            "Epoch:  380\n",
            "Training: Iteration: 297500. Loss: 3.354088068008423. Accuracy: 24.974\n",
            "Testing: Iteration: 297500. Loss: 3.354088068008423. Accuracy: 18.97\n",
            "Epoch:  381\n",
            "Training: Iteration: 298000. Loss: 3.5267655849456787. Accuracy: 25.024\n",
            "Testing: Iteration: 298000. Loss: 3.5267655849456787. Accuracy: 19.03\n",
            "Training: Iteration: 298500. Loss: 3.1096572875976562. Accuracy: 24.988\n",
            "Testing: Iteration: 298500. Loss: 3.1096572875976562. Accuracy: 19.01\n",
            "Epoch:  382\n",
            "Training: Iteration: 299000. Loss: 3.1533994674682617. Accuracy: 25.008\n",
            "Testing: Iteration: 299000. Loss: 3.1533994674682617. Accuracy: 18.98\n",
            "Training: Iteration: 299500. Loss: 3.754208564758301. Accuracy: 25.04\n",
            "Testing: Iteration: 299500. Loss: 3.754208564758301. Accuracy: 18.95\n",
            "Epoch:  383\n",
            "Training: Iteration: 300000. Loss: 3.3603427410125732. Accuracy: 24.98\n",
            "Testing: Iteration: 300000. Loss: 3.3603427410125732. Accuracy: 18.96\n",
            "Epoch:  384\n",
            "Training: Iteration: 300500. Loss: 3.243887186050415. Accuracy: 25.042\n",
            "Testing: Iteration: 300500. Loss: 3.243887186050415. Accuracy: 19.03\n",
            "Training: Iteration: 301000. Loss: 3.2128851413726807. Accuracy: 25.048\n",
            "Testing: Iteration: 301000. Loss: 3.2128851413726807. Accuracy: 19.07\n",
            "Epoch:  385\n",
            "Training: Iteration: 301500. Loss: 3.23759126663208. Accuracy: 25.03\n",
            "Testing: Iteration: 301500. Loss: 3.23759126663208. Accuracy: 19.02\n",
            "Epoch:  386\n",
            "Training: Iteration: 302000. Loss: 3.2852916717529297. Accuracy: 25.026\n",
            "Testing: Iteration: 302000. Loss: 3.2852916717529297. Accuracy: 19.05\n",
            "Training: Iteration: 302500. Loss: 3.1280436515808105. Accuracy: 25.036\n",
            "Testing: Iteration: 302500. Loss: 3.1280436515808105. Accuracy: 19.02\n",
            "Epoch:  387\n",
            "Training: Iteration: 303000. Loss: 3.290701389312744. Accuracy: 25.04\n",
            "Testing: Iteration: 303000. Loss: 3.290701389312744. Accuracy: 19.01\n",
            "Epoch:  388\n",
            "Training: Iteration: 303500. Loss: 3.3003013134002686. Accuracy: 25.092\n",
            "Testing: Iteration: 303500. Loss: 3.3003013134002686. Accuracy: 19.05\n",
            "Training: Iteration: 304000. Loss: 3.390089988708496. Accuracy: 25.04\n",
            "Testing: Iteration: 304000. Loss: 3.390089988708496. Accuracy: 19.0\n",
            "Epoch:  389\n",
            "Training: Iteration: 304500. Loss: 3.026928663253784. Accuracy: 24.99\n",
            "Testing: Iteration: 304500. Loss: 3.026928663253784. Accuracy: 18.96\n",
            "Epoch:  390\n",
            "Training: Iteration: 305000. Loss: 3.231121063232422. Accuracy: 25.078\n",
            "Testing: Iteration: 305000. Loss: 3.231121063232422. Accuracy: 18.94\n",
            "Training: Iteration: 305500. Loss: 3.2294068336486816. Accuracy: 25.022\n",
            "Testing: Iteration: 305500. Loss: 3.2294068336486816. Accuracy: 18.98\n",
            "Epoch:  391\n",
            "Training: Iteration: 306000. Loss: 3.1775808334350586. Accuracy: 25.052\n",
            "Testing: Iteration: 306000. Loss: 3.1775808334350586. Accuracy: 19.13\n",
            "Training: Iteration: 306500. Loss: 3.8624165058135986. Accuracy: 25.04\n",
            "Testing: Iteration: 306500. Loss: 3.8624165058135986. Accuracy: 19.04\n",
            "Epoch:  392\n",
            "Training: Iteration: 307000. Loss: 3.0384562015533447. Accuracy: 25.05\n",
            "Testing: Iteration: 307000. Loss: 3.0384562015533447. Accuracy: 18.98\n",
            "Epoch:  393\n",
            "Training: Iteration: 307500. Loss: 2.940216541290283. Accuracy: 25.08\n",
            "Testing: Iteration: 307500. Loss: 2.940216541290283. Accuracy: 19.14\n",
            "Training: Iteration: 308000. Loss: 3.242703437805176. Accuracy: 25.072\n",
            "Testing: Iteration: 308000. Loss: 3.242703437805176. Accuracy: 18.99\n",
            "Epoch:  394\n",
            "Training: Iteration: 308500. Loss: 3.544544219970703. Accuracy: 25.042\n",
            "Testing: Iteration: 308500. Loss: 3.544544219970703. Accuracy: 19.09\n",
            "Epoch:  395\n",
            "Training: Iteration: 309000. Loss: 3.132086992263794. Accuracy: 25.102\n",
            "Testing: Iteration: 309000. Loss: 3.132086992263794. Accuracy: 19.13\n",
            "Training: Iteration: 309500. Loss: 3.1682517528533936. Accuracy: 25.032\n",
            "Testing: Iteration: 309500. Loss: 3.1682517528533936. Accuracy: 18.92\n",
            "Epoch:  396\n",
            "Training: Iteration: 310000. Loss: 2.958876848220825. Accuracy: 25.0\n",
            "Testing: Iteration: 310000. Loss: 2.958876848220825. Accuracy: 18.98\n",
            "Epoch:  397\n",
            "Training: Iteration: 310500. Loss: 3.4549055099487305. Accuracy: 25.102\n",
            "Testing: Iteration: 310500. Loss: 3.4549055099487305. Accuracy: 19.02\n",
            "Training: Iteration: 311000. Loss: 3.577470064163208. Accuracy: 25.042\n",
            "Testing: Iteration: 311000. Loss: 3.577470064163208. Accuracy: 19.02\n",
            "Epoch:  398\n",
            "Training: Iteration: 311500. Loss: 3.043785810470581. Accuracy: 25.05\n",
            "Testing: Iteration: 311500. Loss: 3.043785810470581. Accuracy: 19.0\n",
            "Training: Iteration: 312000. Loss: 3.306469202041626. Accuracy: 25.116\n",
            "Testing: Iteration: 312000. Loss: 3.306469202041626. Accuracy: 19.05\n",
            "Epoch:  399\n",
            "Training: Iteration: 312500. Loss: 2.9195590019226074. Accuracy: 25.072\n",
            "Testing: Iteration: 312500. Loss: 2.9195590019226074. Accuracy: 18.96\n",
            "Epoch:  400\n",
            "Training: Iteration: 313000. Loss: 3.4055979251861572. Accuracy: 25.082\n",
            "Testing: Iteration: 313000. Loss: 3.4055979251861572. Accuracy: 19.05\n",
            "Training: Iteration: 313500. Loss: 3.507417678833008. Accuracy: 25.07\n",
            "Testing: Iteration: 313500. Loss: 3.507417678833008. Accuracy: 18.99\n",
            "Epoch:  401\n",
            "Training: Iteration: 314000. Loss: 3.4379730224609375. Accuracy: 25.086\n",
            "Testing: Iteration: 314000. Loss: 3.4379730224609375. Accuracy: 19.03\n",
            "Epoch:  402\n",
            "Training: Iteration: 314500. Loss: 3.3490586280822754. Accuracy: 25.126\n",
            "Testing: Iteration: 314500. Loss: 3.3490586280822754. Accuracy: 19.06\n",
            "Training: Iteration: 315000. Loss: 2.905329942703247. Accuracy: 25.104\n",
            "Testing: Iteration: 315000. Loss: 2.905329942703247. Accuracy: 18.88\n",
            "Epoch:  403\n",
            "Training: Iteration: 315500. Loss: 3.2764570713043213. Accuracy: 25.022\n",
            "Testing: Iteration: 315500. Loss: 3.2764570713043213. Accuracy: 18.98\n",
            "Epoch:  404\n",
            "Training: Iteration: 316000. Loss: 3.1931214332580566. Accuracy: 25.12\n",
            "Testing: Iteration: 316000. Loss: 3.1931214332580566. Accuracy: 19.06\n",
            "Training: Iteration: 316500. Loss: 3.316091537475586. Accuracy: 25.076\n",
            "Testing: Iteration: 316500. Loss: 3.316091537475586. Accuracy: 18.98\n",
            "Epoch:  405\n",
            "Training: Iteration: 317000. Loss: 3.4560444355010986. Accuracy: 25.062\n",
            "Testing: Iteration: 317000. Loss: 3.4560444355010986. Accuracy: 18.96\n",
            "Epoch:  406\n",
            "Training: Iteration: 317500. Loss: 3.0719759464263916. Accuracy: 25.152\n",
            "Testing: Iteration: 317500. Loss: 3.0719759464263916. Accuracy: 18.99\n",
            "Training: Iteration: 318000. Loss: 3.4282703399658203. Accuracy: 25.09\n",
            "Testing: Iteration: 318000. Loss: 3.4282703399658203. Accuracy: 19.03\n",
            "Epoch:  407\n",
            "Training: Iteration: 318500. Loss: 3.4260692596435547. Accuracy: 25.062\n",
            "Testing: Iteration: 318500. Loss: 3.4260692596435547. Accuracy: 18.99\n",
            "Training: Iteration: 319000. Loss: 3.2890281677246094. Accuracy: 25.066\n",
            "Testing: Iteration: 319000. Loss: 3.2890281677246094. Accuracy: 19.07\n",
            "Epoch:  408\n",
            "Training: Iteration: 319500. Loss: 3.391017436981201. Accuracy: 25.084\n",
            "Testing: Iteration: 319500. Loss: 3.391017436981201. Accuracy: 18.94\n",
            "Epoch:  409\n",
            "Training: Iteration: 320000. Loss: 3.029719591140747. Accuracy: 25.144\n",
            "Testing: Iteration: 320000. Loss: 3.029719591140747. Accuracy: 19.0\n",
            "Training: Iteration: 320500. Loss: 3.309863567352295. Accuracy: 25.068\n",
            "Testing: Iteration: 320500. Loss: 3.309863567352295. Accuracy: 18.93\n",
            "Epoch:  410\n",
            "Training: Iteration: 321000. Loss: 3.2038142681121826. Accuracy: 25.106\n",
            "Testing: Iteration: 321000. Loss: 3.2038142681121826. Accuracy: 18.99\n",
            "Epoch:  411\n",
            "Training: Iteration: 321500. Loss: 3.562304973602295. Accuracy: 25.12\n",
            "Testing: Iteration: 321500. Loss: 3.562304973602295. Accuracy: 19.1\n",
            "Training: Iteration: 322000. Loss: 3.1007072925567627. Accuracy: 25.09\n",
            "Testing: Iteration: 322000. Loss: 3.1007072925567627. Accuracy: 18.94\n",
            "Epoch:  412\n",
            "Training: Iteration: 322500. Loss: 3.748189687728882. Accuracy: 25.084\n",
            "Testing: Iteration: 322500. Loss: 3.748189687728882. Accuracy: 18.95\n",
            "Epoch:  413\n",
            "Training: Iteration: 323000. Loss: 3.143179178237915. Accuracy: 25.136\n",
            "Testing: Iteration: 323000. Loss: 3.143179178237915. Accuracy: 18.98\n",
            "Training: Iteration: 323500. Loss: 3.0430972576141357. Accuracy: 25.084\n",
            "Testing: Iteration: 323500. Loss: 3.0430972576141357. Accuracy: 18.99\n",
            "Epoch:  414\n",
            "Training: Iteration: 324000. Loss: 3.6989269256591797. Accuracy: 25.112\n",
            "Testing: Iteration: 324000. Loss: 3.6989269256591797. Accuracy: 18.99\n",
            "Training: Iteration: 324500. Loss: 3.5625500679016113. Accuracy: 25.126\n",
            "Testing: Iteration: 324500. Loss: 3.5625500679016113. Accuracy: 18.96\n",
            "Epoch:  415\n",
            "Training: Iteration: 325000. Loss: 3.1818909645080566. Accuracy: 25.116\n",
            "Testing: Iteration: 325000. Loss: 3.1818909645080566. Accuracy: 18.97\n",
            "Epoch:  416\n",
            "Training: Iteration: 325500. Loss: 3.585675001144409. Accuracy: 25.152\n",
            "Testing: Iteration: 325500. Loss: 3.585675001144409. Accuracy: 19.1\n",
            "Training: Iteration: 326000. Loss: 3.075430154800415. Accuracy: 25.12\n",
            "Testing: Iteration: 326000. Loss: 3.075430154800415. Accuracy: 19.03\n",
            "Epoch:  417\n",
            "Training: Iteration: 326500. Loss: 3.855073928833008. Accuracy: 25.12\n",
            "Testing: Iteration: 326500. Loss: 3.855073928833008. Accuracy: 19.05\n",
            "Epoch:  418\n",
            "Training: Iteration: 327000. Loss: 3.2593419551849365. Accuracy: 25.164\n",
            "Testing: Iteration: 327000. Loss: 3.2593419551849365. Accuracy: 19.05\n",
            "Training: Iteration: 327500. Loss: 3.023629665374756. Accuracy: 25.102\n",
            "Testing: Iteration: 327500. Loss: 3.023629665374756. Accuracy: 19.02\n",
            "Epoch:  419\n",
            "Training: Iteration: 328000. Loss: 3.536576747894287. Accuracy: 25.076\n",
            "Testing: Iteration: 328000. Loss: 3.536576747894287. Accuracy: 19.03\n",
            "Epoch:  420\n",
            "Training: Iteration: 328500. Loss: 3.0573084354400635. Accuracy: 25.164\n",
            "Testing: Iteration: 328500. Loss: 3.0573084354400635. Accuracy: 19.05\n",
            "Training: Iteration: 329000. Loss: 3.2914483547210693. Accuracy: 25.126\n",
            "Testing: Iteration: 329000. Loss: 3.2914483547210693. Accuracy: 18.97\n",
            "Epoch:  421\n",
            "Training: Iteration: 329500. Loss: 3.440479278564453. Accuracy: 25.112\n",
            "Testing: Iteration: 329500. Loss: 3.440479278564453. Accuracy: 18.95\n",
            "Training: Iteration: 330000. Loss: 3.302354335784912. Accuracy: 25.184\n",
            "Testing: Iteration: 330000. Loss: 3.302354335784912. Accuracy: 18.98\n",
            "Epoch:  422\n",
            "Training: Iteration: 330500. Loss: 3.4442174434661865. Accuracy: 25.134\n",
            "Testing: Iteration: 330500. Loss: 3.4442174434661865. Accuracy: 18.98\n",
            "Epoch:  423\n",
            "Training: Iteration: 331000. Loss: 3.5269179344177246. Accuracy: 25.142\n",
            "Testing: Iteration: 331000. Loss: 3.5269179344177246. Accuracy: 19.0\n",
            "Training: Iteration: 331500. Loss: 3.325914144515991. Accuracy: 25.16\n",
            "Testing: Iteration: 331500. Loss: 3.325914144515991. Accuracy: 19.01\n",
            "Epoch:  424\n",
            "Training: Iteration: 332000. Loss: 3.7182207107543945. Accuracy: 25.14\n",
            "Testing: Iteration: 332000. Loss: 3.7182207107543945. Accuracy: 18.98\n",
            "Epoch:  425\n",
            "Training: Iteration: 332500. Loss: 3.4307456016540527. Accuracy: 25.194\n",
            "Testing: Iteration: 332500. Loss: 3.4307456016540527. Accuracy: 18.97\n",
            "Training: Iteration: 333000. Loss: 3.3410420417785645. Accuracy: 25.146\n",
            "Testing: Iteration: 333000. Loss: 3.3410420417785645. Accuracy: 19.0\n",
            "Epoch:  426\n",
            "Training: Iteration: 333500. Loss: 3.293332576751709. Accuracy: 25.132\n",
            "Testing: Iteration: 333500. Loss: 3.293332576751709. Accuracy: 18.99\n",
            "Epoch:  427\n",
            "Training: Iteration: 334000. Loss: 3.3826966285705566. Accuracy: 25.178\n",
            "Testing: Iteration: 334000. Loss: 3.3826966285705566. Accuracy: 19.03\n",
            "Training: Iteration: 334500. Loss: 3.1713173389434814. Accuracy: 25.192\n",
            "Testing: Iteration: 334500. Loss: 3.1713173389434814. Accuracy: 19.01\n",
            "Epoch:  428\n",
            "Training: Iteration: 335000. Loss: 3.594921588897705. Accuracy: 25.132\n",
            "Testing: Iteration: 335000. Loss: 3.594921588897705. Accuracy: 18.91\n",
            "Epoch:  429\n",
            "Training: Iteration: 335500. Loss: 3.5400595664978027. Accuracy: 25.194\n",
            "Testing: Iteration: 335500. Loss: 3.5400595664978027. Accuracy: 18.99\n",
            "Training: Iteration: 336000. Loss: 3.0695791244506836. Accuracy: 25.164\n",
            "Testing: Iteration: 336000. Loss: 3.0695791244506836. Accuracy: 18.98\n",
            "Epoch:  430\n",
            "Training: Iteration: 336500. Loss: 3.207942008972168. Accuracy: 25.162\n",
            "Testing: Iteration: 336500. Loss: 3.207942008972168. Accuracy: 18.99\n",
            "Training: Iteration: 337000. Loss: 3.269124746322632. Accuracy: 25.148\n",
            "Testing: Iteration: 337000. Loss: 3.269124746322632. Accuracy: 18.97\n",
            "Epoch:  431\n",
            "Training: Iteration: 337500. Loss: 3.1244630813598633. Accuracy: 25.174\n",
            "Testing: Iteration: 337500. Loss: 3.1244630813598633. Accuracy: 18.92\n",
            "Epoch:  432\n",
            "Training: Iteration: 338000. Loss: 3.2668142318725586. Accuracy: 25.144\n",
            "Testing: Iteration: 338000. Loss: 3.2668142318725586. Accuracy: 19.11\n",
            "Training: Iteration: 338500. Loss: 3.23100209236145. Accuracy: 25.178\n",
            "Testing: Iteration: 338500. Loss: 3.23100209236145. Accuracy: 18.97\n",
            "Epoch:  433\n",
            "Training: Iteration: 339000. Loss: 3.3095855712890625. Accuracy: 25.162\n",
            "Testing: Iteration: 339000. Loss: 3.3095855712890625. Accuracy: 18.99\n",
            "Epoch:  434\n",
            "Training: Iteration: 339500. Loss: 3.0673320293426514. Accuracy: 25.178\n",
            "Testing: Iteration: 339500. Loss: 3.0673320293426514. Accuracy: 19.06\n",
            "Training: Iteration: 340000. Loss: 3.2896931171417236. Accuracy: 25.186\n",
            "Testing: Iteration: 340000. Loss: 3.2896931171417236. Accuracy: 18.91\n",
            "Epoch:  435\n",
            "Training: Iteration: 340500. Loss: 3.060572385787964. Accuracy: 25.126\n",
            "Testing: Iteration: 340500. Loss: 3.060572385787964. Accuracy: 18.92\n",
            "Epoch:  436\n",
            "Training: Iteration: 341000. Loss: 3.4358086585998535. Accuracy: 25.194\n",
            "Testing: Iteration: 341000. Loss: 3.4358086585998535. Accuracy: 19.01\n",
            "Training: Iteration: 341500. Loss: 3.4772937297821045. Accuracy: 25.178\n",
            "Testing: Iteration: 341500. Loss: 3.4772937297821045. Accuracy: 19.0\n",
            "Epoch:  437\n",
            "Training: Iteration: 342000. Loss: 3.4569263458251953. Accuracy: 25.18\n",
            "Testing: Iteration: 342000. Loss: 3.4569263458251953. Accuracy: 19.05\n",
            "Training: Iteration: 342500. Loss: 3.3831355571746826. Accuracy: 25.2\n",
            "Testing: Iteration: 342500. Loss: 3.3831355571746826. Accuracy: 18.99\n",
            "Epoch:  438\n",
            "Training: Iteration: 343000. Loss: 3.6620001792907715. Accuracy: 25.184\n",
            "Testing: Iteration: 343000. Loss: 3.6620001792907715. Accuracy: 18.98\n",
            "Epoch:  439\n",
            "Training: Iteration: 343500. Loss: 3.3167314529418945. Accuracy: 25.182\n",
            "Testing: Iteration: 343500. Loss: 3.3167314529418945. Accuracy: 19.05\n",
            "Training: Iteration: 344000. Loss: 3.335501194000244. Accuracy: 25.194\n",
            "Testing: Iteration: 344000. Loss: 3.335501194000244. Accuracy: 19.07\n",
            "Epoch:  440\n",
            "Training: Iteration: 344500. Loss: 3.0869669914245605. Accuracy: 25.186\n",
            "Testing: Iteration: 344500. Loss: 3.0869669914245605. Accuracy: 18.99\n",
            "Epoch:  441\n",
            "Training: Iteration: 345000. Loss: 3.1597952842712402. Accuracy: 25.206\n",
            "Testing: Iteration: 345000. Loss: 3.1597952842712402. Accuracy: 19.0\n",
            "Training: Iteration: 345500. Loss: 3.3970930576324463. Accuracy: 25.234\n",
            "Testing: Iteration: 345500. Loss: 3.3970930576324463. Accuracy: 18.99\n",
            "Epoch:  442\n",
            "Training: Iteration: 346000. Loss: 2.809898853302002. Accuracy: 25.15\n",
            "Testing: Iteration: 346000. Loss: 2.809898853302002. Accuracy: 18.98\n",
            "Epoch:  443\n",
            "Training: Iteration: 346500. Loss: 3.3792691230773926. Accuracy: 25.24\n",
            "Testing: Iteration: 346500. Loss: 3.3792691230773926. Accuracy: 19.03\n",
            "Training: Iteration: 347000. Loss: 3.346419334411621. Accuracy: 25.242\n",
            "Testing: Iteration: 347000. Loss: 3.346419334411621. Accuracy: 18.98\n",
            "Epoch:  444\n",
            "Training: Iteration: 347500. Loss: 3.1778223514556885. Accuracy: 25.206\n",
            "Testing: Iteration: 347500. Loss: 3.1778223514556885. Accuracy: 18.93\n",
            "Epoch:  445\n",
            "Training: Iteration: 348000. Loss: 3.0296268463134766. Accuracy: 25.27\n",
            "Testing: Iteration: 348000. Loss: 3.0296268463134766. Accuracy: 18.96\n",
            "Training: Iteration: 348500. Loss: 3.3748855590820312. Accuracy: 25.216\n",
            "Testing: Iteration: 348500. Loss: 3.3748855590820312. Accuracy: 19.03\n",
            "Epoch:  446\n",
            "Training: Iteration: 349000. Loss: 3.3796520233154297. Accuracy: 25.166\n",
            "Testing: Iteration: 349000. Loss: 3.3796520233154297. Accuracy: 19.07\n",
            "Training: Iteration: 349500. Loss: 3.2806806564331055. Accuracy: 25.256\n",
            "Testing: Iteration: 349500. Loss: 3.2806806564331055. Accuracy: 19.01\n",
            "Epoch:  447\n",
            "Training: Iteration: 350000. Loss: 3.2329602241516113. Accuracy: 25.168\n",
            "Testing: Iteration: 350000. Loss: 3.2329602241516113. Accuracy: 18.97\n",
            "Epoch:  448\n",
            "Training: Iteration: 350500. Loss: 3.252187728881836. Accuracy: 25.236\n",
            "Testing: Iteration: 350500. Loss: 3.252187728881836. Accuracy: 19.03\n",
            "Training: Iteration: 351000. Loss: 3.30867862701416. Accuracy: 25.216\n",
            "Testing: Iteration: 351000. Loss: 3.30867862701416. Accuracy: 19.02\n",
            "Epoch:  449\n",
            "Training: Iteration: 351500. Loss: 3.2234930992126465. Accuracy: 25.234\n",
            "Testing: Iteration: 351500. Loss: 3.2234930992126465. Accuracy: 18.98\n",
            "Epoch:  450\n",
            "Training: Iteration: 352000. Loss: 3.4590907096862793. Accuracy: 25.278\n",
            "Testing: Iteration: 352000. Loss: 3.4590907096862793. Accuracy: 19.0\n",
            "Training: Iteration: 352500. Loss: 3.0813052654266357. Accuracy: 25.25\n",
            "Testing: Iteration: 352500. Loss: 3.0813052654266357. Accuracy: 18.97\n",
            "Epoch:  451\n",
            "Training: Iteration: 353000. Loss: 2.999833822250366. Accuracy: 25.164\n",
            "Testing: Iteration: 353000. Loss: 2.999833822250366. Accuracy: 18.94\n",
            "Epoch:  452\n",
            "Training: Iteration: 353500. Loss: 3.4218854904174805. Accuracy: 25.288\n",
            "Testing: Iteration: 353500. Loss: 3.4218854904174805. Accuracy: 18.98\n",
            "Training: Iteration: 354000. Loss: 3.3175714015960693. Accuracy: 25.242\n",
            "Testing: Iteration: 354000. Loss: 3.3175714015960693. Accuracy: 19.04\n",
            "Epoch:  453\n",
            "Training: Iteration: 354500. Loss: 3.2015228271484375. Accuracy: 25.214\n",
            "Testing: Iteration: 354500. Loss: 3.2015228271484375. Accuracy: 19.02\n",
            "Training: Iteration: 355000. Loss: 2.9372169971466064. Accuracy: 25.23\n",
            "Testing: Iteration: 355000. Loss: 2.9372169971466064. Accuracy: 18.95\n",
            "Epoch:  454\n",
            "Training: Iteration: 355500. Loss: 3.320406436920166. Accuracy: 25.232\n",
            "Testing: Iteration: 355500. Loss: 3.320406436920166. Accuracy: 18.97\n",
            "Epoch:  455\n",
            "Training: Iteration: 356000. Loss: 3.351284980773926. Accuracy: 25.214\n",
            "Testing: Iteration: 356000. Loss: 3.351284980773926. Accuracy: 19.03\n",
            "Training: Iteration: 356500. Loss: 3.722315788269043. Accuracy: 25.234\n",
            "Testing: Iteration: 356500. Loss: 3.722315788269043. Accuracy: 19.05\n",
            "Epoch:  456\n",
            "Training: Iteration: 357000. Loss: 3.3734216690063477. Accuracy: 25.25\n",
            "Testing: Iteration: 357000. Loss: 3.3734216690063477. Accuracy: 18.97\n",
            "Epoch:  457\n",
            "Training: Iteration: 357500. Loss: 3.0964322090148926. Accuracy: 25.266\n",
            "Testing: Iteration: 357500. Loss: 3.0964322090148926. Accuracy: 19.0\n",
            "Training: Iteration: 358000. Loss: 3.373569965362549. Accuracy: 25.252\n",
            "Testing: Iteration: 358000. Loss: 3.373569965362549. Accuracy: 19.01\n",
            "Epoch:  458\n",
            "Training: Iteration: 358500. Loss: 3.2950963973999023. Accuracy: 25.226\n",
            "Testing: Iteration: 358500. Loss: 3.2950963973999023. Accuracy: 18.94\n",
            "Epoch:  459\n",
            "Training: Iteration: 359000. Loss: 3.5894885063171387. Accuracy: 25.292\n",
            "Testing: Iteration: 359000. Loss: 3.5894885063171387. Accuracy: 19.04\n",
            "Training: Iteration: 359500. Loss: 3.2433323860168457. Accuracy: 25.236\n",
            "Testing: Iteration: 359500. Loss: 3.2433323860168457. Accuracy: 18.97\n",
            "Epoch:  460\n",
            "Training: Iteration: 360000. Loss: 3.002305030822754. Accuracy: 25.23\n",
            "Testing: Iteration: 360000. Loss: 3.002305030822754. Accuracy: 18.94\n",
            "Training: Iteration: 360500. Loss: 3.194042921066284. Accuracy: 25.31\n",
            "Testing: Iteration: 360500. Loss: 3.194042921066284. Accuracy: 18.99\n",
            "Epoch:  461\n",
            "Training: Iteration: 361000. Loss: 3.355339288711548. Accuracy: 25.272\n",
            "Testing: Iteration: 361000. Loss: 3.355339288711548. Accuracy: 19.0\n",
            "Epoch:  462\n",
            "Training: Iteration: 361500. Loss: 3.2670810222625732. Accuracy: 25.224\n",
            "Testing: Iteration: 361500. Loss: 3.2670810222625732. Accuracy: 18.99\n",
            "Training: Iteration: 362000. Loss: 2.983349561691284. Accuracy: 25.312\n",
            "Testing: Iteration: 362000. Loss: 2.983349561691284. Accuracy: 18.98\n",
            "Epoch:  463\n",
            "Training: Iteration: 362500. Loss: 3.4227559566497803. Accuracy: 25.238\n",
            "Testing: Iteration: 362500. Loss: 3.4227559566497803. Accuracy: 19.0\n",
            "Epoch:  464\n",
            "Training: Iteration: 363000. Loss: 2.972379207611084. Accuracy: 25.288\n",
            "Testing: Iteration: 363000. Loss: 2.972379207611084. Accuracy: 19.0\n",
            "Training: Iteration: 363500. Loss: 3.471054792404175. Accuracy: 25.244\n",
            "Testing: Iteration: 363500. Loss: 3.471054792404175. Accuracy: 18.99\n",
            "Epoch:  465\n",
            "Training: Iteration: 364000. Loss: 3.1473262310028076. Accuracy: 25.284\n",
            "Testing: Iteration: 364000. Loss: 3.1473262310028076. Accuracy: 18.99\n",
            "Epoch:  466\n",
            "Training: Iteration: 364500. Loss: 3.2060372829437256. Accuracy: 25.304\n",
            "Testing: Iteration: 364500. Loss: 3.2060372829437256. Accuracy: 19.04\n",
            "Training: Iteration: 365000. Loss: 3.0030434131622314. Accuracy: 25.304\n",
            "Testing: Iteration: 365000. Loss: 3.0030434131622314. Accuracy: 19.03\n",
            "Epoch:  467\n",
            "Training: Iteration: 365500. Loss: 3.464355945587158. Accuracy: 25.238\n",
            "Testing: Iteration: 365500. Loss: 3.464355945587158. Accuracy: 18.93\n",
            "Epoch:  468\n",
            "Training: Iteration: 366000. Loss: 2.985152006149292. Accuracy: 25.334\n",
            "Testing: Iteration: 366000. Loss: 2.985152006149292. Accuracy: 18.94\n",
            "Training: Iteration: 366500. Loss: 3.3400156497955322. Accuracy: 25.276\n",
            "Testing: Iteration: 366500. Loss: 3.3400156497955322. Accuracy: 19.01\n",
            "Epoch:  469\n",
            "Training: Iteration: 367000. Loss: 3.0611348152160645. Accuracy: 25.286\n",
            "Testing: Iteration: 367000. Loss: 3.0611348152160645. Accuracy: 19.0\n",
            "Training: Iteration: 367500. Loss: 3.6681137084960938. Accuracy: 25.306\n",
            "Testing: Iteration: 367500. Loss: 3.6681137084960938. Accuracy: 19.02\n",
            "Epoch:  470\n",
            "Training: Iteration: 368000. Loss: 3.40980863571167. Accuracy: 25.248\n",
            "Testing: Iteration: 368000. Loss: 3.40980863571167. Accuracy: 18.99\n",
            "Epoch:  471\n",
            "Training: Iteration: 368500. Loss: 3.1876797676086426. Accuracy: 25.304\n",
            "Testing: Iteration: 368500. Loss: 3.1876797676086426. Accuracy: 19.06\n",
            "Training: Iteration: 369000. Loss: 3.48172664642334. Accuracy: 25.268\n",
            "Testing: Iteration: 369000. Loss: 3.48172664642334. Accuracy: 18.99\n",
            "Epoch:  472\n",
            "Training: Iteration: 369500. Loss: 3.3750834465026855. Accuracy: 25.292\n",
            "Testing: Iteration: 369500. Loss: 3.3750834465026855. Accuracy: 19.02\n",
            "Epoch:  473\n",
            "Training: Iteration: 370000. Loss: 3.114624261856079. Accuracy: 25.308\n",
            "Testing: Iteration: 370000. Loss: 3.114624261856079. Accuracy: 19.02\n",
            "Training: Iteration: 370500. Loss: 3.3433618545532227. Accuracy: 25.322\n",
            "Testing: Iteration: 370500. Loss: 3.3433618545532227. Accuracy: 18.94\n",
            "Epoch:  474\n",
            "Training: Iteration: 371000. Loss: 3.2370429039001465. Accuracy: 25.252\n",
            "Testing: Iteration: 371000. Loss: 3.2370429039001465. Accuracy: 18.91\n",
            "Epoch:  475\n",
            "Training: Iteration: 371500. Loss: 3.1540656089782715. Accuracy: 25.306\n",
            "Testing: Iteration: 371500. Loss: 3.1540656089782715. Accuracy: 18.97\n",
            "Training: Iteration: 372000. Loss: 3.3228025436401367. Accuracy: 25.294\n",
            "Testing: Iteration: 372000. Loss: 3.3228025436401367. Accuracy: 19.06\n",
            "Epoch:  476\n",
            "Training: Iteration: 372500. Loss: 3.3019216060638428. Accuracy: 25.27\n",
            "Testing: Iteration: 372500. Loss: 3.3019216060638428. Accuracy: 19.04\n",
            "Training: Iteration: 373000. Loss: 3.350956678390503. Accuracy: 25.354\n",
            "Testing: Iteration: 373000. Loss: 3.350956678390503. Accuracy: 19.0\n",
            "Epoch:  477\n",
            "Training: Iteration: 373500. Loss: 3.1970834732055664. Accuracy: 25.338\n",
            "Testing: Iteration: 373500. Loss: 3.1970834732055664. Accuracy: 18.95\n",
            "Epoch:  478\n",
            "Training: Iteration: 374000. Loss: 3.61224102973938. Accuracy: 25.278\n",
            "Testing: Iteration: 374000. Loss: 3.61224102973938. Accuracy: 19.08\n",
            "Training: Iteration: 374500. Loss: 2.887378692626953. Accuracy: 25.31\n",
            "Testing: Iteration: 374500. Loss: 2.887378692626953. Accuracy: 18.98\n",
            "Epoch:  479\n",
            "Training: Iteration: 375000. Loss: 3.306126356124878. Accuracy: 25.306\n",
            "Testing: Iteration: 375000. Loss: 3.306126356124878. Accuracy: 19.02\n",
            "Epoch:  480\n",
            "Training: Iteration: 375500. Loss: 3.5194387435913086. Accuracy: 25.346\n",
            "Testing: Iteration: 375500. Loss: 3.5194387435913086. Accuracy: 19.0\n",
            "Training: Iteration: 376000. Loss: 3.3430495262145996. Accuracy: 25.29\n",
            "Testing: Iteration: 376000. Loss: 3.3430495262145996. Accuracy: 18.98\n",
            "Epoch:  481\n",
            "Training: Iteration: 376500. Loss: 3.3823063373565674. Accuracy: 25.288\n",
            "Testing: Iteration: 376500. Loss: 3.3823063373565674. Accuracy: 18.97\n",
            "Epoch:  482\n",
            "Training: Iteration: 377000. Loss: 3.392240047454834. Accuracy: 25.338\n",
            "Testing: Iteration: 377000. Loss: 3.392240047454834. Accuracy: 18.98\n",
            "Training: Iteration: 377500. Loss: 3.2510910034179688. Accuracy: 25.34\n",
            "Testing: Iteration: 377500. Loss: 3.2510910034179688. Accuracy: 18.99\n",
            "Epoch:  483\n",
            "Training: Iteration: 378000. Loss: 3.4355661869049072. Accuracy: 25.322\n",
            "Testing: Iteration: 378000. Loss: 3.4355661869049072. Accuracy: 19.04\n",
            "Epoch:  484\n",
            "Training: Iteration: 378500. Loss: 3.3579840660095215. Accuracy: 25.376\n",
            "Testing: Iteration: 378500. Loss: 3.3579840660095215. Accuracy: 18.94\n",
            "Training: Iteration: 379000. Loss: 3.6950783729553223. Accuracy: 25.32\n",
            "Testing: Iteration: 379000. Loss: 3.6950783729553223. Accuracy: 19.01\n",
            "Epoch:  485\n",
            "Training: Iteration: 379500. Loss: 3.2538251876831055. Accuracy: 25.242\n",
            "Testing: Iteration: 379500. Loss: 3.2538251876831055. Accuracy: 18.99\n",
            "Training: Iteration: 380000. Loss: 3.277052402496338. Accuracy: 25.332\n",
            "Testing: Iteration: 380000. Loss: 3.277052402496338. Accuracy: 19.03\n",
            "Epoch:  486\n",
            "Training: Iteration: 380500. Loss: 3.3443496227264404. Accuracy: 25.278\n",
            "Testing: Iteration: 380500. Loss: 3.3443496227264404. Accuracy: 19.04\n",
            "Epoch:  487\n",
            "Training: Iteration: 381000. Loss: 2.946744441986084. Accuracy: 25.348\n",
            "Testing: Iteration: 381000. Loss: 2.946744441986084. Accuracy: 18.98\n",
            "Training: Iteration: 381500. Loss: 3.3095054626464844. Accuracy: 25.29\n",
            "Testing: Iteration: 381500. Loss: 3.3095054626464844. Accuracy: 18.99\n",
            "Epoch:  488\n",
            "Training: Iteration: 382000. Loss: 3.3193929195404053. Accuracy: 25.338\n",
            "Testing: Iteration: 382000. Loss: 3.3193929195404053. Accuracy: 19.01\n",
            "Epoch:  489\n",
            "Training: Iteration: 382500. Loss: 3.689988374710083. Accuracy: 25.34\n",
            "Testing: Iteration: 382500. Loss: 3.689988374710083. Accuracy: 18.99\n",
            "Training: Iteration: 383000. Loss: 3.3590099811553955. Accuracy: 25.394\n",
            "Testing: Iteration: 383000. Loss: 3.3590099811553955. Accuracy: 18.94\n",
            "Epoch:  490\n",
            "Training: Iteration: 383500. Loss: 3.20804762840271. Accuracy: 25.298\n",
            "Testing: Iteration: 383500. Loss: 3.20804762840271. Accuracy: 18.95\n",
            "Epoch:  491\n",
            "Training: Iteration: 384000. Loss: 3.275935649871826. Accuracy: 25.358\n",
            "Testing: Iteration: 384000. Loss: 3.275935649871826. Accuracy: 18.97\n",
            "Training: Iteration: 384500. Loss: 3.4619438648223877. Accuracy: 25.356\n",
            "Testing: Iteration: 384500. Loss: 3.4619438648223877. Accuracy: 19.02\n",
            "Epoch:  492\n",
            "Training: Iteration: 385000. Loss: 2.9955899715423584. Accuracy: 25.318\n",
            "Testing: Iteration: 385000. Loss: 2.9955899715423584. Accuracy: 19.02\n",
            "Training: Iteration: 385500. Loss: 3.3176255226135254. Accuracy: 25.386\n",
            "Testing: Iteration: 385500. Loss: 3.3176255226135254. Accuracy: 19.01\n",
            "Epoch:  493\n",
            "Training: Iteration: 386000. Loss: 3.252305507659912. Accuracy: 25.338\n",
            "Testing: Iteration: 386000. Loss: 3.252305507659912. Accuracy: 19.0\n",
            "Epoch:  494\n",
            "Training: Iteration: 386500. Loss: 2.820620536804199. Accuracy: 25.346\n",
            "Testing: Iteration: 386500. Loss: 2.820620536804199. Accuracy: 18.93\n",
            "Training: Iteration: 387000. Loss: 3.340606689453125. Accuracy: 25.344\n",
            "Testing: Iteration: 387000. Loss: 3.340606689453125. Accuracy: 18.94\n",
            "Epoch:  495\n",
            "Training: Iteration: 387500. Loss: 3.343113660812378. Accuracy: 25.336\n",
            "Testing: Iteration: 387500. Loss: 3.343113660812378. Accuracy: 19.03\n",
            "Epoch:  496\n",
            "Training: Iteration: 388000. Loss: 3.484189033508301. Accuracy: 25.366\n",
            "Testing: Iteration: 388000. Loss: 3.484189033508301. Accuracy: 18.98\n",
            "Training: Iteration: 388500. Loss: 3.6428680419921875. Accuracy: 25.38\n",
            "Testing: Iteration: 388500. Loss: 3.6428680419921875. Accuracy: 18.92\n",
            "Epoch:  497\n",
            "Training: Iteration: 389000. Loss: 3.1353330612182617. Accuracy: 25.326\n",
            "Testing: Iteration: 389000. Loss: 3.1353330612182617. Accuracy: 18.89\n",
            "Epoch:  498\n",
            "Training: Iteration: 389500. Loss: 3.036423444747925. Accuracy: 25.36\n",
            "Testing: Iteration: 389500. Loss: 3.036423444747925. Accuracy: 19.03\n",
            "Training: Iteration: 390000. Loss: 3.273862361907959. Accuracy: 25.406\n",
            "Testing: Iteration: 390000. Loss: 3.273862361907959. Accuracy: 18.95\n",
            "Epoch:  499\n",
            "Training: Iteration: 390500. Loss: 3.48852801322937. Accuracy: 25.33\n",
            "Testing: Iteration: 390500. Loss: 3.48852801322937. Accuracy: 18.97\n",
            "Training: Iteration: 391000. Loss: 3.1339149475097656. Accuracy: 25.422\n",
            "Testing: Iteration: 391000. Loss: 3.1339149475097656. Accuracy: 18.95\n",
            "Epoch:  500\n",
            "Training: Iteration: 391500. Loss: 3.24812650680542. Accuracy: 25.356\n",
            "Testing: Iteration: 391500. Loss: 3.24812650680542. Accuracy: 18.93\n",
            "Epoch:  501\n",
            "Training: Iteration: 392000. Loss: 2.972126007080078. Accuracy: 25.3\n",
            "Testing: Iteration: 392000. Loss: 2.972126007080078. Accuracy: 18.91\n",
            "Training: Iteration: 392500. Loss: 2.81471586227417. Accuracy: 25.36\n",
            "Testing: Iteration: 392500. Loss: 2.81471586227417. Accuracy: 18.99\n",
            "Epoch:  502\n",
            "Training: Iteration: 393000. Loss: 3.3543455600738525. Accuracy: 25.36\n",
            "Testing: Iteration: 393000. Loss: 3.3543455600738525. Accuracy: 18.99\n",
            "Epoch:  503\n",
            "Training: Iteration: 393500. Loss: 3.442304849624634. Accuracy: 25.38\n",
            "Testing: Iteration: 393500. Loss: 3.442304849624634. Accuracy: 18.9\n",
            "Training: Iteration: 394000. Loss: 3.1070022583007812. Accuracy: 25.34\n",
            "Testing: Iteration: 394000. Loss: 3.1070022583007812. Accuracy: 18.91\n",
            "Epoch:  504\n",
            "Training: Iteration: 394500. Loss: 3.2896735668182373. Accuracy: 25.352\n",
            "Testing: Iteration: 394500. Loss: 3.2896735668182373. Accuracy: 18.9\n",
            "Epoch:  505\n",
            "Training: Iteration: 395000. Loss: 3.116757392883301. Accuracy: 25.376\n",
            "Testing: Iteration: 395000. Loss: 3.116757392883301. Accuracy: 18.94\n",
            "Training: Iteration: 395500. Loss: 3.1321914196014404. Accuracy: 25.432\n",
            "Testing: Iteration: 395500. Loss: 3.1321914196014404. Accuracy: 18.94\n",
            "Epoch:  506\n",
            "Training: Iteration: 396000. Loss: 3.5456125736236572. Accuracy: 25.362\n",
            "Testing: Iteration: 396000. Loss: 3.5456125736236572. Accuracy: 18.94\n",
            "Epoch:  507\n",
            "Training: Iteration: 396500. Loss: 3.328582286834717. Accuracy: 25.386\n",
            "Testing: Iteration: 396500. Loss: 3.328582286834717. Accuracy: 18.95\n",
            "Training: Iteration: 397000. Loss: 3.5530781745910645. Accuracy: 25.404\n",
            "Testing: Iteration: 397000. Loss: 3.5530781745910645. Accuracy: 18.96\n",
            "Epoch:  508\n",
            "Training: Iteration: 397500. Loss: 3.3296728134155273. Accuracy: 25.352\n",
            "Testing: Iteration: 397500. Loss: 3.3296728134155273. Accuracy: 19.0\n",
            "Training: Iteration: 398000. Loss: 3.151698112487793. Accuracy: 25.354\n",
            "Testing: Iteration: 398000. Loss: 3.151698112487793. Accuracy: 18.89\n",
            "Epoch:  509\n",
            "Training: Iteration: 398500. Loss: 3.4732487201690674. Accuracy: 25.358\n",
            "Testing: Iteration: 398500. Loss: 3.4732487201690674. Accuracy: 18.99\n",
            "Epoch:  510\n",
            "Training: Iteration: 399000. Loss: 3.1576058864593506. Accuracy: 25.392\n",
            "Testing: Iteration: 399000. Loss: 3.1576058864593506. Accuracy: 18.94\n",
            "Training: Iteration: 399500. Loss: 3.3499655723571777. Accuracy: 25.358\n",
            "Testing: Iteration: 399500. Loss: 3.3499655723571777. Accuracy: 18.98\n",
            "Epoch:  511\n",
            "Training: Iteration: 400000. Loss: 3.2759037017822266. Accuracy: 25.364\n",
            "Testing: Iteration: 400000. Loss: 3.2759037017822266. Accuracy: 18.96\n",
            "Epoch:  512\n",
            "Training: Iteration: 400500. Loss: 3.3405919075012207. Accuracy: 25.42\n",
            "Testing: Iteration: 400500. Loss: 3.3405919075012207. Accuracy: 18.88\n",
            "Training: Iteration: 401000. Loss: 3.0966298580169678. Accuracy: 25.404\n",
            "Testing: Iteration: 401000. Loss: 3.0966298580169678. Accuracy: 18.83\n",
            "Epoch:  513\n",
            "Training: Iteration: 401500. Loss: 2.9701297283172607. Accuracy: 25.36\n",
            "Testing: Iteration: 401500. Loss: 2.9701297283172607. Accuracy: 18.89\n",
            "Epoch:  514\n",
            "Training: Iteration: 402000. Loss: 2.992032527923584. Accuracy: 25.414\n",
            "Testing: Iteration: 402000. Loss: 2.992032527923584. Accuracy: 18.91\n",
            "Training: Iteration: 402500. Loss: 3.1603546142578125. Accuracy: 25.406\n",
            "Testing: Iteration: 402500. Loss: 3.1603546142578125. Accuracy: 18.97\n",
            "Epoch:  515\n",
            "Training: Iteration: 403000. Loss: 3.3001630306243896. Accuracy: 25.392\n",
            "Testing: Iteration: 403000. Loss: 3.3001630306243896. Accuracy: 18.93\n",
            "Training: Iteration: 403500. Loss: 3.386983871459961. Accuracy: 25.428\n",
            "Testing: Iteration: 403500. Loss: 3.386983871459961. Accuracy: 18.94\n",
            "Epoch:  516\n",
            "Training: Iteration: 404000. Loss: 3.353459596633911. Accuracy: 25.414\n",
            "Testing: Iteration: 404000. Loss: 3.353459596633911. Accuracy: 18.88\n",
            "Epoch:  517\n",
            "Training: Iteration: 404500. Loss: 3.0360569953918457. Accuracy: 25.392\n",
            "Testing: Iteration: 404500. Loss: 3.0360569953918457. Accuracy: 18.93\n",
            "Training: Iteration: 405000. Loss: 3.480668306350708. Accuracy: 25.438\n",
            "Testing: Iteration: 405000. Loss: 3.480668306350708. Accuracy: 18.98\n",
            "Epoch:  518\n",
            "Training: Iteration: 405500. Loss: 3.3558218479156494. Accuracy: 25.414\n",
            "Testing: Iteration: 405500. Loss: 3.3558218479156494. Accuracy: 18.92\n",
            "Epoch:  519\n",
            "Training: Iteration: 406000. Loss: 3.0934407711029053. Accuracy: 25.422\n",
            "Testing: Iteration: 406000. Loss: 3.0934407711029053. Accuracy: 18.98\n",
            "Training: Iteration: 406500. Loss: 2.987478017807007. Accuracy: 25.382\n",
            "Testing: Iteration: 406500. Loss: 2.987478017807007. Accuracy: 18.89\n",
            "Epoch:  520\n",
            "Training: Iteration: 407000. Loss: 2.8533170223236084. Accuracy: 25.346\n",
            "Testing: Iteration: 407000. Loss: 2.8533170223236084. Accuracy: 18.89\n",
            "Epoch:  521\n",
            "Training: Iteration: 407500. Loss: 3.0715625286102295. Accuracy: 25.408\n",
            "Testing: Iteration: 407500. Loss: 3.0715625286102295. Accuracy: 18.89\n",
            "Training: Iteration: 408000. Loss: 3.359907627105713. Accuracy: 25.418\n",
            "Testing: Iteration: 408000. Loss: 3.359907627105713. Accuracy: 18.88\n",
            "Epoch:  522\n",
            "Training: Iteration: 408500. Loss: 3.194216728210449. Accuracy: 25.4\n",
            "Testing: Iteration: 408500. Loss: 3.194216728210449. Accuracy: 18.94\n",
            "Epoch:  523\n",
            "Training: Iteration: 409000. Loss: 3.1511831283569336. Accuracy: 25.442\n",
            "Testing: Iteration: 409000. Loss: 3.1511831283569336. Accuracy: 18.94\n",
            "Training: Iteration: 409500. Loss: 3.3821818828582764. Accuracy: 25.392\n",
            "Testing: Iteration: 409500. Loss: 3.3821818828582764. Accuracy: 18.89\n",
            "Epoch:  524\n",
            "Training: Iteration: 410000. Loss: 3.1118545532226562. Accuracy: 25.376\n",
            "Testing: Iteration: 410000. Loss: 3.1118545532226562. Accuracy: 18.92\n",
            "Training: Iteration: 410500. Loss: 3.2423830032348633. Accuracy: 25.39\n",
            "Testing: Iteration: 410500. Loss: 3.2423830032348633. Accuracy: 18.95\n",
            "Epoch:  525\n",
            "Training: Iteration: 411000. Loss: 2.8919050693511963. Accuracy: 25.374\n",
            "Testing: Iteration: 411000. Loss: 2.8919050693511963. Accuracy: 18.95\n",
            "Epoch:  526\n",
            "Training: Iteration: 411500. Loss: 3.17901349067688. Accuracy: 25.436\n",
            "Testing: Iteration: 411500. Loss: 3.17901349067688. Accuracy: 18.88\n",
            "Training: Iteration: 412000. Loss: 3.5411953926086426. Accuracy: 25.39\n",
            "Testing: Iteration: 412000. Loss: 3.5411953926086426. Accuracy: 18.99\n",
            "Epoch:  527\n",
            "Training: Iteration: 412500. Loss: 2.967486619949341. Accuracy: 25.404\n",
            "Testing: Iteration: 412500. Loss: 2.967486619949341. Accuracy: 18.84\n",
            "Epoch:  528\n",
            "Training: Iteration: 413000. Loss: 3.3785898685455322. Accuracy: 25.464\n",
            "Testing: Iteration: 413000. Loss: 3.3785898685455322. Accuracy: 18.88\n",
            "Training: Iteration: 413500. Loss: 3.3346314430236816. Accuracy: 25.45\n",
            "Testing: Iteration: 413500. Loss: 3.3346314430236816. Accuracy: 18.82\n",
            "Epoch:  529\n",
            "Training: Iteration: 414000. Loss: 3.2895634174346924. Accuracy: 25.376\n",
            "Testing: Iteration: 414000. Loss: 3.2895634174346924. Accuracy: 18.91\n",
            "Epoch:  530\n",
            "Training: Iteration: 414500. Loss: 3.0631608963012695. Accuracy: 25.396\n",
            "Testing: Iteration: 414500. Loss: 3.0631608963012695. Accuracy: 18.85\n",
            "Training: Iteration: 415000. Loss: 3.396867275238037. Accuracy: 25.398\n",
            "Testing: Iteration: 415000. Loss: 3.396867275238037. Accuracy: 18.84\n",
            "Epoch:  531\n",
            "Training: Iteration: 415500. Loss: 3.0944154262542725. Accuracy: 25.414\n",
            "Testing: Iteration: 415500. Loss: 3.0944154262542725. Accuracy: 18.95\n",
            "Training: Iteration: 416000. Loss: 3.7283270359039307. Accuracy: 25.432\n",
            "Testing: Iteration: 416000. Loss: 3.7283270359039307. Accuracy: 18.94\n",
            "Epoch:  532\n",
            "Training: Iteration: 416500. Loss: 3.6290206909179688. Accuracy: 25.416\n",
            "Testing: Iteration: 416500. Loss: 3.6290206909179688. Accuracy: 18.86\n",
            "Epoch:  533\n",
            "Training: Iteration: 417000. Loss: 3.1041808128356934. Accuracy: 25.45\n",
            "Testing: Iteration: 417000. Loss: 3.1041808128356934. Accuracy: 18.82\n",
            "Training: Iteration: 417500. Loss: 3.519622325897217. Accuracy: 25.432\n",
            "Testing: Iteration: 417500. Loss: 3.519622325897217. Accuracy: 18.94\n",
            "Epoch:  534\n",
            "Training: Iteration: 418000. Loss: 3.3123300075531006. Accuracy: 25.454\n",
            "Testing: Iteration: 418000. Loss: 3.3123300075531006. Accuracy: 18.96\n",
            "Epoch:  535\n",
            "Training: Iteration: 418500. Loss: 3.2722153663635254. Accuracy: 25.444\n",
            "Testing: Iteration: 418500. Loss: 3.2722153663635254. Accuracy: 18.94\n",
            "Training: Iteration: 419000. Loss: 3.3425652980804443. Accuracy: 25.424\n",
            "Testing: Iteration: 419000. Loss: 3.3425652980804443. Accuracy: 18.81\n",
            "Epoch:  536\n",
            "Training: Iteration: 419500. Loss: 3.4756722450256348. Accuracy: 25.412\n",
            "Testing: Iteration: 419500. Loss: 3.4756722450256348. Accuracy: 18.83\n",
            "Epoch:  537\n",
            "Training: Iteration: 420000. Loss: 3.1281611919403076. Accuracy: 25.434\n",
            "Testing: Iteration: 420000. Loss: 3.1281611919403076. Accuracy: 18.91\n",
            "Training: Iteration: 420500. Loss: 3.0501558780670166. Accuracy: 25.458\n",
            "Testing: Iteration: 420500. Loss: 3.0501558780670166. Accuracy: 18.85\n",
            "Epoch:  538\n",
            "Training: Iteration: 421000. Loss: 3.320241689682007. Accuracy: 25.438\n",
            "Testing: Iteration: 421000. Loss: 3.320241689682007. Accuracy: 18.85\n",
            "Epoch:  539\n",
            "Training: Iteration: 421500. Loss: 3.2457385063171387. Accuracy: 25.492\n",
            "Testing: Iteration: 421500. Loss: 3.2457385063171387. Accuracy: 18.87\n",
            "Training: Iteration: 422000. Loss: 3.1831862926483154. Accuracy: 25.438\n",
            "Testing: Iteration: 422000. Loss: 3.1831862926483154. Accuracy: 18.78\n",
            "Epoch:  540\n",
            "Training: Iteration: 422500. Loss: 3.6003119945526123. Accuracy: 25.38\n",
            "Testing: Iteration: 422500. Loss: 3.6003119945526123. Accuracy: 18.82\n",
            "Training: Iteration: 423000. Loss: 3.223654270172119. Accuracy: 25.404\n",
            "Testing: Iteration: 423000. Loss: 3.223654270172119. Accuracy: 18.94\n",
            "Epoch:  541\n",
            "Training: Iteration: 423500. Loss: 3.122934341430664. Accuracy: 25.438\n",
            "Testing: Iteration: 423500. Loss: 3.122934341430664. Accuracy: 18.94\n",
            "Epoch:  542\n",
            "Training: Iteration: 424000. Loss: 3.5272021293640137. Accuracy: 25.474\n",
            "Testing: Iteration: 424000. Loss: 3.5272021293640137. Accuracy: 18.79\n",
            "Training: Iteration: 424500. Loss: 3.202620506286621. Accuracy: 25.43\n",
            "Testing: Iteration: 424500. Loss: 3.202620506286621. Accuracy: 18.91\n",
            "Epoch:  543\n",
            "Training: Iteration: 425000. Loss: 3.170397996902466. Accuracy: 25.426\n",
            "Testing: Iteration: 425000. Loss: 3.170397996902466. Accuracy: 18.83\n",
            "Epoch:  544\n",
            "Training: Iteration: 425500. Loss: 3.5636274814605713. Accuracy: 25.456\n",
            "Testing: Iteration: 425500. Loss: 3.5636274814605713. Accuracy: 18.93\n",
            "Training: Iteration: 426000. Loss: 3.630995988845825. Accuracy: 25.498\n",
            "Testing: Iteration: 426000. Loss: 3.630995988845825. Accuracy: 18.79\n",
            "Epoch:  545\n",
            "Training: Iteration: 426500. Loss: 3.307009220123291. Accuracy: 25.47\n",
            "Testing: Iteration: 426500. Loss: 3.307009220123291. Accuracy: 18.85\n",
            "Epoch:  546\n",
            "Training: Iteration: 427000. Loss: 3.4057564735412598. Accuracy: 25.462\n",
            "Testing: Iteration: 427000. Loss: 3.4057564735412598. Accuracy: 18.82\n",
            "Training: Iteration: 427500. Loss: 3.5655527114868164. Accuracy: 25.438\n",
            "Testing: Iteration: 427500. Loss: 3.5655527114868164. Accuracy: 18.85\n",
            "Epoch:  547\n",
            "Training: Iteration: 428000. Loss: 2.8170881271362305. Accuracy: 25.444\n",
            "Testing: Iteration: 428000. Loss: 2.8170881271362305. Accuracy: 18.82\n",
            "Training: Iteration: 428500. Loss: 3.188772678375244. Accuracy: 25.418\n",
            "Testing: Iteration: 428500. Loss: 3.188772678375244. Accuracy: 18.87\n",
            "Epoch:  548\n",
            "Training: Iteration: 429000. Loss: 3.0470786094665527. Accuracy: 25.426\n",
            "Testing: Iteration: 429000. Loss: 3.0470786094665527. Accuracy: 18.81\n",
            "Epoch:  549\n",
            "Training: Iteration: 429500. Loss: 3.4476325511932373. Accuracy: 25.488\n",
            "Testing: Iteration: 429500. Loss: 3.4476325511932373. Accuracy: 18.73\n",
            "Training: Iteration: 430000. Loss: 2.7615795135498047. Accuracy: 25.446\n",
            "Testing: Iteration: 430000. Loss: 2.7615795135498047. Accuracy: 18.9\n",
            "Epoch:  550\n",
            "Training: Iteration: 430500. Loss: 3.7953925132751465. Accuracy: 25.466\n",
            "Testing: Iteration: 430500. Loss: 3.7953925132751465. Accuracy: 18.89\n",
            "Epoch:  551\n",
            "Training: Iteration: 431000. Loss: 2.684612274169922. Accuracy: 25.468\n",
            "Testing: Iteration: 431000. Loss: 2.684612274169922. Accuracy: 18.81\n",
            "Training: Iteration: 431500. Loss: 3.522031307220459. Accuracy: 25.444\n",
            "Testing: Iteration: 431500. Loss: 3.522031307220459. Accuracy: 18.81\n",
            "Epoch:  552\n",
            "Training: Iteration: 432000. Loss: 3.3906962871551514. Accuracy: 25.474\n",
            "Testing: Iteration: 432000. Loss: 3.3906962871551514. Accuracy: 18.79\n",
            "Epoch:  553\n",
            "Training: Iteration: 432500. Loss: 2.9614510536193848. Accuracy: 25.482\n",
            "Testing: Iteration: 432500. Loss: 2.9614510536193848. Accuracy: 18.82\n",
            "Training: Iteration: 433000. Loss: 3.190023183822632. Accuracy: 25.478\n",
            "Testing: Iteration: 433000. Loss: 3.190023183822632. Accuracy: 18.79\n",
            "Epoch:  554\n",
            "Training: Iteration: 433500. Loss: 3.1608903408050537. Accuracy: 25.47\n",
            "Testing: Iteration: 433500. Loss: 3.1608903408050537. Accuracy: 18.78\n",
            "Training: Iteration: 434000. Loss: 3.617997884750366. Accuracy: 25.492\n",
            "Testing: Iteration: 434000. Loss: 3.617997884750366. Accuracy: 18.83\n",
            "Epoch:  555\n",
            "Training: Iteration: 434500. Loss: 3.181183338165283. Accuracy: 25.466\n",
            "Testing: Iteration: 434500. Loss: 3.181183338165283. Accuracy: 18.79\n",
            "Epoch:  556\n",
            "Training: Iteration: 435000. Loss: 3.3310844898223877. Accuracy: 25.432\n",
            "Testing: Iteration: 435000. Loss: 3.3310844898223877. Accuracy: 18.73\n",
            "Training: Iteration: 435500. Loss: 3.1372265815734863. Accuracy: 25.452\n",
            "Testing: Iteration: 435500. Loss: 3.1372265815734863. Accuracy: 18.93\n",
            "Epoch:  557\n",
            "Training: Iteration: 436000. Loss: 3.1551363468170166. Accuracy: 25.482\n",
            "Testing: Iteration: 436000. Loss: 3.1551363468170166. Accuracy: 18.9\n",
            "Epoch:  558\n",
            "Training: Iteration: 436500. Loss: 3.138979911804199. Accuracy: 25.498\n",
            "Testing: Iteration: 436500. Loss: 3.138979911804199. Accuracy: 18.83\n",
            "Training: Iteration: 437000. Loss: 3.4662344455718994. Accuracy: 25.45\n",
            "Testing: Iteration: 437000. Loss: 3.4662344455718994. Accuracy: 18.83\n",
            "Epoch:  559\n",
            "Training: Iteration: 437500. Loss: 3.3887836933135986. Accuracy: 25.44\n",
            "Testing: Iteration: 437500. Loss: 3.3887836933135986. Accuracy: 18.84\n",
            "Epoch:  560\n",
            "Training: Iteration: 438000. Loss: 3.204211950302124. Accuracy: 25.492\n",
            "Testing: Iteration: 438000. Loss: 3.204211950302124. Accuracy: 18.79\n",
            "Training: Iteration: 438500. Loss: 3.1666159629821777. Accuracy: 25.51\n",
            "Testing: Iteration: 438500. Loss: 3.1666159629821777. Accuracy: 18.86\n",
            "Epoch:  561\n",
            "Training: Iteration: 439000. Loss: 2.7305104732513428. Accuracy: 25.522\n",
            "Testing: Iteration: 439000. Loss: 2.7305104732513428. Accuracy: 18.85\n",
            "Epoch:  562\n",
            "Training: Iteration: 439500. Loss: 3.1093342304229736. Accuracy: 25.528\n",
            "Testing: Iteration: 439500. Loss: 3.1093342304229736. Accuracy: 18.88\n",
            "Training: Iteration: 440000. Loss: 3.363736391067505. Accuracy: 25.498\n",
            "Testing: Iteration: 440000. Loss: 3.363736391067505. Accuracy: 18.78\n",
            "Epoch:  563\n",
            "Training: Iteration: 440500. Loss: 3.4316489696502686. Accuracy: 25.476\n",
            "Testing: Iteration: 440500. Loss: 3.4316489696502686. Accuracy: 18.75\n",
            "Training: Iteration: 441000. Loss: 3.4531993865966797. Accuracy: 25.466\n",
            "Testing: Iteration: 441000. Loss: 3.4531993865966797. Accuracy: 18.85\n",
            "Epoch:  564\n",
            "Training: Iteration: 441500. Loss: 3.442511558532715. Accuracy: 25.468\n",
            "Testing: Iteration: 441500. Loss: 3.442511558532715. Accuracy: 18.89\n",
            "Epoch:  565\n",
            "Training: Iteration: 442000. Loss: 3.2805371284484863. Accuracy: 25.496\n",
            "Testing: Iteration: 442000. Loss: 3.2805371284484863. Accuracy: 18.76\n",
            "Training: Iteration: 442500. Loss: 3.1635589599609375. Accuracy: 25.442\n",
            "Testing: Iteration: 442500. Loss: 3.1635589599609375. Accuracy: 18.86\n",
            "Epoch:  566\n",
            "Training: Iteration: 443000. Loss: 3.558300733566284. Accuracy: 25.478\n",
            "Testing: Iteration: 443000. Loss: 3.558300733566284. Accuracy: 18.86\n",
            "Epoch:  567\n",
            "Training: Iteration: 443500. Loss: 3.14158034324646. Accuracy: 25.524\n",
            "Testing: Iteration: 443500. Loss: 3.14158034324646. Accuracy: 18.73\n",
            "Training: Iteration: 444000. Loss: 3.586029529571533. Accuracy: 25.51\n",
            "Testing: Iteration: 444000. Loss: 3.586029529571533. Accuracy: 18.84\n",
            "Epoch:  568\n",
            "Training: Iteration: 444500. Loss: 3.3989744186401367. Accuracy: 25.456\n",
            "Testing: Iteration: 444500. Loss: 3.3989744186401367. Accuracy: 18.84\n",
            "Epoch:  569\n",
            "Training: Iteration: 445000. Loss: 3.379535436630249. Accuracy: 25.464\n",
            "Testing: Iteration: 445000. Loss: 3.379535436630249. Accuracy: 18.79\n",
            "Training: Iteration: 445500. Loss: 3.328242301940918. Accuracy: 25.484\n",
            "Testing: Iteration: 445500. Loss: 3.328242301940918. Accuracy: 18.84\n",
            "Epoch:  570\n",
            "Training: Iteration: 446000. Loss: 3.1074392795562744. Accuracy: 25.512\n",
            "Testing: Iteration: 446000. Loss: 3.1074392795562744. Accuracy: 18.8\n",
            "Training: Iteration: 446500. Loss: 2.9635603427886963. Accuracy: 25.51\n",
            "Testing: Iteration: 446500. Loss: 2.9635603427886963. Accuracy: 18.86\n",
            "Epoch:  571\n",
            "Training: Iteration: 447000. Loss: 2.9111592769622803. Accuracy: 25.472\n",
            "Testing: Iteration: 447000. Loss: 2.9111592769622803. Accuracy: 18.78\n",
            "Epoch:  572\n",
            "Training: Iteration: 447500. Loss: 3.0496644973754883. Accuracy: 25.476\n",
            "Testing: Iteration: 447500. Loss: 3.0496644973754883. Accuracy: 18.7\n",
            "Training: Iteration: 448000. Loss: 3.536167860031128. Accuracy: 25.492\n",
            "Testing: Iteration: 448000. Loss: 3.536167860031128. Accuracy: 18.87\n",
            "Epoch:  573\n",
            "Training: Iteration: 448500. Loss: 3.18729829788208. Accuracy: 25.488\n",
            "Testing: Iteration: 448500. Loss: 3.18729829788208. Accuracy: 18.87\n",
            "Epoch:  574\n",
            "Training: Iteration: 449000. Loss: 3.2576029300689697. Accuracy: 25.502\n",
            "Testing: Iteration: 449000. Loss: 3.2576029300689697. Accuracy: 18.89\n",
            "Training: Iteration: 449500. Loss: 3.4802048206329346. Accuracy: 25.482\n",
            "Testing: Iteration: 449500. Loss: 3.4802048206329346. Accuracy: 18.76\n",
            "Epoch:  575\n",
            "Training: Iteration: 450000. Loss: 3.5037894248962402. Accuracy: 25.476\n",
            "Testing: Iteration: 450000. Loss: 3.5037894248962402. Accuracy: 18.79\n",
            "Epoch:  576\n",
            "Training: Iteration: 450500. Loss: 3.299426317214966. Accuracy: 25.492\n",
            "Testing: Iteration: 450500. Loss: 3.299426317214966. Accuracy: 18.77\n",
            "Training: Iteration: 451000. Loss: 2.878377914428711. Accuracy: 25.528\n",
            "Testing: Iteration: 451000. Loss: 2.878377914428711. Accuracy: 18.76\n",
            "Epoch:  577\n",
            "Training: Iteration: 451500. Loss: 3.1205813884735107. Accuracy: 25.518\n",
            "Testing: Iteration: 451500. Loss: 3.1205813884735107. Accuracy: 18.78\n",
            "Epoch:  578\n",
            "Training: Iteration: 452000. Loss: 3.156942129135132. Accuracy: 25.566\n",
            "Testing: Iteration: 452000. Loss: 3.156942129135132. Accuracy: 18.81\n",
            "Training: Iteration: 452500. Loss: 3.619034767150879. Accuracy: 25.52\n",
            "Testing: Iteration: 452500. Loss: 3.619034767150879. Accuracy: 18.78\n",
            "Epoch:  579\n",
            "Training: Iteration: 453000. Loss: 3.122659683227539. Accuracy: 25.456\n",
            "Testing: Iteration: 453000. Loss: 3.122659683227539. Accuracy: 18.72\n",
            "Training: Iteration: 453500. Loss: 3.007450819015503. Accuracy: 25.472\n",
            "Testing: Iteration: 453500. Loss: 3.007450819015503. Accuracy: 18.82\n",
            "Epoch:  580\n",
            "Training: Iteration: 454000. Loss: 3.552952766418457. Accuracy: 25.506\n",
            "Testing: Iteration: 454000. Loss: 3.552952766418457. Accuracy: 18.86\n",
            "Epoch:  581\n",
            "Training: Iteration: 454500. Loss: 3.254070997238159. Accuracy: 25.55\n",
            "Testing: Iteration: 454500. Loss: 3.254070997238159. Accuracy: 18.79\n",
            "Training: Iteration: 455000. Loss: 3.167396306991577. Accuracy: 25.476\n",
            "Testing: Iteration: 455000. Loss: 3.167396306991577. Accuracy: 18.87\n",
            "Epoch:  582\n",
            "Training: Iteration: 455500. Loss: 3.128481149673462. Accuracy: 25.484\n",
            "Testing: Iteration: 455500. Loss: 3.128481149673462. Accuracy: 18.83\n",
            "Epoch:  583\n",
            "Training: Iteration: 456000. Loss: 3.4332187175750732. Accuracy: 25.562\n",
            "Testing: Iteration: 456000. Loss: 3.4332187175750732. Accuracy: 18.77\n",
            "Training: Iteration: 456500. Loss: 3.204174041748047. Accuracy: 25.562\n",
            "Testing: Iteration: 456500. Loss: 3.204174041748047. Accuracy: 18.8\n",
            "Epoch:  584\n",
            "Training: Iteration: 457000. Loss: 3.3916854858398438. Accuracy: 25.552\n",
            "Testing: Iteration: 457000. Loss: 3.3916854858398438. Accuracy: 18.76\n",
            "Epoch:  585\n",
            "Training: Iteration: 457500. Loss: 3.451951265335083. Accuracy: 25.528\n",
            "Testing: Iteration: 457500. Loss: 3.451951265335083. Accuracy: 18.75\n",
            "Training: Iteration: 458000. Loss: 3.322632312774658. Accuracy: 25.49\n",
            "Testing: Iteration: 458000. Loss: 3.322632312774658. Accuracy: 18.75\n",
            "Epoch:  586\n",
            "Training: Iteration: 458500. Loss: 3.2590157985687256. Accuracy: 25.54\n",
            "Testing: Iteration: 458500. Loss: 3.2590157985687256. Accuracy: 18.75\n",
            "Training: Iteration: 459000. Loss: 3.5487241744995117. Accuracy: 25.492\n",
            "Testing: Iteration: 459000. Loss: 3.5487241744995117. Accuracy: 18.81\n",
            "Epoch:  587\n",
            "Training: Iteration: 459500. Loss: 3.1463255882263184. Accuracy: 25.504\n",
            "Testing: Iteration: 459500. Loss: 3.1463255882263184. Accuracy: 18.79\n",
            "Epoch:  588\n",
            "Training: Iteration: 460000. Loss: 3.192499876022339. Accuracy: 25.574\n",
            "Testing: Iteration: 460000. Loss: 3.192499876022339. Accuracy: 18.76\n",
            "Training: Iteration: 460500. Loss: 3.4395666122436523. Accuracy: 25.53\n",
            "Testing: Iteration: 460500. Loss: 3.4395666122436523. Accuracy: 18.85\n",
            "Epoch:  589\n",
            "Training: Iteration: 461000. Loss: 3.247772216796875. Accuracy: 25.54\n",
            "Testing: Iteration: 461000. Loss: 3.247772216796875. Accuracy: 18.86\n",
            "Epoch:  590\n",
            "Training: Iteration: 461500. Loss: 2.9551613330841064. Accuracy: 25.506\n",
            "Testing: Iteration: 461500. Loss: 2.9551613330841064. Accuracy: 18.74\n",
            "Training: Iteration: 462000. Loss: 3.1913721561431885. Accuracy: 25.514\n",
            "Testing: Iteration: 462000. Loss: 3.1913721561431885. Accuracy: 18.74\n",
            "Epoch:  591\n",
            "Training: Iteration: 462500. Loss: 3.4655141830444336. Accuracy: 25.512\n",
            "Testing: Iteration: 462500. Loss: 3.4655141830444336. Accuracy: 18.75\n",
            "Epoch:  592\n",
            "Training: Iteration: 463000. Loss: 3.365192413330078. Accuracy: 25.546\n",
            "Testing: Iteration: 463000. Loss: 3.365192413330078. Accuracy: 18.7\n",
            "Training: Iteration: 463500. Loss: 3.3932113647460938. Accuracy: 25.542\n",
            "Testing: Iteration: 463500. Loss: 3.3932113647460938. Accuracy: 18.77\n",
            "Epoch:  593\n",
            "Training: Iteration: 464000. Loss: 3.417893409729004. Accuracy: 25.54\n",
            "Testing: Iteration: 464000. Loss: 3.417893409729004. Accuracy: 18.7\n",
            "Training: Iteration: 464500. Loss: 3.2722504138946533. Accuracy: 25.524\n",
            "Testing: Iteration: 464500. Loss: 3.2722504138946533. Accuracy: 18.78\n",
            "Epoch:  594\n",
            "Training: Iteration: 465000. Loss: 3.047635793685913. Accuracy: 25.518\n",
            "Testing: Iteration: 465000. Loss: 3.047635793685913. Accuracy: 18.73\n",
            "Epoch:  595\n",
            "Training: Iteration: 465500. Loss: 2.776716947555542. Accuracy: 25.526\n",
            "Testing: Iteration: 465500. Loss: 2.776716947555542. Accuracy: 18.61\n",
            "Training: Iteration: 466000. Loss: 3.2800357341766357. Accuracy: 25.518\n",
            "Testing: Iteration: 466000. Loss: 3.2800357341766357. Accuracy: 18.85\n",
            "Epoch:  596\n",
            "Training: Iteration: 466500. Loss: 3.300628900527954. Accuracy: 25.558\n",
            "Testing: Iteration: 466500. Loss: 3.300628900527954. Accuracy: 18.84\n",
            "Epoch:  597\n",
            "Training: Iteration: 467000. Loss: 3.5020666122436523. Accuracy: 25.556\n",
            "Testing: Iteration: 467000. Loss: 3.5020666122436523. Accuracy: 18.72\n",
            "Training: Iteration: 467500. Loss: 3.208850383758545. Accuracy: 25.49\n",
            "Testing: Iteration: 467500. Loss: 3.208850383758545. Accuracy: 18.81\n",
            "Epoch:  598\n",
            "Training: Iteration: 468000. Loss: 3.3802273273468018. Accuracy: 25.54\n",
            "Testing: Iteration: 468000. Loss: 3.3802273273468018. Accuracy: 18.8\n",
            "Epoch:  599\n",
            "Training: Iteration: 468500. Loss: 3.3344733715057373. Accuracy: 25.578\n",
            "Testing: Iteration: 468500. Loss: 3.3344733715057373. Accuracy: 18.71\n",
            "Training: Iteration: 469000. Loss: 2.9567291736602783. Accuracy: 25.556\n",
            "Testing: Iteration: 469000. Loss: 2.9567291736602783. Accuracy: 18.79\n",
            "Epoch:  600\n",
            "Training: Iteration: 469500. Loss: 3.432896137237549. Accuracy: 25.548\n",
            "Testing: Iteration: 469500. Loss: 3.432896137237549. Accuracy: 18.73\n",
            "Epoch:  601\n",
            "Training: Iteration: 470000. Loss: 3.0417416095733643. Accuracy: 25.556\n",
            "Testing: Iteration: 470000. Loss: 3.0417416095733643. Accuracy: 18.77\n",
            "Training: Iteration: 470500. Loss: 2.899381160736084. Accuracy: 25.52\n",
            "Testing: Iteration: 470500. Loss: 2.899381160736084. Accuracy: 18.65\n",
            "Epoch:  602\n",
            "Training: Iteration: 471000. Loss: 3.225739002227783. Accuracy: 25.558\n",
            "Testing: Iteration: 471000. Loss: 3.225739002227783. Accuracy: 18.68\n",
            "Training: Iteration: 471500. Loss: 2.9875009059906006. Accuracy: 25.484\n",
            "Testing: Iteration: 471500. Loss: 2.9875009059906006. Accuracy: 18.77\n",
            "Epoch:  603\n",
            "Training: Iteration: 472000. Loss: 3.300668239593506. Accuracy: 25.508\n",
            "Testing: Iteration: 472000. Loss: 3.300668239593506. Accuracy: 18.76\n",
            "Epoch:  604\n",
            "Training: Iteration: 472500. Loss: 2.8847343921661377. Accuracy: 25.596\n",
            "Testing: Iteration: 472500. Loss: 2.8847343921661377. Accuracy: 18.72\n",
            "Training: Iteration: 473000. Loss: 3.369612216949463. Accuracy: 25.508\n",
            "Testing: Iteration: 473000. Loss: 3.369612216949463. Accuracy: 18.84\n",
            "Epoch:  605\n",
            "Training: Iteration: 473500. Loss: 3.2448456287384033. Accuracy: 25.588\n",
            "Testing: Iteration: 473500. Loss: 3.2448456287384033. Accuracy: 18.79\n",
            "Epoch:  606\n",
            "Training: Iteration: 474000. Loss: 3.126957893371582. Accuracy: 25.568\n",
            "Testing: Iteration: 474000. Loss: 3.126957893371582. Accuracy: 18.67\n",
            "Training: Iteration: 474500. Loss: 3.369856357574463. Accuracy: 25.562\n",
            "Testing: Iteration: 474500. Loss: 3.369856357574463. Accuracy: 18.79\n",
            "Epoch:  607\n",
            "Training: Iteration: 475000. Loss: 2.9088242053985596. Accuracy: 25.516\n",
            "Testing: Iteration: 475000. Loss: 2.9088242053985596. Accuracy: 18.76\n",
            "Epoch:  608\n",
            "Training: Iteration: 475500. Loss: 3.0449745655059814. Accuracy: 25.538\n",
            "Testing: Iteration: 475500. Loss: 3.0449745655059814. Accuracy: 18.71\n",
            "Training: Iteration: 476000. Loss: 3.1476430892944336. Accuracy: 25.524\n",
            "Testing: Iteration: 476000. Loss: 3.1476430892944336. Accuracy: 18.69\n",
            "Epoch:  609\n",
            "Training: Iteration: 476500. Loss: 3.099813222885132. Accuracy: 25.562\n",
            "Testing: Iteration: 476500. Loss: 3.099813222885132. Accuracy: 18.68\n",
            "Training: Iteration: 477000. Loss: 2.9687912464141846. Accuracy: 25.518\n",
            "Testing: Iteration: 477000. Loss: 2.9687912464141846. Accuracy: 18.74\n",
            "Epoch:  610\n",
            "Training: Iteration: 477500. Loss: 3.2489261627197266. Accuracy: 25.528\n",
            "Testing: Iteration: 477500. Loss: 3.2489261627197266. Accuracy: 18.7\n",
            "Epoch:  611\n",
            "Training: Iteration: 478000. Loss: 3.378551483154297. Accuracy: 25.544\n",
            "Testing: Iteration: 478000. Loss: 3.378551483154297. Accuracy: 18.66\n",
            "Training: Iteration: 478500. Loss: 3.2552216053009033. Accuracy: 25.53\n",
            "Testing: Iteration: 478500. Loss: 3.2552216053009033. Accuracy: 18.83\n",
            "Epoch:  612\n",
            "Training: Iteration: 479000. Loss: 3.097940683364868. Accuracy: 25.546\n",
            "Testing: Iteration: 479000. Loss: 3.097940683364868. Accuracy: 18.81\n",
            "Epoch:  613\n",
            "Training: Iteration: 479500. Loss: 3.3301596641540527. Accuracy: 25.552\n",
            "Testing: Iteration: 479500. Loss: 3.3301596641540527. Accuracy: 18.78\n",
            "Training: Iteration: 480000. Loss: 3.068403959274292. Accuracy: 25.52\n",
            "Testing: Iteration: 480000. Loss: 3.068403959274292. Accuracy: 18.8\n",
            "Epoch:  614\n",
            "Training: Iteration: 480500. Loss: 3.131136417388916. Accuracy: 25.548\n",
            "Testing: Iteration: 480500. Loss: 3.131136417388916. Accuracy: 18.73\n",
            "Epoch:  615\n",
            "Training: Iteration: 481000. Loss: 3.6727347373962402. Accuracy: 25.58\n",
            "Testing: Iteration: 481000. Loss: 3.6727347373962402. Accuracy: 18.68\n",
            "Training: Iteration: 481500. Loss: 3.7525241374969482. Accuracy: 25.558\n",
            "Testing: Iteration: 481500. Loss: 3.7525241374969482. Accuracy: 18.73\n",
            "Epoch:  616\n",
            "Training: Iteration: 482000. Loss: 3.1048903465270996. Accuracy: 25.56\n",
            "Testing: Iteration: 482000. Loss: 3.1048903465270996. Accuracy: 18.73\n",
            "Epoch:  617\n",
            "Training: Iteration: 482500. Loss: 3.093982219696045. Accuracy: 25.622\n",
            "Testing: Iteration: 482500. Loss: 3.093982219696045. Accuracy: 18.68\n",
            "Training: Iteration: 483000. Loss: 2.964869260787964. Accuracy: 25.492\n",
            "Testing: Iteration: 483000. Loss: 2.964869260787964. Accuracy: 18.65\n",
            "Epoch:  618\n",
            "Training: Iteration: 483500. Loss: 3.3698551654815674. Accuracy: 25.546\n",
            "Testing: Iteration: 483500. Loss: 3.3698551654815674. Accuracy: 18.67\n",
            "Training: Iteration: 484000. Loss: 3.1897168159484863. Accuracy: 25.528\n",
            "Testing: Iteration: 484000. Loss: 3.1897168159484863. Accuracy: 18.76\n",
            "Epoch:  619\n",
            "Training: Iteration: 484500. Loss: 3.319981575012207. Accuracy: 25.546\n",
            "Testing: Iteration: 484500. Loss: 3.319981575012207. Accuracy: 18.79\n",
            "Epoch:  620\n",
            "Training: Iteration: 485000. Loss: 3.4070370197296143. Accuracy: 25.614\n",
            "Testing: Iteration: 485000. Loss: 3.4070370197296143. Accuracy: 18.7\n",
            "Training: Iteration: 485500. Loss: 3.0409581661224365. Accuracy: 25.498\n",
            "Testing: Iteration: 485500. Loss: 3.0409581661224365. Accuracy: 18.77\n",
            "Epoch:  621\n",
            "Training: Iteration: 486000. Loss: 3.619701862335205. Accuracy: 25.594\n",
            "Testing: Iteration: 486000. Loss: 3.619701862335205. Accuracy: 18.69\n",
            "Epoch:  622\n",
            "Training: Iteration: 486500. Loss: 3.389180898666382. Accuracy: 25.614\n",
            "Testing: Iteration: 486500. Loss: 3.389180898666382. Accuracy: 18.62\n",
            "Training: Iteration: 487000. Loss: 3.4372799396514893. Accuracy: 25.564\n",
            "Testing: Iteration: 487000. Loss: 3.4372799396514893. Accuracy: 18.77\n",
            "Epoch:  623\n",
            "Training: Iteration: 487500. Loss: 3.291205644607544. Accuracy: 25.582\n",
            "Testing: Iteration: 487500. Loss: 3.291205644607544. Accuracy: 18.67\n",
            "Epoch:  624\n",
            "Training: Iteration: 488000. Loss: 3.2443788051605225. Accuracy: 25.572\n",
            "Testing: Iteration: 488000. Loss: 3.2443788051605225. Accuracy: 18.67\n",
            "Training: Iteration: 488500. Loss: 3.148138999938965. Accuracy: 25.514\n",
            "Testing: Iteration: 488500. Loss: 3.148138999938965. Accuracy: 18.63\n",
            "Epoch:  625\n",
            "Training: Iteration: 489000. Loss: 3.0694706439971924. Accuracy: 25.604\n",
            "Testing: Iteration: 489000. Loss: 3.0694706439971924. Accuracy: 18.66\n",
            "Training: Iteration: 489500. Loss: 2.876539707183838. Accuracy: 25.548\n",
            "Testing: Iteration: 489500. Loss: 2.876539707183838. Accuracy: 18.66\n",
            "Epoch:  626\n",
            "Training: Iteration: 490000. Loss: 3.3669633865356445. Accuracy: 25.552\n",
            "Testing: Iteration: 490000. Loss: 3.3669633865356445. Accuracy: 18.59\n",
            "Epoch:  627\n",
            "Training: Iteration: 490500. Loss: 3.0700035095214844. Accuracy: 25.646\n",
            "Testing: Iteration: 490500. Loss: 3.0700035095214844. Accuracy: 18.67\n",
            "Training: Iteration: 491000. Loss: 3.5494089126586914. Accuracy: 25.534\n",
            "Testing: Iteration: 491000. Loss: 3.5494089126586914. Accuracy: 18.78\n",
            "Epoch:  628\n",
            "Training: Iteration: 491500. Loss: 3.159635305404663. Accuracy: 25.59\n",
            "Testing: Iteration: 491500. Loss: 3.159635305404663. Accuracy: 18.73\n",
            "Epoch:  629\n",
            "Training: Iteration: 492000. Loss: 3.237536907196045. Accuracy: 25.562\n",
            "Testing: Iteration: 492000. Loss: 3.237536907196045. Accuracy: 18.69\n",
            "Training: Iteration: 492500. Loss: 3.2645790576934814. Accuracy: 25.55\n",
            "Testing: Iteration: 492500. Loss: 3.2645790576934814. Accuracy: 18.71\n",
            "Epoch:  630\n",
            "Training: Iteration: 493000. Loss: 3.3159050941467285. Accuracy: 25.564\n",
            "Testing: Iteration: 493000. Loss: 3.3159050941467285. Accuracy: 18.66\n",
            "Epoch:  631\n",
            "Training: Iteration: 493500. Loss: 3.483715772628784. Accuracy: 25.586\n",
            "Testing: Iteration: 493500. Loss: 3.483715772628784. Accuracy: 18.7\n",
            "Training: Iteration: 494000. Loss: 3.046640634536743. Accuracy: 25.584\n",
            "Testing: Iteration: 494000. Loss: 3.046640634536743. Accuracy: 18.67\n",
            "Epoch:  632\n",
            "Training: Iteration: 494500. Loss: 3.1262247562408447. Accuracy: 25.566\n",
            "Testing: Iteration: 494500. Loss: 3.1262247562408447. Accuracy: 18.67\n",
            "Training: Iteration: 495000. Loss: 3.712360382080078. Accuracy: 25.604\n",
            "Testing: Iteration: 495000. Loss: 3.712360382080078. Accuracy: 18.67\n",
            "Epoch:  633\n",
            "Training: Iteration: 495500. Loss: 3.3392691612243652. Accuracy: 25.54\n",
            "Testing: Iteration: 495500. Loss: 3.3392691612243652. Accuracy: 18.64\n",
            "Epoch:  634\n",
            "Training: Iteration: 496000. Loss: 3.2110989093780518. Accuracy: 25.6\n",
            "Testing: Iteration: 496000. Loss: 3.2110989093780518. Accuracy: 18.59\n",
            "Training: Iteration: 496500. Loss: 3.169517755508423. Accuracy: 25.564\n",
            "Testing: Iteration: 496500. Loss: 3.169517755508423. Accuracy: 18.76\n",
            "Epoch:  635\n",
            "Training: Iteration: 497000. Loss: 3.211634635925293. Accuracy: 25.624\n",
            "Testing: Iteration: 497000. Loss: 3.211634635925293. Accuracy: 18.78\n",
            "Epoch:  636\n",
            "Training: Iteration: 497500. Loss: 3.2354254722595215. Accuracy: 25.624\n",
            "Testing: Iteration: 497500. Loss: 3.2354254722595215. Accuracy: 18.7\n",
            "Training: Iteration: 498000. Loss: 3.1007273197174072. Accuracy: 25.512\n",
            "Testing: Iteration: 498000. Loss: 3.1007273197174072. Accuracy: 18.7\n",
            "Epoch:  637\n",
            "Training: Iteration: 498500. Loss: 3.2774972915649414. Accuracy: 25.594\n",
            "Testing: Iteration: 498500. Loss: 3.2774972915649414. Accuracy: 18.72\n",
            "Epoch:  638\n",
            "Training: Iteration: 499000. Loss: 3.245575428009033. Accuracy: 25.61\n",
            "Testing: Iteration: 499000. Loss: 3.245575428009033. Accuracy: 18.57\n",
            "Training: Iteration: 499500. Loss: 3.35225510597229. Accuracy: 25.612\n",
            "Testing: Iteration: 499500. Loss: 3.35225510597229. Accuracy: 18.68\n",
            "Epoch:  639\n",
            "Training: Iteration: 500000. Loss: 2.9563357830047607. Accuracy: 25.612\n",
            "Testing: Iteration: 500000. Loss: 2.9563357830047607. Accuracy: 18.67\n",
            "Epoch:  640\n",
            "Training: Iteration: 500500. Loss: 3.195082902908325. Accuracy: 25.588\n",
            "Testing: Iteration: 500500. Loss: 3.195082902908325. Accuracy: 18.66\n",
            "Training: Iteration: 501000. Loss: 3.1939003467559814. Accuracy: 25.558\n",
            "Testing: Iteration: 501000. Loss: 3.1939003467559814. Accuracy: 18.62\n",
            "Epoch:  641\n",
            "Training: Iteration: 501500. Loss: 3.139068365097046. Accuracy: 25.622\n",
            "Testing: Iteration: 501500. Loss: 3.139068365097046. Accuracy: 18.63\n",
            "Training: Iteration: 502000. Loss: 3.8245456218719482. Accuracy: 25.582\n",
            "Testing: Iteration: 502000. Loss: 3.8245456218719482. Accuracy: 18.67\n",
            "Epoch:  642\n",
            "Training: Iteration: 502500. Loss: 3.0209009647369385. Accuracy: 25.572\n",
            "Testing: Iteration: 502500. Loss: 3.0209009647369385. Accuracy: 18.65\n",
            "Epoch:  643\n",
            "Training: Iteration: 503000. Loss: 2.913033962249756. Accuracy: 25.668\n",
            "Testing: Iteration: 503000. Loss: 2.913033962249756. Accuracy: 18.67\n",
            "Training: Iteration: 503500. Loss: 3.1990416049957275. Accuracy: 25.57\n",
            "Testing: Iteration: 503500. Loss: 3.1990416049957275. Accuracy: 18.72\n",
            "Epoch:  644\n",
            "Training: Iteration: 504000. Loss: 3.516759157180786. Accuracy: 25.604\n",
            "Testing: Iteration: 504000. Loss: 3.516759157180786. Accuracy: 18.68\n",
            "Epoch:  645\n",
            "Training: Iteration: 504500. Loss: 3.093912124633789. Accuracy: 25.618\n",
            "Testing: Iteration: 504500. Loss: 3.093912124633789. Accuracy: 18.64\n",
            "Training: Iteration: 505000. Loss: 3.134777069091797. Accuracy: 25.594\n",
            "Testing: Iteration: 505000. Loss: 3.134777069091797. Accuracy: 18.75\n",
            "Epoch:  646\n",
            "Training: Iteration: 505500. Loss: 2.904265880584717. Accuracy: 25.55\n",
            "Testing: Iteration: 505500. Loss: 2.904265880584717. Accuracy: 18.64\n",
            "Epoch:  647\n",
            "Training: Iteration: 506000. Loss: 3.4097321033477783. Accuracy: 25.578\n",
            "Testing: Iteration: 506000. Loss: 3.4097321033477783. Accuracy: 18.59\n",
            "Training: Iteration: 506500. Loss: 3.528977870941162. Accuracy: 25.576\n",
            "Testing: Iteration: 506500. Loss: 3.528977870941162. Accuracy: 18.58\n",
            "Epoch:  648\n",
            "Training: Iteration: 507000. Loss: 3.002945899963379. Accuracy: 25.638\n",
            "Testing: Iteration: 507000. Loss: 3.002945899963379. Accuracy: 18.63\n",
            "Training: Iteration: 507500. Loss: 3.2902514934539795. Accuracy: 25.588\n",
            "Testing: Iteration: 507500. Loss: 3.2902514934539795. Accuracy: 18.61\n",
            "Epoch:  649\n",
            "Training: Iteration: 508000. Loss: 2.909419536590576. Accuracy: 25.572\n",
            "Testing: Iteration: 508000. Loss: 2.909419536590576. Accuracy: 18.59\n",
            "Epoch:  650\n",
            "Training: Iteration: 508500. Loss: 3.3601150512695312. Accuracy: 25.636\n",
            "Testing: Iteration: 508500. Loss: 3.3601150512695312. Accuracy: 18.64\n",
            "Training: Iteration: 509000. Loss: 3.5056233406066895. Accuracy: 25.56\n",
            "Testing: Iteration: 509000. Loss: 3.5056233406066895. Accuracy: 18.71\n",
            "Epoch:  651\n",
            "Training: Iteration: 509500. Loss: 3.4204866886138916. Accuracy: 25.61\n",
            "Testing: Iteration: 509500. Loss: 3.4204866886138916. Accuracy: 18.73\n",
            "Epoch:  652\n",
            "Training: Iteration: 510000. Loss: 3.3110759258270264. Accuracy: 25.602\n",
            "Testing: Iteration: 510000. Loss: 3.3110759258270264. Accuracy: 18.76\n",
            "Training: Iteration: 510500. Loss: 2.874768018722534. Accuracy: 25.574\n",
            "Testing: Iteration: 510500. Loss: 2.874768018722534. Accuracy: 18.72\n",
            "Epoch:  653\n",
            "Training: Iteration: 511000. Loss: 3.268033027648926. Accuracy: 25.568\n",
            "Testing: Iteration: 511000. Loss: 3.268033027648926. Accuracy: 18.63\n",
            "Epoch:  654\n",
            "Training: Iteration: 511500. Loss: 3.169781446456909. Accuracy: 25.626\n",
            "Testing: Iteration: 511500. Loss: 3.169781446456909. Accuracy: 18.59\n",
            "Training: Iteration: 512000. Loss: 3.2711453437805176. Accuracy: 25.604\n",
            "Testing: Iteration: 512000. Loss: 3.2711453437805176. Accuracy: 18.66\n",
            "Epoch:  655\n",
            "Training: Iteration: 512500. Loss: 3.437389373779297. Accuracy: 25.614\n",
            "Testing: Iteration: 512500. Loss: 3.437389373779297. Accuracy: 18.63\n",
            "Epoch:  656\n",
            "Training: Iteration: 513000. Loss: 3.0283241271972656. Accuracy: 25.652\n",
            "Testing: Iteration: 513000. Loss: 3.0283241271972656. Accuracy: 18.72\n",
            "Training: Iteration: 513500. Loss: 3.384249210357666. Accuracy: 25.566\n",
            "Testing: Iteration: 513500. Loss: 3.384249210357666. Accuracy: 18.6\n",
            "Epoch:  657\n",
            "Training: Iteration: 514000. Loss: 3.387629270553589. Accuracy: 25.612\n",
            "Testing: Iteration: 514000. Loss: 3.387629270553589. Accuracy: 18.58\n",
            "Training: Iteration: 514500. Loss: 3.235219717025757. Accuracy: 25.602\n",
            "Testing: Iteration: 514500. Loss: 3.235219717025757. Accuracy: 18.7\n",
            "Epoch:  658\n",
            "Training: Iteration: 515000. Loss: 3.3613712787628174. Accuracy: 25.594\n",
            "Testing: Iteration: 515000. Loss: 3.3613712787628174. Accuracy: 18.68\n",
            "Epoch:  659\n",
            "Training: Iteration: 515500. Loss: 2.99114990234375. Accuracy: 25.63\n",
            "Testing: Iteration: 515500. Loss: 2.99114990234375. Accuracy: 18.66\n",
            "Training: Iteration: 516000. Loss: 3.2718307971954346. Accuracy: 25.55\n",
            "Testing: Iteration: 516000. Loss: 3.2718307971954346. Accuracy: 18.67\n",
            "Epoch:  660\n",
            "Training: Iteration: 516500. Loss: 3.16848087310791. Accuracy: 25.578\n",
            "Testing: Iteration: 516500. Loss: 3.16848087310791. Accuracy: 18.69\n",
            "Epoch:  661\n",
            "Training: Iteration: 517000. Loss: 3.540590763092041. Accuracy: 25.666\n",
            "Testing: Iteration: 517000. Loss: 3.540590763092041. Accuracy: 18.59\n",
            "Training: Iteration: 517500. Loss: 3.0532379150390625. Accuracy: 25.626\n",
            "Testing: Iteration: 517500. Loss: 3.0532379150390625. Accuracy: 18.68\n",
            "Epoch:  662\n",
            "Training: Iteration: 518000. Loss: 3.7283902168273926. Accuracy: 25.586\n",
            "Testing: Iteration: 518000. Loss: 3.7283902168273926. Accuracy: 18.59\n",
            "Epoch:  663\n",
            "Training: Iteration: 518500. Loss: 3.1026790142059326. Accuracy: 25.608\n",
            "Testing: Iteration: 518500. Loss: 3.1026790142059326. Accuracy: 18.6\n",
            "Training: Iteration: 519000. Loss: 3.0274853706359863. Accuracy: 25.604\n",
            "Testing: Iteration: 519000. Loss: 3.0274853706359863. Accuracy: 18.49\n",
            "Epoch:  664\n",
            "Training: Iteration: 519500. Loss: 3.662750005722046. Accuracy: 25.668\n",
            "Testing: Iteration: 519500. Loss: 3.662750005722046. Accuracy: 18.63\n",
            "Training: Iteration: 520000. Loss: 3.5251269340515137. Accuracy: 25.582\n",
            "Testing: Iteration: 520000. Loss: 3.5251269340515137. Accuracy: 18.65\n",
            "Epoch:  665\n",
            "Training: Iteration: 520500. Loss: 3.1668996810913086. Accuracy: 25.582\n",
            "Testing: Iteration: 520500. Loss: 3.1668996810913086. Accuracy: 18.5\n",
            "Epoch:  666\n",
            "Training: Iteration: 521000. Loss: 3.542928457260132. Accuracy: 25.678\n",
            "Testing: Iteration: 521000. Loss: 3.542928457260132. Accuracy: 18.66\n",
            "Training: Iteration: 521500. Loss: 3.0251595973968506. Accuracy: 25.624\n",
            "Testing: Iteration: 521500. Loss: 3.0251595973968506. Accuracy: 18.69\n",
            "Epoch:  667\n",
            "Training: Iteration: 522000. Loss: 3.8378849029541016. Accuracy: 25.632\n",
            "Testing: Iteration: 522000. Loss: 3.8378849029541016. Accuracy: 18.67\n",
            "Epoch:  668\n",
            "Training: Iteration: 522500. Loss: 3.2112767696380615. Accuracy: 25.61\n",
            "Testing: Iteration: 522500. Loss: 3.2112767696380615. Accuracy: 18.63\n",
            "Training: Iteration: 523000. Loss: 2.981752634048462. Accuracy: 25.62\n",
            "Testing: Iteration: 523000. Loss: 2.981752634048462. Accuracy: 18.69\n",
            "Epoch:  669\n",
            "Training: Iteration: 523500. Loss: 3.513655424118042. Accuracy: 25.586\n",
            "Testing: Iteration: 523500. Loss: 3.513655424118042. Accuracy: 18.58\n",
            "Epoch:  670\n",
            "Training: Iteration: 524000. Loss: 3.031987190246582. Accuracy: 25.642\n",
            "Testing: Iteration: 524000. Loss: 3.031987190246582. Accuracy: 18.61\n",
            "Training: Iteration: 524500. Loss: 3.250331401824951. Accuracy: 25.656\n",
            "Testing: Iteration: 524500. Loss: 3.250331401824951. Accuracy: 18.62\n",
            "Epoch:  671\n",
            "Training: Iteration: 525000. Loss: 3.4083635807037354. Accuracy: 25.618\n",
            "Testing: Iteration: 525000. Loss: 3.4083635807037354. Accuracy: 18.61\n",
            "Training: Iteration: 525500. Loss: 3.286355972290039. Accuracy: 25.66\n",
            "Testing: Iteration: 525500. Loss: 3.286355972290039. Accuracy: 18.59\n",
            "Epoch:  672\n",
            "Training: Iteration: 526000. Loss: 3.421738386154175. Accuracy: 25.6\n",
            "Testing: Iteration: 526000. Loss: 3.421738386154175. Accuracy: 18.57\n",
            "Epoch:  673\n",
            "Training: Iteration: 526500. Loss: 3.5112252235412598. Accuracy: 25.64\n",
            "Testing: Iteration: 526500. Loss: 3.5112252235412598. Accuracy: 18.54\n",
            "Training: Iteration: 527000. Loss: 3.2908096313476562. Accuracy: 25.638\n",
            "Testing: Iteration: 527000. Loss: 3.2908096313476562. Accuracy: 18.67\n",
            "Epoch:  674\n",
            "Training: Iteration: 527500. Loss: 3.7013981342315674. Accuracy: 25.62\n",
            "Testing: Iteration: 527500. Loss: 3.7013981342315674. Accuracy: 18.67\n",
            "Epoch:  675\n",
            "Training: Iteration: 528000. Loss: 3.4011707305908203. Accuracy: 25.65\n",
            "Testing: Iteration: 528000. Loss: 3.4011707305908203. Accuracy: 18.67\n",
            "Training: Iteration: 528500. Loss: 3.285254716873169. Accuracy: 25.576\n",
            "Testing: Iteration: 528500. Loss: 3.285254716873169. Accuracy: 18.65\n",
            "Epoch:  676\n",
            "Training: Iteration: 529000. Loss: 3.261620044708252. Accuracy: 25.612\n",
            "Testing: Iteration: 529000. Loss: 3.261620044708252. Accuracy: 18.67\n",
            "Epoch:  677\n",
            "Training: Iteration: 529500. Loss: 3.354914426803589. Accuracy: 25.652\n",
            "Testing: Iteration: 529500. Loss: 3.354914426803589. Accuracy: 18.58\n",
            "Training: Iteration: 530000. Loss: 3.1401970386505127. Accuracy: 25.652\n",
            "Testing: Iteration: 530000. Loss: 3.1401970386505127. Accuracy: 18.56\n",
            "Epoch:  678\n",
            "Training: Iteration: 530500. Loss: 3.58801531791687. Accuracy: 25.67\n",
            "Testing: Iteration: 530500. Loss: 3.58801531791687. Accuracy: 18.62\n",
            "Epoch:  679\n",
            "Training: Iteration: 531000. Loss: 3.489018201828003. Accuracy: 25.682\n",
            "Testing: Iteration: 531000. Loss: 3.489018201828003. Accuracy: 18.59\n",
            "Training: Iteration: 531500. Loss: 3.0421533584594727. Accuracy: 25.63\n",
            "Testing: Iteration: 531500. Loss: 3.0421533584594727. Accuracy: 18.58\n",
            "Epoch:  680\n",
            "Training: Iteration: 532000. Loss: 3.160048007965088. Accuracy: 25.676\n",
            "Testing: Iteration: 532000. Loss: 3.160048007965088. Accuracy: 18.59\n",
            "Training: Iteration: 532500. Loss: 3.235710382461548. Accuracy: 25.618\n",
            "Testing: Iteration: 532500. Loss: 3.235710382461548. Accuracy: 18.63\n",
            "Epoch:  681\n",
            "Training: Iteration: 533000. Loss: 3.085191249847412. Accuracy: 25.63\n",
            "Testing: Iteration: 533000. Loss: 3.085191249847412. Accuracy: 18.6\n",
            "Epoch:  682\n",
            "Training: Iteration: 533500. Loss: 3.2233943939208984. Accuracy: 25.682\n",
            "Testing: Iteration: 533500. Loss: 3.2233943939208984. Accuracy: 18.66\n",
            "Training: Iteration: 534000. Loss: 3.207017421722412. Accuracy: 25.632\n",
            "Testing: Iteration: 534000. Loss: 3.207017421722412. Accuracy: 18.62\n",
            "Epoch:  683\n",
            "Training: Iteration: 534500. Loss: 3.2799160480499268. Accuracy: 25.616\n",
            "Testing: Iteration: 534500. Loss: 3.2799160480499268. Accuracy: 18.61\n",
            "Epoch:  684\n",
            "Training: Iteration: 535000. Loss: 3.015446901321411. Accuracy: 25.65\n",
            "Testing: Iteration: 535000. Loss: 3.015446901321411. Accuracy: 18.61\n",
            "Training: Iteration: 535500. Loss: 3.2509512901306152. Accuracy: 25.658\n",
            "Testing: Iteration: 535500. Loss: 3.2509512901306152. Accuracy: 18.66\n",
            "Epoch:  685\n",
            "Training: Iteration: 536000. Loss: 3.0097997188568115. Accuracy: 25.578\n",
            "Testing: Iteration: 536000. Loss: 3.0097997188568115. Accuracy: 18.6\n",
            "Epoch:  686\n",
            "Training: Iteration: 536500. Loss: 3.413613796234131. Accuracy: 25.692\n",
            "Testing: Iteration: 536500. Loss: 3.413613796234131. Accuracy: 18.53\n",
            "Training: Iteration: 537000. Loss: 3.4558892250061035. Accuracy: 25.622\n",
            "Testing: Iteration: 537000. Loss: 3.4558892250061035. Accuracy: 18.55\n",
            "Epoch:  687\n",
            "Training: Iteration: 537500. Loss: 3.435790538787842. Accuracy: 25.688\n",
            "Testing: Iteration: 537500. Loss: 3.435790538787842. Accuracy: 18.55\n",
            "Training: Iteration: 538000. Loss: 3.360100269317627. Accuracy: 25.656\n",
            "Testing: Iteration: 538000. Loss: 3.360100269317627. Accuracy: 18.58\n",
            "Epoch:  688\n",
            "Training: Iteration: 538500. Loss: 3.6292293071746826. Accuracy: 25.622\n",
            "Testing: Iteration: 538500. Loss: 3.6292293071746826. Accuracy: 18.57\n",
            "Epoch:  689\n",
            "Training: Iteration: 539000. Loss: 3.313206195831299. Accuracy: 25.662\n",
            "Testing: Iteration: 539000. Loss: 3.313206195831299. Accuracy: 18.57\n",
            "Training: Iteration: 539500. Loss: 3.289412498474121. Accuracy: 25.65\n",
            "Testing: Iteration: 539500. Loss: 3.289412498474121. Accuracy: 18.62\n",
            "Epoch:  690\n",
            "Training: Iteration: 540000. Loss: 3.051581382751465. Accuracy: 25.67\n",
            "Testing: Iteration: 540000. Loss: 3.051581382751465. Accuracy: 18.62\n",
            "Epoch:  691\n",
            "Training: Iteration: 540500. Loss: 3.1282827854156494. Accuracy: 25.662\n",
            "Testing: Iteration: 540500. Loss: 3.1282827854156494. Accuracy: 18.61\n",
            "Training: Iteration: 541000. Loss: 3.3641858100891113. Accuracy: 25.642\n",
            "Testing: Iteration: 541000. Loss: 3.3641858100891113. Accuracy: 18.62\n",
            "Epoch:  692\n",
            "Training: Iteration: 541500. Loss: 2.766645669937134. Accuracy: 25.632\n",
            "Testing: Iteration: 541500. Loss: 2.766645669937134. Accuracy: 18.53\n",
            "Epoch:  693\n",
            "Training: Iteration: 542000. Loss: 3.3551862239837646. Accuracy: 25.648\n",
            "Testing: Iteration: 542000. Loss: 3.3551862239837646. Accuracy: 18.58\n",
            "Training: Iteration: 542500. Loss: 3.3186566829681396. Accuracy: 25.626\n",
            "Testing: Iteration: 542500. Loss: 3.3186566829681396. Accuracy: 18.52\n",
            "Epoch:  694\n",
            "Training: Iteration: 543000. Loss: 3.158127784729004. Accuracy: 25.656\n",
            "Testing: Iteration: 543000. Loss: 3.158127784729004. Accuracy: 18.58\n",
            "Epoch:  695\n",
            "Training: Iteration: 543500. Loss: 3.0255813598632812. Accuracy: 25.672\n",
            "Testing: Iteration: 543500. Loss: 3.0255813598632812. Accuracy: 18.59\n",
            "Training: Iteration: 544000. Loss: 3.346675157546997. Accuracy: 25.614\n",
            "Testing: Iteration: 544000. Loss: 3.346675157546997. Accuracy: 18.56\n",
            "Epoch:  696\n",
            "Training: Iteration: 544500. Loss: 3.3626976013183594. Accuracy: 25.636\n",
            "Testing: Iteration: 544500. Loss: 3.3626976013183594. Accuracy: 18.54\n",
            "Training: Iteration: 545000. Loss: 3.2390918731689453. Accuracy: 25.66\n",
            "Testing: Iteration: 545000. Loss: 3.2390918731689453. Accuracy: 18.63\n",
            "Epoch:  697\n",
            "Training: Iteration: 545500. Loss: 3.193739652633667. Accuracy: 25.658\n",
            "Testing: Iteration: 545500. Loss: 3.193739652633667. Accuracy: 18.61\n",
            "Epoch:  698\n",
            "Training: Iteration: 546000. Loss: 3.2322652339935303. Accuracy: 25.676\n",
            "Testing: Iteration: 546000. Loss: 3.2322652339935303. Accuracy: 18.62\n",
            "Training: Iteration: 546500. Loss: 3.2765562534332275. Accuracy: 25.602\n",
            "Testing: Iteration: 546500. Loss: 3.2765562534332275. Accuracy: 18.66\n",
            "Epoch:  699\n",
            "Training: Iteration: 547000. Loss: 3.2019381523132324. Accuracy: 25.608\n",
            "Testing: Iteration: 547000. Loss: 3.2019381523132324. Accuracy: 18.59\n",
            "Epoch:  700\n",
            "Training: Iteration: 547500. Loss: 3.4580111503601074. Accuracy: 25.682\n",
            "Testing: Iteration: 547500. Loss: 3.4580111503601074. Accuracy: 18.57\n",
            "Training: Iteration: 548000. Loss: 3.058544635772705. Accuracy: 25.652\n",
            "Testing: Iteration: 548000. Loss: 3.058544635772705. Accuracy: 18.67\n",
            "Epoch:  701\n",
            "Training: Iteration: 548500. Loss: 2.9614055156707764. Accuracy: 25.598\n",
            "Testing: Iteration: 548500. Loss: 2.9614055156707764. Accuracy: 18.48\n",
            "Epoch:  702\n",
            "Training: Iteration: 549000. Loss: 3.409327507019043. Accuracy: 25.68\n",
            "Testing: Iteration: 549000. Loss: 3.409327507019043. Accuracy: 18.48\n",
            "Training: Iteration: 549500. Loss: 3.2827882766723633. Accuracy: 25.622\n",
            "Testing: Iteration: 549500. Loss: 3.2827882766723633. Accuracy: 18.48\n",
            "Epoch:  703\n",
            "Training: Iteration: 550000. Loss: 3.197615623474121. Accuracy: 25.664\n",
            "Testing: Iteration: 550000. Loss: 3.197615623474121. Accuracy: 18.62\n",
            "Training: Iteration: 550500. Loss: 2.8977890014648438. Accuracy: 25.654\n",
            "Testing: Iteration: 550500. Loss: 2.8977890014648438. Accuracy: 18.61\n",
            "Epoch:  704\n",
            "Training: Iteration: 551000. Loss: 3.273996591567993. Accuracy: 25.626\n",
            "Testing: Iteration: 551000. Loss: 3.273996591567993. Accuracy: 18.53\n",
            "Epoch:  705\n",
            "Training: Iteration: 551500. Loss: 3.3164479732513428. Accuracy: 25.698\n",
            "Testing: Iteration: 551500. Loss: 3.3164479732513428. Accuracy: 18.66\n",
            "Training: Iteration: 552000. Loss: 3.6986165046691895. Accuracy: 25.65\n",
            "Testing: Iteration: 552000. Loss: 3.6986165046691895. Accuracy: 18.6\n",
            "Epoch:  706\n",
            "Training: Iteration: 552500. Loss: 3.324079990386963. Accuracy: 25.644\n",
            "Testing: Iteration: 552500. Loss: 3.324079990386963. Accuracy: 18.61\n",
            "Epoch:  707\n",
            "Training: Iteration: 553000. Loss: 3.0619592666625977. Accuracy: 25.658\n",
            "Testing: Iteration: 553000. Loss: 3.0619592666625977. Accuracy: 18.6\n",
            "Training: Iteration: 553500. Loss: 3.3416898250579834. Accuracy: 25.646\n",
            "Testing: Iteration: 553500. Loss: 3.3416898250579834. Accuracy: 18.67\n",
            "Epoch:  708\n",
            "Training: Iteration: 554000. Loss: 3.2744574546813965. Accuracy: 25.614\n",
            "Testing: Iteration: 554000. Loss: 3.2744574546813965. Accuracy: 18.53\n",
            "Epoch:  709\n",
            "Training: Iteration: 554500. Loss: 3.565302848815918. Accuracy: 25.658\n",
            "Testing: Iteration: 554500. Loss: 3.565302848815918. Accuracy: 18.53\n",
            "Training: Iteration: 555000. Loss: 3.221996307373047. Accuracy: 25.68\n",
            "Testing: Iteration: 555000. Loss: 3.221996307373047. Accuracy: 18.56\n",
            "Epoch:  710\n",
            "Training: Iteration: 555500. Loss: 2.9547932147979736. Accuracy: 25.634\n",
            "Testing: Iteration: 555500. Loss: 2.9547932147979736. Accuracy: 18.55\n",
            "Training: Iteration: 556000. Loss: 3.158275604248047. Accuracy: 25.698\n",
            "Testing: Iteration: 556000. Loss: 3.158275604248047. Accuracy: 18.54\n",
            "Epoch:  711\n",
            "Training: Iteration: 556500. Loss: 3.3053126335144043. Accuracy: 25.64\n",
            "Testing: Iteration: 556500. Loss: 3.3053126335144043. Accuracy: 18.57\n",
            "Epoch:  712\n",
            "Training: Iteration: 557000. Loss: 3.2283356189727783. Accuracy: 25.634\n",
            "Testing: Iteration: 557000. Loss: 3.2283356189727783. Accuracy: 18.53\n",
            "Training: Iteration: 557500. Loss: 2.980227470397949. Accuracy: 25.672\n",
            "Testing: Iteration: 557500. Loss: 2.980227470397949. Accuracy: 18.6\n",
            "Epoch:  713\n",
            "Training: Iteration: 558000. Loss: 3.3923697471618652. Accuracy: 25.638\n",
            "Testing: Iteration: 558000. Loss: 3.3923697471618652. Accuracy: 18.61\n",
            "Epoch:  714\n",
            "Training: Iteration: 558500. Loss: 2.943197727203369. Accuracy: 25.694\n",
            "Testing: Iteration: 558500. Loss: 2.943197727203369. Accuracy: 18.57\n",
            "Training: Iteration: 559000. Loss: 3.436640739440918. Accuracy: 25.614\n",
            "Testing: Iteration: 559000. Loss: 3.436640739440918. Accuracy: 18.59\n",
            "Epoch:  715\n",
            "Training: Iteration: 559500. Loss: 3.115593910217285. Accuracy: 25.652\n",
            "Testing: Iteration: 559500. Loss: 3.115593910217285. Accuracy: 18.61\n",
            "Epoch:  716\n",
            "Training: Iteration: 560000. Loss: 3.2065157890319824. Accuracy: 25.666\n",
            "Testing: Iteration: 560000. Loss: 3.2065157890319824. Accuracy: 18.54\n",
            "Training: Iteration: 560500. Loss: 2.963524103164673. Accuracy: 25.692\n",
            "Testing: Iteration: 560500. Loss: 2.963524103164673. Accuracy: 18.61\n",
            "Epoch:  717\n",
            "Training: Iteration: 561000. Loss: 3.418120861053467. Accuracy: 25.682\n",
            "Testing: Iteration: 561000. Loss: 3.418120861053467. Accuracy: 18.54\n",
            "Epoch:  718\n",
            "Training: Iteration: 561500. Loss: 2.9595861434936523. Accuracy: 25.706\n",
            "Testing: Iteration: 561500. Loss: 2.9595861434936523. Accuracy: 18.49\n",
            "Training: Iteration: 562000. Loss: 3.3003170490264893. Accuracy: 25.638\n",
            "Testing: Iteration: 562000. Loss: 3.3003170490264893. Accuracy: 18.59\n",
            "Epoch:  719\n",
            "Training: Iteration: 562500. Loss: 3.0374207496643066. Accuracy: 25.692\n",
            "Testing: Iteration: 562500. Loss: 3.0374207496643066. Accuracy: 18.57\n",
            "Training: Iteration: 563000. Loss: 3.6283185482025146. Accuracy: 25.644\n",
            "Testing: Iteration: 563000. Loss: 3.6283185482025146. Accuracy: 18.53\n",
            "Epoch:  720\n",
            "Training: Iteration: 563500. Loss: 3.3995487689971924. Accuracy: 25.668\n",
            "Testing: Iteration: 563500. Loss: 3.3995487689971924. Accuracy: 18.58\n",
            "Epoch:  721\n",
            "Training: Iteration: 564000. Loss: 3.169745683670044. Accuracy: 25.674\n",
            "Testing: Iteration: 564000. Loss: 3.169745683670044. Accuracy: 18.6\n",
            "Training: Iteration: 564500. Loss: 3.4566872119903564. Accuracy: 25.65\n",
            "Testing: Iteration: 564500. Loss: 3.4566872119903564. Accuracy: 18.55\n",
            "Epoch:  722\n",
            "Training: Iteration: 565000. Loss: 3.3581430912017822. Accuracy: 25.636\n",
            "Testing: Iteration: 565000. Loss: 3.3581430912017822. Accuracy: 18.53\n",
            "Epoch:  723\n",
            "Training: Iteration: 565500. Loss: 3.107332229614258. Accuracy: 25.704\n",
            "Testing: Iteration: 565500. Loss: 3.107332229614258. Accuracy: 18.52\n",
            "Training: Iteration: 566000. Loss: 3.3348655700683594. Accuracy: 25.682\n",
            "Testing: Iteration: 566000. Loss: 3.3348655700683594. Accuracy: 18.5\n",
            "Epoch:  724\n",
            "Training: Iteration: 566500. Loss: 3.187405586242676. Accuracy: 25.648\n",
            "Testing: Iteration: 566500. Loss: 3.187405586242676. Accuracy: 18.48\n",
            "Epoch:  725\n",
            "Training: Iteration: 567000. Loss: 3.117884874343872. Accuracy: 25.722\n",
            "Testing: Iteration: 567000. Loss: 3.117884874343872. Accuracy: 18.49\n",
            "Training: Iteration: 567500. Loss: 3.2971231937408447. Accuracy: 25.642\n",
            "Testing: Iteration: 567500. Loss: 3.2971231937408447. Accuracy: 18.56\n",
            "Epoch:  726\n",
            "Training: Iteration: 568000. Loss: 3.2602059841156006. Accuracy: 25.662\n",
            "Testing: Iteration: 568000. Loss: 3.2602059841156006. Accuracy: 18.53\n",
            "Training: Iteration: 568500. Loss: 3.303368091583252. Accuracy: 25.686\n",
            "Testing: Iteration: 568500. Loss: 3.303368091583252. Accuracy: 18.5\n",
            "Epoch:  727\n",
            "Training: Iteration: 569000. Loss: 3.1768174171447754. Accuracy: 25.682\n",
            "Testing: Iteration: 569000. Loss: 3.1768174171447754. Accuracy: 18.51\n",
            "Epoch:  728\n",
            "Training: Iteration: 569500. Loss: 3.583432912826538. Accuracy: 25.664\n",
            "Testing: Iteration: 569500. Loss: 3.583432912826538. Accuracy: 18.53\n",
            "Training: Iteration: 570000. Loss: 2.8568766117095947. Accuracy: 25.672\n",
            "Testing: Iteration: 570000. Loss: 2.8568766117095947. Accuracy: 18.57\n",
            "Epoch:  729\n",
            "Training: Iteration: 570500. Loss: 3.2691903114318848. Accuracy: 25.678\n",
            "Testing: Iteration: 570500. Loss: 3.2691903114318848. Accuracy: 18.48\n",
            "Epoch:  730\n",
            "Training: Iteration: 571000. Loss: 3.4935600757598877. Accuracy: 25.71\n",
            "Testing: Iteration: 571000. Loss: 3.4935600757598877. Accuracy: 18.59\n",
            "Training: Iteration: 571500. Loss: 3.316568374633789. Accuracy: 25.622\n",
            "Testing: Iteration: 571500. Loss: 3.316568374633789. Accuracy: 18.62\n",
            "Epoch:  731\n",
            "Training: Iteration: 572000. Loss: 3.345376491546631. Accuracy: 25.626\n",
            "Testing: Iteration: 572000. Loss: 3.345376491546631. Accuracy: 18.54\n",
            "Epoch:  732\n",
            "Training: Iteration: 572500. Loss: 3.351513624191284. Accuracy: 25.712\n",
            "Testing: Iteration: 572500. Loss: 3.351513624191284. Accuracy: 18.53\n",
            "Training: Iteration: 573000. Loss: 3.2348906993865967. Accuracy: 25.674\n",
            "Testing: Iteration: 573000. Loss: 3.2348906993865967. Accuracy: 18.5\n",
            "Epoch:  733\n",
            "Training: Iteration: 573500. Loss: 3.4044456481933594. Accuracy: 25.654\n",
            "Testing: Iteration: 573500. Loss: 3.4044456481933594. Accuracy: 18.52\n",
            "Epoch:  734\n",
            "Training: Iteration: 574000. Loss: 3.3292860984802246. Accuracy: 25.732\n",
            "Testing: Iteration: 574000. Loss: 3.3292860984802246. Accuracy: 18.49\n",
            "Training: Iteration: 574500. Loss: 3.6801488399505615. Accuracy: 25.658\n",
            "Testing: Iteration: 574500. Loss: 3.6801488399505615. Accuracy: 18.58\n",
            "Epoch:  735\n",
            "Training: Iteration: 575000. Loss: 3.230386972427368. Accuracy: 25.664\n",
            "Testing: Iteration: 575000. Loss: 3.230386972427368. Accuracy: 18.5\n",
            "Training: Iteration: 575500. Loss: 3.2423062324523926. Accuracy: 25.68\n",
            "Testing: Iteration: 575500. Loss: 3.2423062324523926. Accuracy: 18.52\n",
            "Epoch:  736\n",
            "Training: Iteration: 576000. Loss: 3.331759214401245. Accuracy: 25.666\n",
            "Testing: Iteration: 576000. Loss: 3.331759214401245. Accuracy: 18.54\n",
            "Epoch:  737\n",
            "Training: Iteration: 576500. Loss: 2.921020984649658. Accuracy: 25.682\n",
            "Testing: Iteration: 576500. Loss: 2.921020984649658. Accuracy: 18.56\n",
            "Training: Iteration: 577000. Loss: 3.28342604637146. Accuracy: 25.628\n",
            "Testing: Iteration: 577000. Loss: 3.28342604637146. Accuracy: 18.55\n",
            "Epoch:  738\n",
            "Training: Iteration: 577500. Loss: 3.289802312850952. Accuracy: 25.61\n",
            "Testing: Iteration: 577500. Loss: 3.289802312850952. Accuracy: 18.51\n",
            "Epoch:  739\n",
            "Training: Iteration: 578000. Loss: 3.6639671325683594. Accuracy: 25.688\n",
            "Testing: Iteration: 578000. Loss: 3.6639671325683594. Accuracy: 18.44\n",
            "Training: Iteration: 578500. Loss: 3.3250057697296143. Accuracy: 25.676\n",
            "Testing: Iteration: 578500. Loss: 3.3250057697296143. Accuracy: 18.57\n",
            "Epoch:  740\n",
            "Training: Iteration: 579000. Loss: 3.1717376708984375. Accuracy: 25.598\n",
            "Testing: Iteration: 579000. Loss: 3.1717376708984375. Accuracy: 18.51\n",
            "Epoch:  741\n",
            "Training: Iteration: 579500. Loss: 3.2239885330200195. Accuracy: 25.7\n",
            "Testing: Iteration: 579500. Loss: 3.2239885330200195. Accuracy: 18.42\n",
            "Training: Iteration: 580000. Loss: 3.4337239265441895. Accuracy: 25.63\n",
            "Testing: Iteration: 580000. Loss: 3.4337239265441895. Accuracy: 18.51\n",
            "Epoch:  742\n",
            "Training: Iteration: 580500. Loss: 2.959791660308838. Accuracy: 25.678\n",
            "Testing: Iteration: 580500. Loss: 2.959791660308838. Accuracy: 18.5\n",
            "Training: Iteration: 581000. Loss: 3.312007188796997. Accuracy: 25.726\n",
            "Testing: Iteration: 581000. Loss: 3.312007188796997. Accuracy: 18.49\n",
            "Epoch:  743\n",
            "Training: Iteration: 581500. Loss: 3.216604471206665. Accuracy: 25.686\n",
            "Testing: Iteration: 581500. Loss: 3.216604471206665. Accuracy: 18.51\n",
            "Epoch:  744\n",
            "Training: Iteration: 582000. Loss: 2.7825818061828613. Accuracy: 25.702\n",
            "Testing: Iteration: 582000. Loss: 2.7825818061828613. Accuracy: 18.53\n",
            "Training: Iteration: 582500. Loss: 3.3219804763793945. Accuracy: 25.708\n",
            "Testing: Iteration: 582500. Loss: 3.3219804763793945. Accuracy: 18.52\n",
            "Epoch:  745\n",
            "Training: Iteration: 583000. Loss: 3.3305139541625977. Accuracy: 25.674\n",
            "Testing: Iteration: 583000. Loss: 3.3305139541625977. Accuracy: 18.49\n",
            "Epoch:  746\n",
            "Training: Iteration: 583500. Loss: 3.4743247032165527. Accuracy: 25.682\n",
            "Testing: Iteration: 583500. Loss: 3.4743247032165527. Accuracy: 18.53\n",
            "Training: Iteration: 584000. Loss: 3.616551399230957. Accuracy: 25.666\n",
            "Testing: Iteration: 584000. Loss: 3.616551399230957. Accuracy: 18.59\n",
            "Epoch:  747\n",
            "Training: Iteration: 584500. Loss: 3.123934507369995. Accuracy: 25.616\n",
            "Testing: Iteration: 584500. Loss: 3.123934507369995. Accuracy: 18.53\n",
            "Epoch:  748\n",
            "Training: Iteration: 585000. Loss: 3.0352795124053955. Accuracy: 25.722\n",
            "Testing: Iteration: 585000. Loss: 3.0352795124053955. Accuracy: 18.52\n",
            "Training: Iteration: 585500. Loss: 3.2529594898223877. Accuracy: 25.672\n",
            "Testing: Iteration: 585500. Loss: 3.2529594898223877. Accuracy: 18.48\n",
            "Epoch:  749\n",
            "Training: Iteration: 586000. Loss: 3.4842889308929443. Accuracy: 25.652\n",
            "Testing: Iteration: 586000. Loss: 3.4842889308929443. Accuracy: 18.47\n",
            "Training: Iteration: 586500. Loss: 3.0414743423461914. Accuracy: 25.744\n",
            "Testing: Iteration: 586500. Loss: 3.0414743423461914. Accuracy: 18.47\n",
            "Epoch:  750\n",
            "Training: Iteration: 587000. Loss: 3.203253746032715. Accuracy: 25.708\n",
            "Testing: Iteration: 587000. Loss: 3.203253746032715. Accuracy: 18.5\n",
            "Epoch:  751\n",
            "Training: Iteration: 587500. Loss: 2.939624547958374. Accuracy: 25.622\n",
            "Testing: Iteration: 587500. Loss: 2.939624547958374. Accuracy: 18.44\n",
            "Training: Iteration: 588000. Loss: 2.7738287448883057. Accuracy: 25.676\n",
            "Testing: Iteration: 588000. Loss: 2.7738287448883057. Accuracy: 18.55\n",
            "Epoch:  752\n",
            "Training: Iteration: 588500. Loss: 3.3208260536193848. Accuracy: 25.658\n",
            "Testing: Iteration: 588500. Loss: 3.3208260536193848. Accuracy: 18.54\n",
            "Epoch:  753\n",
            "Training: Iteration: 589000. Loss: 3.427088975906372. Accuracy: 25.724\n",
            "Testing: Iteration: 589000. Loss: 3.427088975906372. Accuracy: 18.5\n",
            "Training: Iteration: 589500. Loss: 3.0647552013397217. Accuracy: 25.64\n",
            "Testing: Iteration: 589500. Loss: 3.0647552013397217. Accuracy: 18.57\n",
            "Epoch:  754\n",
            "Training: Iteration: 590000. Loss: 3.2545793056488037. Accuracy: 25.648\n",
            "Testing: Iteration: 590000. Loss: 3.2545793056488037. Accuracy: 18.53\n",
            "Epoch:  755\n",
            "Training: Iteration: 590500. Loss: 3.1003828048706055. Accuracy: 25.718\n",
            "Testing: Iteration: 590500. Loss: 3.1003828048706055. Accuracy: 18.5\n",
            "Training: Iteration: 591000. Loss: 3.1145691871643066. Accuracy: 25.69\n",
            "Testing: Iteration: 591000. Loss: 3.1145691871643066. Accuracy: 18.51\n",
            "Epoch:  756\n",
            "Training: Iteration: 591500. Loss: 3.537105083465576. Accuracy: 25.656\n",
            "Testing: Iteration: 591500. Loss: 3.537105083465576. Accuracy: 18.48\n",
            "Epoch:  757\n",
            "Training: Iteration: 592000. Loss: 3.317666530609131. Accuracy: 25.742\n",
            "Testing: Iteration: 592000. Loss: 3.317666530609131. Accuracy: 18.44\n",
            "Training: Iteration: 592500. Loss: 3.537402868270874. Accuracy: 25.654\n",
            "Testing: Iteration: 592500. Loss: 3.537402868270874. Accuracy: 18.48\n",
            "Epoch:  758\n",
            "Training: Iteration: 593000. Loss: 3.304487943649292. Accuracy: 25.688\n",
            "Testing: Iteration: 593000. Loss: 3.304487943649292. Accuracy: 18.5\n",
            "Training: Iteration: 593500. Loss: 3.143951892852783. Accuracy: 25.678\n",
            "Testing: Iteration: 593500. Loss: 3.143951892852783. Accuracy: 18.48\n",
            "Epoch:  759\n",
            "Training: Iteration: 594000. Loss: 3.4693989753723145. Accuracy: 25.668\n",
            "Testing: Iteration: 594000. Loss: 3.4693989753723145. Accuracy: 18.46\n",
            "Epoch:  760\n",
            "Training: Iteration: 594500. Loss: 3.1396617889404297. Accuracy: 25.684\n",
            "Testing: Iteration: 594500. Loss: 3.1396617889404297. Accuracy: 18.58\n",
            "Training: Iteration: 595000. Loss: 3.349303960800171. Accuracy: 25.668\n",
            "Testing: Iteration: 595000. Loss: 3.349303960800171. Accuracy: 18.59\n",
            "Epoch:  761\n",
            "Training: Iteration: 595500. Loss: 3.2659645080566406. Accuracy: 25.672\n",
            "Testing: Iteration: 595500. Loss: 3.2659645080566406. Accuracy: 18.49\n",
            "Epoch:  762\n",
            "Training: Iteration: 596000. Loss: 3.329315662384033. Accuracy: 25.73\n",
            "Testing: Iteration: 596000. Loss: 3.329315662384033. Accuracy: 18.45\n",
            "Training: Iteration: 596500. Loss: 3.083664894104004. Accuracy: 25.704\n",
            "Testing: Iteration: 596500. Loss: 3.083664894104004. Accuracy: 18.48\n",
            "Epoch:  763\n",
            "Training: Iteration: 597000. Loss: 2.95957088470459. Accuracy: 25.636\n",
            "Testing: Iteration: 597000. Loss: 2.95957088470459. Accuracy: 18.46\n",
            "Epoch:  764\n",
            "Training: Iteration: 597500. Loss: 2.9599146842956543. Accuracy: 25.754\n",
            "Testing: Iteration: 597500. Loss: 2.9599146842956543. Accuracy: 18.49\n",
            "Training: Iteration: 598000. Loss: 3.1166369915008545. Accuracy: 25.678\n",
            "Testing: Iteration: 598000. Loss: 3.1166369915008545. Accuracy: 18.49\n",
            "Epoch:  765\n",
            "Training: Iteration: 598500. Loss: 3.2848153114318848. Accuracy: 25.68\n",
            "Testing: Iteration: 598500. Loss: 3.2848153114318848. Accuracy: 18.4\n",
            "Training: Iteration: 599000. Loss: 3.3550381660461426. Accuracy: 25.726\n",
            "Testing: Iteration: 599000. Loss: 3.3550381660461426. Accuracy: 18.49\n",
            "Epoch:  766\n",
            "Training: Iteration: 599500. Loss: 3.3286237716674805. Accuracy: 25.7\n",
            "Testing: Iteration: 599500. Loss: 3.3286237716674805. Accuracy: 18.52\n",
            "Epoch:  767\n",
            "Training: Iteration: 600000. Loss: 3.015608310699463. Accuracy: 25.686\n",
            "Testing: Iteration: 600000. Loss: 3.015608310699463. Accuracy: 18.48\n",
            "Training: Iteration: 600500. Loss: 3.4537482261657715. Accuracy: 25.73\n",
            "Testing: Iteration: 600500. Loss: 3.4537482261657715. Accuracy: 18.55\n",
            "Epoch:  768\n",
            "Training: Iteration: 601000. Loss: 3.337263345718384. Accuracy: 25.72\n",
            "Testing: Iteration: 601000. Loss: 3.337263345718384. Accuracy: 18.43\n",
            "Epoch:  769\n",
            "Training: Iteration: 601500. Loss: 3.0640132427215576. Accuracy: 25.702\n",
            "Testing: Iteration: 601500. Loss: 3.0640132427215576. Accuracy: 18.54\n",
            "Training: Iteration: 602000. Loss: 2.959479331970215. Accuracy: 25.66\n",
            "Testing: Iteration: 602000. Loss: 2.959479331970215. Accuracy: 18.58\n",
            "Epoch:  770\n",
            "Training: Iteration: 602500. Loss: 2.822455406188965. Accuracy: 25.626\n",
            "Testing: Iteration: 602500. Loss: 2.822455406188965. Accuracy: 18.51\n",
            "Epoch:  771\n",
            "Training: Iteration: 603000. Loss: 3.0283772945404053. Accuracy: 25.738\n",
            "Testing: Iteration: 603000. Loss: 3.0283772945404053. Accuracy: 18.48\n",
            "Training: Iteration: 603500. Loss: 3.3410983085632324. Accuracy: 25.716\n",
            "Testing: Iteration: 603500. Loss: 3.3410983085632324. Accuracy: 18.54\n",
            "Epoch:  772\n",
            "Training: Iteration: 604000. Loss: 3.169501543045044. Accuracy: 25.686\n",
            "Testing: Iteration: 604000. Loss: 3.169501543045044. Accuracy: 18.45\n",
            "Epoch:  773\n",
            "Training: Iteration: 604500. Loss: 3.1205716133117676. Accuracy: 25.766\n",
            "Testing: Iteration: 604500. Loss: 3.1205716133117676. Accuracy: 18.45\n",
            "Training: Iteration: 605000. Loss: 3.3523216247558594. Accuracy: 25.714\n",
            "Testing: Iteration: 605000. Loss: 3.3523216247558594. Accuracy: 18.49\n",
            "Epoch:  774\n",
            "Training: Iteration: 605500. Loss: 3.09885573387146. Accuracy: 25.692\n",
            "Testing: Iteration: 605500. Loss: 3.09885573387146. Accuracy: 18.43\n",
            "Training: Iteration: 606000. Loss: 3.218825340270996. Accuracy: 25.718\n",
            "Testing: Iteration: 606000. Loss: 3.218825340270996. Accuracy: 18.53\n",
            "Epoch:  775\n",
            "Training: Iteration: 606500. Loss: 2.842937707901001. Accuracy: 25.696\n",
            "Testing: Iteration: 606500. Loss: 2.842937707901001. Accuracy: 18.5\n",
            "Epoch:  776\n",
            "Training: Iteration: 607000. Loss: 3.1573405265808105. Accuracy: 25.71\n",
            "Testing: Iteration: 607000. Loss: 3.1573405265808105. Accuracy: 18.53\n",
            "Training: Iteration: 607500. Loss: 3.532515525817871. Accuracy: 25.678\n",
            "Testing: Iteration: 607500. Loss: 3.532515525817871. Accuracy: 18.53\n",
            "Epoch:  777\n",
            "Training: Iteration: 608000. Loss: 2.9431827068328857. Accuracy: 25.66\n",
            "Testing: Iteration: 608000. Loss: 2.9431827068328857. Accuracy: 18.48\n",
            "Epoch:  778\n",
            "Training: Iteration: 608500. Loss: 3.362563133239746. Accuracy: 25.72\n",
            "Testing: Iteration: 608500. Loss: 3.362563133239746. Accuracy: 18.42\n",
            "Training: Iteration: 609000. Loss: 3.311483860015869. Accuracy: 25.708\n",
            "Testing: Iteration: 609000. Loss: 3.311483860015869. Accuracy: 18.52\n",
            "Epoch:  779\n",
            "Training: Iteration: 609500. Loss: 3.2744529247283936. Accuracy: 25.626\n",
            "Testing: Iteration: 609500. Loss: 3.2744529247283936. Accuracy: 18.47\n",
            "Epoch:  780\n",
            "Training: Iteration: 610000. Loss: 3.0353550910949707. Accuracy: 25.734\n",
            "Testing: Iteration: 610000. Loss: 3.0353550910949707. Accuracy: 18.33\n",
            "Training: Iteration: 610500. Loss: 3.389699935913086. Accuracy: 25.682\n",
            "Testing: Iteration: 610500. Loss: 3.389699935913086. Accuracy: 18.37\n",
            "Epoch:  781\n",
            "Training: Iteration: 611000. Loss: 3.070279121398926. Accuracy: 25.682\n",
            "Testing: Iteration: 611000. Loss: 3.070279121398926. Accuracy: 18.47\n",
            "Training: Iteration: 611500. Loss: 3.6984493732452393. Accuracy: 25.732\n",
            "Testing: Iteration: 611500. Loss: 3.6984493732452393. Accuracy: 18.48\n",
            "Epoch:  782\n",
            "Training: Iteration: 612000. Loss: 3.6279802322387695. Accuracy: 25.742\n",
            "Testing: Iteration: 612000. Loss: 3.6279802322387695. Accuracy: 18.44\n",
            "Epoch:  783\n",
            "Training: Iteration: 612500. Loss: 3.0782370567321777. Accuracy: 25.708\n",
            "Testing: Iteration: 612500. Loss: 3.0782370567321777. Accuracy: 18.54\n",
            "Training: Iteration: 613000. Loss: 3.50544810295105. Accuracy: 25.752\n",
            "Testing: Iteration: 613000. Loss: 3.50544810295105. Accuracy: 18.47\n",
            "Epoch:  784\n",
            "Training: Iteration: 613500. Loss: 3.2823612689971924. Accuracy: 25.706\n",
            "Testing: Iteration: 613500. Loss: 3.2823612689971924. Accuracy: 18.5\n",
            "Epoch:  785\n",
            "Training: Iteration: 614000. Loss: 3.2389986515045166. Accuracy: 25.716\n",
            "Testing: Iteration: 614000. Loss: 3.2389986515045166. Accuracy: 18.52\n",
            "Training: Iteration: 614500. Loss: 3.306600570678711. Accuracy: 25.686\n",
            "Testing: Iteration: 614500. Loss: 3.306600570678711. Accuracy: 18.47\n",
            "Epoch:  786\n",
            "Training: Iteration: 615000. Loss: 3.437838315963745. Accuracy: 25.668\n",
            "Testing: Iteration: 615000. Loss: 3.437838315963745. Accuracy: 18.49\n",
            "Epoch:  787\n",
            "Training: Iteration: 615500. Loss: 3.1067028045654297. Accuracy: 25.746\n",
            "Testing: Iteration: 615500. Loss: 3.1067028045654297. Accuracy: 18.46\n",
            "Training: Iteration: 616000. Loss: 3.0172553062438965. Accuracy: 25.714\n",
            "Testing: Iteration: 616000. Loss: 3.0172553062438965. Accuracy: 18.5\n",
            "Epoch:  788\n",
            "Training: Iteration: 616500. Loss: 3.310622453689575. Accuracy: 25.672\n",
            "Testing: Iteration: 616500. Loss: 3.310622453689575. Accuracy: 18.41\n",
            "Epoch:  789\n",
            "Training: Iteration: 617000. Loss: 3.2153666019439697. Accuracy: 25.774\n",
            "Testing: Iteration: 617000. Loss: 3.2153666019439697. Accuracy: 18.48\n",
            "Training: Iteration: 617500. Loss: 3.1631603240966797. Accuracy: 25.746\n",
            "Testing: Iteration: 617500. Loss: 3.1631603240966797. Accuracy: 18.48\n",
            "Epoch:  790\n",
            "Training: Iteration: 618000. Loss: 3.578902006149292. Accuracy: 25.64\n",
            "Testing: Iteration: 618000. Loss: 3.578902006149292. Accuracy: 18.48\n",
            "Training: Iteration: 618500. Loss: 3.190258264541626. Accuracy: 25.738\n",
            "Testing: Iteration: 618500. Loss: 3.190258264541626. Accuracy: 18.47\n",
            "Epoch:  791\n",
            "Training: Iteration: 619000. Loss: 3.104572296142578. Accuracy: 25.706\n",
            "Testing: Iteration: 619000. Loss: 3.104572296142578. Accuracy: 18.51\n",
            "Epoch:  792\n",
            "Training: Iteration: 619500. Loss: 3.4995338916778564. Accuracy: 25.728\n",
            "Testing: Iteration: 619500. Loss: 3.4995338916778564. Accuracy: 18.51\n",
            "Training: Iteration: 620000. Loss: 3.1734273433685303. Accuracy: 25.684\n",
            "Testing: Iteration: 620000. Loss: 3.1734273433685303. Accuracy: 18.49\n",
            "Epoch:  793\n",
            "Training: Iteration: 620500. Loss: 3.155052661895752. Accuracy: 25.686\n",
            "Testing: Iteration: 620500. Loss: 3.155052661895752. Accuracy: 18.47\n",
            "Epoch:  794\n",
            "Training: Iteration: 621000. Loss: 3.5532755851745605. Accuracy: 25.726\n",
            "Testing: Iteration: 621000. Loss: 3.5532755851745605. Accuracy: 18.4\n",
            "Training: Iteration: 621500. Loss: 3.6175854206085205. Accuracy: 25.712\n",
            "Testing: Iteration: 621500. Loss: 3.6175854206085205. Accuracy: 18.47\n",
            "Epoch:  795\n",
            "Training: Iteration: 622000. Loss: 3.2965352535247803. Accuracy: 25.656\n",
            "Testing: Iteration: 622000. Loss: 3.2965352535247803. Accuracy: 18.41\n",
            "Epoch:  796\n",
            "Training: Iteration: 622500. Loss: 3.3716342449188232. Accuracy: 25.746\n",
            "Testing: Iteration: 622500. Loss: 3.3716342449188232. Accuracy: 18.4\n",
            "Training: Iteration: 623000. Loss: 3.5405948162078857. Accuracy: 25.674\n",
            "Testing: Iteration: 623000. Loss: 3.5405948162078857. Accuracy: 18.41\n",
            "Epoch:  797\n",
            "Training: Iteration: 623500. Loss: 2.794599771499634. Accuracy: 25.712\n",
            "Testing: Iteration: 623500. Loss: 2.794599771499634. Accuracy: 18.49\n",
            "Training: Iteration: 624000. Loss: 3.15390682220459. Accuracy: 25.692\n",
            "Testing: Iteration: 624000. Loss: 3.15390682220459. Accuracy: 18.45\n",
            "Epoch:  798\n",
            "Training: Iteration: 624500. Loss: 3.026926040649414. Accuracy: 25.746\n",
            "Testing: Iteration: 624500. Loss: 3.026926040649414. Accuracy: 18.43\n",
            "Epoch:  799\n",
            "Training: Iteration: 625000. Loss: 3.410309314727783. Accuracy: 25.698\n",
            "Testing: Iteration: 625000. Loss: 3.410309314727783. Accuracy: 18.52\n",
            "Training: Iteration: 625500. Loss: 2.7365522384643555. Accuracy: 25.706\n",
            "Testing: Iteration: 625500. Loss: 2.7365522384643555. Accuracy: 18.52\n",
            "Epoch:  800\n",
            "Training: Iteration: 626000. Loss: 3.7573418617248535. Accuracy: 25.684\n",
            "Testing: Iteration: 626000. Loss: 3.7573418617248535. Accuracy: 18.43\n",
            "Epoch:  801\n",
            "Training: Iteration: 626500. Loss: 2.654447078704834. Accuracy: 25.742\n",
            "Testing: Iteration: 626500. Loss: 2.654447078704834. Accuracy: 18.46\n",
            "Training: Iteration: 627000. Loss: 3.5187320709228516. Accuracy: 25.712\n",
            "Testing: Iteration: 627000. Loss: 3.5187320709228516. Accuracy: 18.43\n",
            "Epoch:  802\n",
            "Training: Iteration: 627500. Loss: 3.379164934158325. Accuracy: 25.648\n",
            "Testing: Iteration: 627500. Loss: 3.379164934158325. Accuracy: 18.42\n",
            "Epoch:  803\n",
            "Training: Iteration: 628000. Loss: 2.9358091354370117. Accuracy: 25.744\n",
            "Testing: Iteration: 628000. Loss: 2.9358091354370117. Accuracy: 18.39\n",
            "Training: Iteration: 628500. Loss: 3.173322916030884. Accuracy: 25.702\n",
            "Testing: Iteration: 628500. Loss: 3.173322916030884. Accuracy: 18.43\n",
            "Epoch:  804\n",
            "Training: Iteration: 629000. Loss: 3.138653039932251. Accuracy: 25.704\n",
            "Testing: Iteration: 629000. Loss: 3.138653039932251. Accuracy: 18.37\n",
            "Training: Iteration: 629500. Loss: 3.6016407012939453. Accuracy: 25.786\n",
            "Testing: Iteration: 629500. Loss: 3.6016407012939453. Accuracy: 18.41\n",
            "Epoch:  805\n",
            "Training: Iteration: 630000. Loss: 3.173384189605713. Accuracy: 25.71\n",
            "Testing: Iteration: 630000. Loss: 3.173384189605713. Accuracy: 18.46\n",
            "Epoch:  806\n",
            "Training: Iteration: 630500. Loss: 3.306623697280884. Accuracy: 25.672\n",
            "Testing: Iteration: 630500. Loss: 3.306623697280884. Accuracy: 18.42\n",
            "Training: Iteration: 631000. Loss: 3.1223645210266113. Accuracy: 25.734\n",
            "Testing: Iteration: 631000. Loss: 3.1223645210266113. Accuracy: 18.5\n",
            "Epoch:  807\n",
            "Training: Iteration: 631500. Loss: 3.1416854858398438. Accuracy: 25.722\n",
            "Testing: Iteration: 631500. Loss: 3.1416854858398438. Accuracy: 18.37\n",
            "Epoch:  808\n",
            "Training: Iteration: 632000. Loss: 3.0996642112731934. Accuracy: 25.702\n",
            "Testing: Iteration: 632000. Loss: 3.0996642112731934. Accuracy: 18.54\n",
            "Training: Iteration: 632500. Loss: 3.439051389694214. Accuracy: 25.716\n",
            "Testing: Iteration: 632500. Loss: 3.439051389694214. Accuracy: 18.54\n",
            "Epoch:  809\n",
            "Training: Iteration: 633000. Loss: 3.377452850341797. Accuracy: 25.64\n",
            "Testing: Iteration: 633000. Loss: 3.377452850341797. Accuracy: 18.46\n",
            "Epoch:  810\n",
            "Training: Iteration: 633500. Loss: 3.1895694732666016. Accuracy: 25.756\n",
            "Testing: Iteration: 633500. Loss: 3.1895694732666016. Accuracy: 18.42\n",
            "Training: Iteration: 634000. Loss: 3.145118236541748. Accuracy: 25.712\n",
            "Testing: Iteration: 634000. Loss: 3.145118236541748. Accuracy: 18.47\n",
            "Epoch:  811\n",
            "Training: Iteration: 634500. Loss: 2.705061435699463. Accuracy: 25.682\n",
            "Testing: Iteration: 634500. Loss: 2.705061435699463. Accuracy: 18.44\n",
            "Epoch:  812\n",
            "Training: Iteration: 635000. Loss: 3.0930869579315186. Accuracy: 25.772\n",
            "Testing: Iteration: 635000. Loss: 3.0930869579315186. Accuracy: 18.39\n",
            "Training: Iteration: 635500. Loss: 3.3462321758270264. Accuracy: 25.734\n",
            "Testing: Iteration: 635500. Loss: 3.3462321758270264. Accuracy: 18.46\n",
            "Epoch:  813\n",
            "Training: Iteration: 636000. Loss: 3.405407667160034. Accuracy: 25.708\n",
            "Testing: Iteration: 636000. Loss: 3.405407667160034. Accuracy: 18.38\n",
            "Training: Iteration: 636500. Loss: 3.4285151958465576. Accuracy: 25.72\n",
            "Testing: Iteration: 636500. Loss: 3.4285151958465576. Accuracy: 18.48\n",
            "Epoch:  814\n",
            "Training: Iteration: 637000. Loss: 3.4153831005096436. Accuracy: 25.752\n",
            "Testing: Iteration: 637000. Loss: 3.4153831005096436. Accuracy: 18.44\n",
            "Epoch:  815\n",
            "Training: Iteration: 637500. Loss: 3.250185251235962. Accuracy: 25.706\n",
            "Testing: Iteration: 637500. Loss: 3.250185251235962. Accuracy: 18.52\n",
            "Training: Iteration: 638000. Loss: 3.124523639678955. Accuracy: 25.72\n",
            "Testing: Iteration: 638000. Loss: 3.124523639678955. Accuracy: 18.52\n",
            "Epoch:  816\n",
            "Training: Iteration: 638500. Loss: 3.546757698059082. Accuracy: 25.702\n",
            "Testing: Iteration: 638500. Loss: 3.546757698059082. Accuracy: 18.45\n",
            "Epoch:  817\n",
            "Training: Iteration: 639000. Loss: 3.1101505756378174. Accuracy: 25.758\n",
            "Testing: Iteration: 639000. Loss: 3.1101505756378174. Accuracy: 18.41\n",
            "Training: Iteration: 639500. Loss: 3.589052438735962. Accuracy: 25.738\n",
            "Testing: Iteration: 639500. Loss: 3.589052438735962. Accuracy: 18.48\n",
            "Epoch:  818\n",
            "Training: Iteration: 640000. Loss: 3.37397837638855. Accuracy: 25.632\n",
            "Testing: Iteration: 640000. Loss: 3.37397837638855. Accuracy: 18.44\n",
            "Epoch:  819\n",
            "Training: Iteration: 640500. Loss: 3.3585431575775146. Accuracy: 25.734\n",
            "Testing: Iteration: 640500. Loss: 3.3585431575775146. Accuracy: 18.29\n",
            "Training: Iteration: 641000. Loss: 3.305309295654297. Accuracy: 25.696\n",
            "Testing: Iteration: 641000. Loss: 3.305309295654297. Accuracy: 18.36\n",
            "Epoch:  820\n",
            "Training: Iteration: 641500. Loss: 3.097318410873413. Accuracy: 25.718\n",
            "Testing: Iteration: 641500. Loss: 3.097318410873413. Accuracy: 18.39\n",
            "Training: Iteration: 642000. Loss: 2.93249249458313. Accuracy: 25.746\n",
            "Testing: Iteration: 642000. Loss: 2.93249249458313. Accuracy: 18.42\n",
            "Epoch:  821\n",
            "Training: Iteration: 642500. Loss: 2.882328987121582. Accuracy: 25.768\n",
            "Testing: Iteration: 642500. Loss: 2.882328987121582. Accuracy: 18.36\n",
            "Epoch:  822\n",
            "Training: Iteration: 643000. Loss: 3.02418851852417. Accuracy: 25.698\n",
            "Testing: Iteration: 643000. Loss: 3.02418851852417. Accuracy: 18.5\n",
            "Training: Iteration: 643500. Loss: 3.53802752494812. Accuracy: 25.74\n",
            "Testing: Iteration: 643500. Loss: 3.53802752494812. Accuracy: 18.46\n",
            "Epoch:  823\n",
            "Training: Iteration: 644000. Loss: 3.1682043075561523. Accuracy: 25.71\n",
            "Testing: Iteration: 644000. Loss: 3.1682043075561523. Accuracy: 18.45\n",
            "Epoch:  824\n",
            "Training: Iteration: 644500. Loss: 3.240478992462158. Accuracy: 25.736\n",
            "Testing: Iteration: 644500. Loss: 3.240478992462158. Accuracy: 18.5\n",
            "Training: Iteration: 645000. Loss: 3.4597725868225098. Accuracy: 25.724\n",
            "Testing: Iteration: 645000. Loss: 3.4597725868225098. Accuracy: 18.48\n",
            "Epoch:  825\n",
            "Training: Iteration: 645500. Loss: 3.5043094158172607. Accuracy: 25.68\n",
            "Testing: Iteration: 645500. Loss: 3.5043094158172607. Accuracy: 18.44\n",
            "Epoch:  826\n",
            "Training: Iteration: 646000. Loss: 3.2850756645202637. Accuracy: 25.788\n",
            "Testing: Iteration: 646000. Loss: 3.2850756645202637. Accuracy: 18.43\n",
            "Training: Iteration: 646500. Loss: 2.8720953464508057. Accuracy: 25.728\n",
            "Testing: Iteration: 646500. Loss: 2.8720953464508057. Accuracy: 18.46\n",
            "Epoch:  827\n",
            "Training: Iteration: 647000. Loss: 3.078200101852417. Accuracy: 25.668\n",
            "Testing: Iteration: 647000. Loss: 3.078200101852417. Accuracy: 18.38\n",
            "Epoch:  828\n",
            "Training: Iteration: 647500. Loss: 3.1371588706970215. Accuracy: 25.806\n",
            "Testing: Iteration: 647500. Loss: 3.1371588706970215. Accuracy: 18.43\n",
            "Training: Iteration: 648000. Loss: 3.636542558670044. Accuracy: 25.742\n",
            "Testing: Iteration: 648000. Loss: 3.636542558670044. Accuracy: 18.44\n",
            "Epoch:  829\n",
            "Training: Iteration: 648500. Loss: 3.0866870880126953. Accuracy: 25.696\n",
            "Testing: Iteration: 648500. Loss: 3.0866870880126953. Accuracy: 18.43\n",
            "Training: Iteration: 649000. Loss: 2.9644646644592285. Accuracy: 25.764\n",
            "Testing: Iteration: 649000. Loss: 2.9644646644592285. Accuracy: 18.48\n",
            "Epoch:  830\n",
            "Training: Iteration: 649500. Loss: 3.5190656185150146. Accuracy: 25.724\n",
            "Testing: Iteration: 649500. Loss: 3.5190656185150146. Accuracy: 18.49\n",
            "Epoch:  831\n",
            "Training: Iteration: 650000. Loss: 3.2118942737579346. Accuracy: 25.742\n",
            "Testing: Iteration: 650000. Loss: 3.2118942737579346. Accuracy: 18.46\n",
            "Training: Iteration: 650500. Loss: 3.1571292877197266. Accuracy: 25.688\n",
            "Testing: Iteration: 650500. Loss: 3.1571292877197266. Accuracy: 18.51\n",
            "Epoch:  832\n",
            "Training: Iteration: 651000. Loss: 3.1001267433166504. Accuracy: 25.696\n",
            "Testing: Iteration: 651000. Loss: 3.1001267433166504. Accuracy: 18.44\n",
            "Epoch:  833\n",
            "Training: Iteration: 651500. Loss: 3.4117631912231445. Accuracy: 25.75\n",
            "Testing: Iteration: 651500. Loss: 3.4117631912231445. Accuracy: 18.38\n",
            "Training: Iteration: 652000. Loss: 3.179927110671997. Accuracy: 25.726\n",
            "Testing: Iteration: 652000. Loss: 3.179927110671997. Accuracy: 18.4\n",
            "Epoch:  834\n",
            "Training: Iteration: 652500. Loss: 3.3817288875579834. Accuracy: 25.694\n",
            "Testing: Iteration: 652500. Loss: 3.3817288875579834. Accuracy: 18.43\n",
            "Epoch:  835\n",
            "Training: Iteration: 653000. Loss: 3.4373955726623535. Accuracy: 25.768\n",
            "Testing: Iteration: 653000. Loss: 3.4373955726623535. Accuracy: 18.38\n",
            "Training: Iteration: 653500. Loss: 3.3234915733337402. Accuracy: 25.716\n",
            "Testing: Iteration: 653500. Loss: 3.3234915733337402. Accuracy: 18.4\n",
            "Epoch:  836\n",
            "Training: Iteration: 654000. Loss: 3.2376227378845215. Accuracy: 25.75\n",
            "Testing: Iteration: 654000. Loss: 3.2376227378845215. Accuracy: 18.43\n",
            "Training: Iteration: 654500. Loss: 3.538701295852661. Accuracy: 25.734\n",
            "Testing: Iteration: 654500. Loss: 3.538701295852661. Accuracy: 18.43\n",
            "Epoch:  837\n",
            "Training: Iteration: 655000. Loss: 3.123898506164551. Accuracy: 25.792\n",
            "Testing: Iteration: 655000. Loss: 3.123898506164551. Accuracy: 18.38\n",
            "Epoch:  838\n",
            "Training: Iteration: 655500. Loss: 3.1690101623535156. Accuracy: 25.768\n",
            "Testing: Iteration: 655500. Loss: 3.1690101623535156. Accuracy: 18.49\n",
            "Training: Iteration: 656000. Loss: 3.418087959289551. Accuracy: 25.74\n",
            "Testing: Iteration: 656000. Loss: 3.418087959289551. Accuracy: 18.51\n",
            "Epoch:  839\n",
            "Training: Iteration: 656500. Loss: 3.247771978378296. Accuracy: 25.662\n",
            "Testing: Iteration: 656500. Loss: 3.247771978378296. Accuracy: 18.43\n",
            "Epoch:  840\n",
            "Training: Iteration: 657000. Loss: 2.924184560775757. Accuracy: 25.75\n",
            "Testing: Iteration: 657000. Loss: 2.924184560775757. Accuracy: 18.43\n",
            "Training: Iteration: 657500. Loss: 3.1659836769104004. Accuracy: 25.73\n",
            "Testing: Iteration: 657500. Loss: 3.1659836769104004. Accuracy: 18.46\n",
            "Epoch:  841\n",
            "Training: Iteration: 658000. Loss: 3.4321935176849365. Accuracy: 25.642\n",
            "Testing: Iteration: 658000. Loss: 3.4321935176849365. Accuracy: 18.38\n",
            "Epoch:  842\n",
            "Training: Iteration: 658500. Loss: 3.346668243408203. Accuracy: 25.802\n",
            "Testing: Iteration: 658500. Loss: 3.346668243408203. Accuracy: 18.38\n",
            "Training: Iteration: 659000. Loss: 3.376110792160034. Accuracy: 25.74\n",
            "Testing: Iteration: 659000. Loss: 3.376110792160034. Accuracy: 18.43\n",
            "Epoch:  843\n",
            "Training: Iteration: 659500. Loss: 3.397592544555664. Accuracy: 25.712\n",
            "Testing: Iteration: 659500. Loss: 3.397592544555664. Accuracy: 18.34\n",
            "Training: Iteration: 660000. Loss: 3.2309458255767822. Accuracy: 25.78\n",
            "Testing: Iteration: 660000. Loss: 3.2309458255767822. Accuracy: 18.41\n",
            "Epoch:  844\n",
            "Training: Iteration: 660500. Loss: 3.029539108276367. Accuracy: 25.746\n",
            "Testing: Iteration: 660500. Loss: 3.029539108276367. Accuracy: 18.37\n",
            "Epoch:  845\n",
            "Training: Iteration: 661000. Loss: 2.7486302852630615. Accuracy: 25.672\n",
            "Testing: Iteration: 661000. Loss: 2.7486302852630615. Accuracy: 18.4\n",
            "Training: Iteration: 661500. Loss: 3.274719715118408. Accuracy: 25.716\n",
            "Testing: Iteration: 661500. Loss: 3.274719715118408. Accuracy: 18.51\n",
            "Epoch:  846\n",
            "Training: Iteration: 662000. Loss: 3.278031349182129. Accuracy: 25.724\n",
            "Testing: Iteration: 662000. Loss: 3.278031349182129. Accuracy: 18.35\n",
            "Epoch:  847\n",
            "Training: Iteration: 662500. Loss: 3.4662325382232666. Accuracy: 25.754\n",
            "Testing: Iteration: 662500. Loss: 3.4662325382232666. Accuracy: 18.5\n",
            "Training: Iteration: 663000. Loss: 3.186983108520508. Accuracy: 25.716\n",
            "Testing: Iteration: 663000. Loss: 3.186983108520508. Accuracy: 18.55\n",
            "Epoch:  848\n",
            "Training: Iteration: 663500. Loss: 3.359313726425171. Accuracy: 25.698\n",
            "Testing: Iteration: 663500. Loss: 3.359313726425171. Accuracy: 18.39\n",
            "Epoch:  849\n",
            "Training: Iteration: 664000. Loss: 3.3222150802612305. Accuracy: 25.78\n",
            "Testing: Iteration: 664000. Loss: 3.3222150802612305. Accuracy: 18.4\n",
            "Training: Iteration: 664500. Loss: 2.9395360946655273. Accuracy: 25.736\n",
            "Testing: Iteration: 664500. Loss: 2.9395360946655273. Accuracy: 18.45\n",
            "Epoch:  850\n",
            "Training: Iteration: 665000. Loss: 3.4059245586395264. Accuracy: 25.708\n",
            "Testing: Iteration: 665000. Loss: 3.4059245586395264. Accuracy: 18.4\n",
            "Epoch:  851\n",
            "Training: Iteration: 665500. Loss: 3.0238003730773926. Accuracy: 25.788\n",
            "Testing: Iteration: 665500. Loss: 3.0238003730773926. Accuracy: 18.34\n",
            "Training: Iteration: 666000. Loss: 2.86364483833313. Accuracy: 25.714\n",
            "Testing: Iteration: 666000. Loss: 2.86364483833313. Accuracy: 18.4\n",
            "Epoch:  852\n",
            "Training: Iteration: 666500. Loss: 3.175241231918335. Accuracy: 25.75\n",
            "Testing: Iteration: 666500. Loss: 3.175241231918335. Accuracy: 18.39\n",
            "Training: Iteration: 667000. Loss: 2.9546308517456055. Accuracy: 25.758\n",
            "Testing: Iteration: 667000. Loss: 2.9546308517456055. Accuracy: 18.46\n",
            "Epoch:  853\n",
            "Training: Iteration: 667500. Loss: 3.275801181793213. Accuracy: 25.732\n",
            "Testing: Iteration: 667500. Loss: 3.275801181793213. Accuracy: 18.44\n",
            "Epoch:  854\n",
            "Training: Iteration: 668000. Loss: 2.8591296672821045. Accuracy: 25.724\n",
            "Testing: Iteration: 668000. Loss: 2.8591296672821045. Accuracy: 18.47\n",
            "Training: Iteration: 668500. Loss: 3.33925199508667. Accuracy: 25.708\n",
            "Testing: Iteration: 668500. Loss: 3.33925199508667. Accuracy: 18.49\n",
            "Epoch:  855\n",
            "Training: Iteration: 669000. Loss: 3.2252559661865234. Accuracy: 25.706\n",
            "Testing: Iteration: 669000. Loss: 3.2252559661865234. Accuracy: 18.39\n",
            "Epoch:  856\n",
            "Training: Iteration: 669500. Loss: 3.103865623474121. Accuracy: 25.754\n",
            "Testing: Iteration: 669500. Loss: 3.103865623474121. Accuracy: 18.42\n",
            "Training: Iteration: 670000. Loss: 3.3499670028686523. Accuracy: 25.716\n",
            "Testing: Iteration: 670000. Loss: 3.3499670028686523. Accuracy: 18.49\n",
            "Epoch:  857\n",
            "Training: Iteration: 670500. Loss: 2.8773558139801025. Accuracy: 25.646\n",
            "Testing: Iteration: 670500. Loss: 2.8773558139801025. Accuracy: 18.43\n",
            "Epoch:  858\n",
            "Training: Iteration: 671000. Loss: 3.0074515342712402. Accuracy: 25.746\n",
            "Testing: Iteration: 671000. Loss: 3.0074515342712402. Accuracy: 18.27\n",
            "Training: Iteration: 671500. Loss: 3.1259918212890625. Accuracy: 25.71\n",
            "Testing: Iteration: 671500. Loss: 3.1259918212890625. Accuracy: 18.36\n",
            "Epoch:  859\n",
            "Training: Iteration: 672000. Loss: 3.0734753608703613. Accuracy: 25.74\n",
            "Testing: Iteration: 672000. Loss: 3.0734753608703613. Accuracy: 18.34\n",
            "Training: Iteration: 672500. Loss: 2.9356374740600586. Accuracy: 25.752\n",
            "Testing: Iteration: 672500. Loss: 2.9356374740600586. Accuracy: 18.44\n",
            "Epoch:  860\n",
            "Training: Iteration: 673000. Loss: 3.2328081130981445. Accuracy: 25.782\n",
            "Testing: Iteration: 673000. Loss: 3.2328081130981445. Accuracy: 18.41\n",
            "Epoch:  861\n",
            "Training: Iteration: 673500. Loss: 3.3648667335510254. Accuracy: 25.724\n",
            "Testing: Iteration: 673500. Loss: 3.3648667335510254. Accuracy: 18.49\n",
            "Training: Iteration: 674000. Loss: 3.2434017658233643. Accuracy: 25.744\n",
            "Testing: Iteration: 674000. Loss: 3.2434017658233643. Accuracy: 18.46\n",
            "Epoch:  862\n",
            "Training: Iteration: 674500. Loss: 3.089498519897461. Accuracy: 25.728\n",
            "Testing: Iteration: 674500. Loss: 3.089498519897461. Accuracy: 18.38\n",
            "Epoch:  863\n",
            "Training: Iteration: 675000. Loss: 3.322415828704834. Accuracy: 25.756\n",
            "Testing: Iteration: 675000. Loss: 3.322415828704834. Accuracy: 18.42\n",
            "Training: Iteration: 675500. Loss: 3.0490832328796387. Accuracy: 25.726\n",
            "Testing: Iteration: 675500. Loss: 3.0490832328796387. Accuracy: 18.43\n",
            "Epoch:  864\n",
            "Training: Iteration: 676000. Loss: 3.1156227588653564. Accuracy: 25.694\n",
            "Testing: Iteration: 676000. Loss: 3.1156227588653564. Accuracy: 18.36\n",
            "Epoch:  865\n",
            "Training: Iteration: 676500. Loss: 3.648158550262451. Accuracy: 25.802\n",
            "Testing: Iteration: 676500. Loss: 3.648158550262451. Accuracy: 18.36\n",
            "Training: Iteration: 677000. Loss: 3.7472329139709473. Accuracy: 25.73\n",
            "Testing: Iteration: 677000. Loss: 3.7472329139709473. Accuracy: 18.43\n",
            "Epoch:  866\n",
            "Training: Iteration: 677500. Loss: 3.099945545196533. Accuracy: 25.692\n",
            "Testing: Iteration: 677500. Loss: 3.099945545196533. Accuracy: 18.35\n",
            "Epoch:  867\n",
            "Training: Iteration: 678000. Loss: 3.0637624263763428. Accuracy: 25.812\n",
            "Testing: Iteration: 678000. Loss: 3.0637624263763428. Accuracy: 18.39\n",
            "Training: Iteration: 678500. Loss: 2.954038619995117. Accuracy: 25.738\n",
            "Testing: Iteration: 678500. Loss: 2.954038619995117. Accuracy: 18.42\n",
            "Epoch:  868\n",
            "Training: Iteration: 679000. Loss: 3.3487088680267334. Accuracy: 25.724\n",
            "Testing: Iteration: 679000. Loss: 3.3487088680267334. Accuracy: 18.42\n",
            "Training: Iteration: 679500. Loss: 3.1669204235076904. Accuracy: 25.756\n",
            "Testing: Iteration: 679500. Loss: 3.1669204235076904. Accuracy: 18.51\n",
            "Epoch:  869\n",
            "Training: Iteration: 680000. Loss: 3.300037145614624. Accuracy: 25.734\n",
            "Testing: Iteration: 680000. Loss: 3.300037145614624. Accuracy: 18.37\n",
            "Epoch:  870\n",
            "Training: Iteration: 680500. Loss: 3.3959949016571045. Accuracy: 25.772\n",
            "Testing: Iteration: 680500. Loss: 3.3959949016571045. Accuracy: 18.4\n",
            "Training: Iteration: 681000. Loss: 3.0151450634002686. Accuracy: 25.728\n",
            "Testing: Iteration: 681000. Loss: 3.0151450634002686. Accuracy: 18.45\n",
            "Epoch:  871\n",
            "Training: Iteration: 681500. Loss: 3.6134417057037354. Accuracy: 25.73\n",
            "Testing: Iteration: 681500. Loss: 3.6134417057037354. Accuracy: 18.34\n",
            "Epoch:  872\n",
            "Training: Iteration: 682000. Loss: 3.380734920501709. Accuracy: 25.774\n",
            "Testing: Iteration: 682000. Loss: 3.380734920501709. Accuracy: 18.39\n",
            "Training: Iteration: 682500. Loss: 3.425853967666626. Accuracy: 25.74\n",
            "Testing: Iteration: 682500. Loss: 3.425853967666626. Accuracy: 18.4\n",
            "Epoch:  873\n",
            "Training: Iteration: 683000. Loss: 3.2758948802948. Accuracy: 25.738\n",
            "Testing: Iteration: 683000. Loss: 3.2758948802948. Accuracy: 18.39\n",
            "Epoch:  874\n",
            "Training: Iteration: 683500. Loss: 3.2313051223754883. Accuracy: 25.788\n",
            "Testing: Iteration: 683500. Loss: 3.2313051223754883. Accuracy: 18.31\n",
            "Training: Iteration: 684000. Loss: 3.135772705078125. Accuracy: 25.712\n",
            "Testing: Iteration: 684000. Loss: 3.135772705078125. Accuracy: 18.38\n",
            "Epoch:  875\n",
            "Training: Iteration: 684500. Loss: 3.042860746383667. Accuracy: 25.764\n",
            "Testing: Iteration: 684500. Loss: 3.042860746383667. Accuracy: 18.39\n",
            "Training: Iteration: 685000. Loss: 2.8543946743011475. Accuracy: 25.738\n",
            "Testing: Iteration: 685000. Loss: 2.8543946743011475. Accuracy: 18.44\n",
            "Epoch:  876\n",
            "Training: Iteration: 685500. Loss: 3.3549418449401855. Accuracy: 25.796\n",
            "Testing: Iteration: 685500. Loss: 3.3549418449401855. Accuracy: 18.4\n",
            "Epoch:  877\n",
            "Training: Iteration: 686000. Loss: 3.059600830078125. Accuracy: 25.782\n",
            "Testing: Iteration: 686000. Loss: 3.059600830078125. Accuracy: 18.47\n",
            "Training: Iteration: 686500. Loss: 3.518613576889038. Accuracy: 25.768\n",
            "Testing: Iteration: 686500. Loss: 3.518613576889038. Accuracy: 18.46\n",
            "Epoch:  878\n",
            "Training: Iteration: 687000. Loss: 3.1466658115386963. Accuracy: 25.748\n",
            "Testing: Iteration: 687000. Loss: 3.1466658115386963. Accuracy: 18.35\n",
            "Epoch:  879\n",
            "Training: Iteration: 687500. Loss: 3.2168221473693848. Accuracy: 25.754\n",
            "Testing: Iteration: 687500. Loss: 3.2168221473693848. Accuracy: 18.43\n",
            "Training: Iteration: 688000. Loss: 3.237287759780884. Accuracy: 25.76\n",
            "Testing: Iteration: 688000. Loss: 3.237287759780884. Accuracy: 18.38\n",
            "Epoch:  880\n",
            "Training: Iteration: 688500. Loss: 3.3025999069213867. Accuracy: 25.676\n",
            "Testing: Iteration: 688500. Loss: 3.3025999069213867. Accuracy: 18.32\n",
            "Epoch:  881\n",
            "Training: Iteration: 689000. Loss: 3.4604947566986084. Accuracy: 25.834\n",
            "Testing: Iteration: 689000. Loss: 3.4604947566986084. Accuracy: 18.35\n",
            "Training: Iteration: 689500. Loss: 3.013596534729004. Accuracy: 25.75\n",
            "Testing: Iteration: 689500. Loss: 3.013596534729004. Accuracy: 18.38\n",
            "Epoch:  882\n",
            "Training: Iteration: 690000. Loss: 3.116616725921631. Accuracy: 25.752\n",
            "Testing: Iteration: 690000. Loss: 3.116616725921631. Accuracy: 18.36\n",
            "Training: Iteration: 690500. Loss: 3.691720724105835. Accuracy: 25.782\n",
            "Testing: Iteration: 690500. Loss: 3.691720724105835. Accuracy: 18.47\n",
            "Epoch:  883\n",
            "Training: Iteration: 691000. Loss: 3.3275604248046875. Accuracy: 25.732\n",
            "Testing: Iteration: 691000. Loss: 3.3275604248046875. Accuracy: 18.39\n",
            "Epoch:  884\n",
            "Training: Iteration: 691500. Loss: 3.200261116027832. Accuracy: 25.724\n",
            "Testing: Iteration: 691500. Loss: 3.200261116027832. Accuracy: 18.41\n",
            "Training: Iteration: 692000. Loss: 3.146591901779175. Accuracy: 25.74\n",
            "Testing: Iteration: 692000. Loss: 3.146591901779175. Accuracy: 18.48\n",
            "Epoch:  885\n",
            "Training: Iteration: 692500. Loss: 3.197033166885376. Accuracy: 25.762\n",
            "Testing: Iteration: 692500. Loss: 3.197033166885376. Accuracy: 18.33\n",
            "Epoch:  886\n",
            "Training: Iteration: 693000. Loss: 3.2115540504455566. Accuracy: 25.788\n",
            "Testing: Iteration: 693000. Loss: 3.2115540504455566. Accuracy: 18.41\n",
            "Training: Iteration: 693500. Loss: 3.092784881591797. Accuracy: 25.746\n",
            "Testing: Iteration: 693500. Loss: 3.092784881591797. Accuracy: 18.49\n",
            "Epoch:  887\n",
            "Training: Iteration: 694000. Loss: 3.277453660964966. Accuracy: 25.736\n",
            "Testing: Iteration: 694000. Loss: 3.277453660964966. Accuracy: 18.33\n",
            "Epoch:  888\n",
            "Training: Iteration: 694500. Loss: 3.2168407440185547. Accuracy: 25.81\n",
            "Testing: Iteration: 694500. Loss: 3.2168407440185547. Accuracy: 18.37\n",
            "Training: Iteration: 695000. Loss: 3.3327674865722656. Accuracy: 25.758\n",
            "Testing: Iteration: 695000. Loss: 3.3327674865722656. Accuracy: 18.42\n",
            "Epoch:  889\n",
            "Training: Iteration: 695500. Loss: 2.9207921028137207. Accuracy: 25.732\n",
            "Testing: Iteration: 695500. Loss: 2.9207921028137207. Accuracy: 18.34\n",
            "Epoch:  890\n",
            "Training: Iteration: 696000. Loss: 3.176767349243164. Accuracy: 25.814\n",
            "Testing: Iteration: 696000. Loss: 3.176767349243164. Accuracy: 18.32\n",
            "Training: Iteration: 696500. Loss: 3.1755213737487793. Accuracy: 25.72\n",
            "Testing: Iteration: 696500. Loss: 3.1755213737487793. Accuracy: 18.34\n",
            "Epoch:  891\n",
            "Training: Iteration: 697000. Loss: 3.117478847503662. Accuracy: 25.832\n",
            "Testing: Iteration: 697000. Loss: 3.117478847503662. Accuracy: 18.39\n",
            "Training: Iteration: 697500. Loss: 3.806652069091797. Accuracy: 25.762\n",
            "Testing: Iteration: 697500. Loss: 3.806652069091797. Accuracy: 18.4\n",
            "Epoch:  892\n",
            "Training: Iteration: 698000. Loss: 3.0165905952453613. Accuracy: 25.766\n",
            "Testing: Iteration: 698000. Loss: 3.0165905952453613. Accuracy: 18.4\n",
            "Epoch:  893\n",
            "Training: Iteration: 698500. Loss: 2.9049181938171387. Accuracy: 25.768\n",
            "Testing: Iteration: 698500. Loss: 2.9049181938171387. Accuracy: 18.43\n",
            "Training: Iteration: 699000. Loss: 3.17960786819458. Accuracy: 25.722\n",
            "Testing: Iteration: 699000. Loss: 3.17960786819458. Accuracy: 18.46\n",
            "Epoch:  894\n",
            "Training: Iteration: 699500. Loss: 3.5013792514801025. Accuracy: 25.734\n",
            "Testing: Iteration: 699500. Loss: 3.5013792514801025. Accuracy: 18.34\n",
            "Epoch:  895\n",
            "Training: Iteration: 700000. Loss: 3.0759353637695312. Accuracy: 25.794\n",
            "Testing: Iteration: 700000. Loss: 3.0759353637695312. Accuracy: 18.37\n",
            "Training: Iteration: 700500. Loss: 3.1189067363739014. Accuracy: 25.772\n",
            "Testing: Iteration: 700500. Loss: 3.1189067363739014. Accuracy: 18.39\n",
            "Epoch:  896\n",
            "Training: Iteration: 701000. Loss: 2.8730010986328125. Accuracy: 25.714\n",
            "Testing: Iteration: 701000. Loss: 2.8730010986328125. Accuracy: 18.34\n",
            "Epoch:  897\n",
            "Training: Iteration: 701500. Loss: 3.392573118209839. Accuracy: 25.792\n",
            "Testing: Iteration: 701500. Loss: 3.392573118209839. Accuracy: 18.31\n",
            "Training: Iteration: 702000. Loss: 3.5057427883148193. Accuracy: 25.752\n",
            "Testing: Iteration: 702000. Loss: 3.5057427883148193. Accuracy: 18.39\n",
            "Epoch:  898\n",
            "Training: Iteration: 702500. Loss: 2.9832708835601807. Accuracy: 25.778\n",
            "Testing: Iteration: 702500. Loss: 2.9832708835601807. Accuracy: 18.32\n",
            "Training: Iteration: 703000. Loss: 3.2900803089141846. Accuracy: 25.8\n",
            "Testing: Iteration: 703000. Loss: 3.2900803089141846. Accuracy: 18.4\n",
            "Epoch:  899\n",
            "Training: Iteration: 703500. Loss: 2.9088351726531982. Accuracy: 25.792\n",
            "Testing: Iteration: 703500. Loss: 2.9088351726531982. Accuracy: 18.41\n",
            "Epoch:  900\n",
            "Training: Iteration: 704000. Loss: 3.3402326107025146. Accuracy: 25.772\n",
            "Testing: Iteration: 704000. Loss: 3.3402326107025146. Accuracy: 18.43\n",
            "Training: Iteration: 704500. Loss: 3.51159930229187. Accuracy: 25.752\n",
            "Testing: Iteration: 704500. Loss: 3.51159930229187. Accuracy: 18.43\n",
            "Epoch:  901\n",
            "Training: Iteration: 705000. Loss: 3.415959119796753. Accuracy: 25.762\n",
            "Testing: Iteration: 705000. Loss: 3.415959119796753. Accuracy: 18.31\n",
            "Epoch:  902\n",
            "Training: Iteration: 705500. Loss: 3.288938045501709. Accuracy: 25.766\n",
            "Testing: Iteration: 705500. Loss: 3.288938045501709. Accuracy: 18.43\n",
            "Training: Iteration: 706000. Loss: 2.864442825317383. Accuracy: 25.762\n",
            "Testing: Iteration: 706000. Loss: 2.864442825317383. Accuracy: 18.42\n",
            "Epoch:  903\n",
            "Training: Iteration: 706500. Loss: 3.2656288146972656. Accuracy: 25.714\n",
            "Testing: Iteration: 706500. Loss: 3.2656288146972656. Accuracy: 18.3\n",
            "Epoch:  904\n",
            "Training: Iteration: 707000. Loss: 3.160576343536377. Accuracy: 25.812\n",
            "Testing: Iteration: 707000. Loss: 3.160576343536377. Accuracy: 18.34\n",
            "Training: Iteration: 707500. Loss: 3.2501611709594727. Accuracy: 25.728\n",
            "Testing: Iteration: 707500. Loss: 3.2501611709594727. Accuracy: 18.37\n",
            "Epoch:  905\n",
            "Training: Iteration: 708000. Loss: 3.4265894889831543. Accuracy: 25.712\n",
            "Testing: Iteration: 708000. Loss: 3.4265894889831543. Accuracy: 18.32\n",
            "Epoch:  906\n",
            "Training: Iteration: 708500. Loss: 3.009577512741089. Accuracy: 25.836\n",
            "Testing: Iteration: 708500. Loss: 3.009577512741089. Accuracy: 18.33\n",
            "Training: Iteration: 709000. Loss: 3.362454891204834. Accuracy: 25.75\n",
            "Testing: Iteration: 709000. Loss: 3.362454891204834. Accuracy: 18.38\n",
            "Epoch:  907\n",
            "Training: Iteration: 709500. Loss: 3.3745787143707275. Accuracy: 25.774\n",
            "Testing: Iteration: 709500. Loss: 3.3745787143707275. Accuracy: 18.37\n",
            "Training: Iteration: 710000. Loss: 3.2111284732818604. Accuracy: 25.788\n",
            "Testing: Iteration: 710000. Loss: 3.2111284732818604. Accuracy: 18.41\n",
            "Epoch:  908\n",
            "Training: Iteration: 710500. Loss: 3.3414487838745117. Accuracy: 25.784\n",
            "Testing: Iteration: 710500. Loss: 3.3414487838745117. Accuracy: 18.38\n",
            "Epoch:  909\n",
            "Training: Iteration: 711000. Loss: 2.969675064086914. Accuracy: 25.78\n",
            "Testing: Iteration: 711000. Loss: 2.969675064086914. Accuracy: 18.39\n",
            "Training: Iteration: 711500. Loss: 3.2557504177093506. Accuracy: 25.756\n",
            "Testing: Iteration: 711500. Loss: 3.2557504177093506. Accuracy: 18.44\n",
            "Epoch:  910\n",
            "Training: Iteration: 712000. Loss: 3.1520230770111084. Accuracy: 25.712\n",
            "Testing: Iteration: 712000. Loss: 3.1520230770111084. Accuracy: 18.3\n",
            "Epoch:  911\n",
            "Training: Iteration: 712500. Loss: 3.5322699546813965. Accuracy: 25.8\n",
            "Testing: Iteration: 712500. Loss: 3.5322699546813965. Accuracy: 18.38\n",
            "Training: Iteration: 713000. Loss: 3.030339479446411. Accuracy: 25.788\n",
            "Testing: Iteration: 713000. Loss: 3.030339479446411. Accuracy: 18.36\n",
            "Epoch:  912\n",
            "Training: Iteration: 713500. Loss: 3.7224435806274414. Accuracy: 25.76\n",
            "Testing: Iteration: 713500. Loss: 3.7224435806274414. Accuracy: 18.3\n",
            "Epoch:  913\n",
            "Training: Iteration: 714000. Loss: 3.0812528133392334. Accuracy: 25.804\n",
            "Testing: Iteration: 714000. Loss: 3.0812528133392334. Accuracy: 18.27\n",
            "Training: Iteration: 714500. Loss: 3.01934552192688. Accuracy: 25.734\n",
            "Testing: Iteration: 714500. Loss: 3.01934552192688. Accuracy: 18.38\n",
            "Epoch:  914\n",
            "Training: Iteration: 715000. Loss: 3.644383668899536. Accuracy: 25.79\n",
            "Testing: Iteration: 715000. Loss: 3.644383668899536. Accuracy: 18.38\n",
            "Training: Iteration: 715500. Loss: 3.507581949234009. Accuracy: 25.79\n",
            "Testing: Iteration: 715500. Loss: 3.507581949234009. Accuracy: 18.45\n",
            "Epoch:  915\n",
            "Training: Iteration: 716000. Loss: 3.1627557277679443. Accuracy: 25.786\n",
            "Testing: Iteration: 716000. Loss: 3.1627557277679443. Accuracy: 18.4\n",
            "Epoch:  916\n",
            "Training: Iteration: 716500. Loss: 3.520733118057251. Accuracy: 25.79\n",
            "Testing: Iteration: 716500. Loss: 3.520733118057251. Accuracy: 18.5\n",
            "Training: Iteration: 717000. Loss: 3.003419876098633. Accuracy: 25.794\n",
            "Testing: Iteration: 717000. Loss: 3.003419876098633. Accuracy: 18.44\n",
            "Epoch:  917\n",
            "Training: Iteration: 717500. Loss: 3.826836585998535. Accuracy: 25.774\n",
            "Testing: Iteration: 717500. Loss: 3.826836585998535. Accuracy: 18.31\n",
            "Epoch:  918\n",
            "Training: Iteration: 718000. Loss: 3.189396858215332. Accuracy: 25.81\n",
            "Testing: Iteration: 718000. Loss: 3.189396858215332. Accuracy: 18.4\n",
            "Training: Iteration: 718500. Loss: 2.964447259902954. Accuracy: 25.768\n",
            "Testing: Iteration: 718500. Loss: 2.964447259902954. Accuracy: 18.42\n",
            "Epoch:  919\n",
            "Training: Iteration: 719000. Loss: 3.5072309970855713. Accuracy: 25.706\n",
            "Testing: Iteration: 719000. Loss: 3.5072309970855713. Accuracy: 18.3\n",
            "Epoch:  920\n",
            "Training: Iteration: 719500. Loss: 3.019442319869995. Accuracy: 25.852\n",
            "Testing: Iteration: 719500. Loss: 3.019442319869995. Accuracy: 18.33\n",
            "Training: Iteration: 720000. Loss: 3.2315211296081543. Accuracy: 25.784\n",
            "Testing: Iteration: 720000. Loss: 3.2315211296081543. Accuracy: 18.36\n",
            "Epoch:  921\n",
            "Training: Iteration: 720500. Loss: 3.3977692127227783. Accuracy: 25.734\n",
            "Testing: Iteration: 720500. Loss: 3.3977692127227783. Accuracy: 18.3\n",
            "Training: Iteration: 721000. Loss: 3.2829649448394775. Accuracy: 25.816\n",
            "Testing: Iteration: 721000. Loss: 3.2829649448394775. Accuracy: 18.45\n",
            "Epoch:  922\n",
            "Training: Iteration: 721500. Loss: 3.4102694988250732. Accuracy: 25.758\n",
            "Testing: Iteration: 721500. Loss: 3.4102694988250732. Accuracy: 18.39\n",
            "Epoch:  923\n",
            "Training: Iteration: 722000. Loss: 3.507751941680908. Accuracy: 25.76\n",
            "Testing: Iteration: 722000. Loss: 3.507751941680908. Accuracy: 18.38\n",
            "Training: Iteration: 722500. Loss: 3.274203062057495. Accuracy: 25.774\n",
            "Testing: Iteration: 722500. Loss: 3.274203062057495. Accuracy: 18.48\n",
            "Epoch:  924\n",
            "Training: Iteration: 723000. Loss: 3.6967577934265137. Accuracy: 25.782\n",
            "Testing: Iteration: 723000. Loss: 3.6967577934265137. Accuracy: 18.31\n",
            "Epoch:  925\n",
            "Training: Iteration: 723500. Loss: 3.3884458541870117. Accuracy: 25.798\n",
            "Testing: Iteration: 723500. Loss: 3.3884458541870117. Accuracy: 18.39\n",
            "Training: Iteration: 724000. Loss: 3.2552876472473145. Accuracy: 25.766\n",
            "Testing: Iteration: 724000. Loss: 3.2552876472473145. Accuracy: 18.49\n",
            "Epoch:  926\n",
            "Training: Iteration: 724500. Loss: 3.2538418769836426. Accuracy: 25.722\n",
            "Testing: Iteration: 724500. Loss: 3.2538418769836426. Accuracy: 18.28\n",
            "Epoch:  927\n",
            "Training: Iteration: 725000. Loss: 3.343289613723755. Accuracy: 25.828\n",
            "Testing: Iteration: 725000. Loss: 3.343289613723755. Accuracy: 18.39\n",
            "Training: Iteration: 725500. Loss: 3.1251320838928223. Accuracy: 25.774\n",
            "Testing: Iteration: 725500. Loss: 3.1251320838928223. Accuracy: 18.44\n",
            "Epoch:  928\n",
            "Training: Iteration: 726000. Loss: 3.586805582046509. Accuracy: 25.764\n",
            "Testing: Iteration: 726000. Loss: 3.586805582046509. Accuracy: 18.31\n",
            "Epoch:  929\n",
            "Training: Iteration: 726500. Loss: 3.4608821868896484. Accuracy: 25.84\n",
            "Testing: Iteration: 726500. Loss: 3.4608821868896484. Accuracy: 18.36\n",
            "Training: Iteration: 727000. Loss: 3.029855966567993. Accuracy: 25.726\n",
            "Testing: Iteration: 727000. Loss: 3.029855966567993. Accuracy: 18.33\n",
            "Epoch:  930\n",
            "Training: Iteration: 727500. Loss: 3.140698194503784. Accuracy: 25.832\n",
            "Testing: Iteration: 727500. Loss: 3.140698194503784. Accuracy: 18.34\n",
            "Training: Iteration: 728000. Loss: 3.2197368144989014. Accuracy: 25.79\n",
            "Testing: Iteration: 728000. Loss: 3.2197368144989014. Accuracy: 18.39\n",
            "Epoch:  931\n",
            "Training: Iteration: 728500. Loss: 3.066303253173828. Accuracy: 25.764\n",
            "Testing: Iteration: 728500. Loss: 3.066303253173828. Accuracy: 18.38\n",
            "Epoch:  932\n",
            "Training: Iteration: 729000. Loss: 3.2048068046569824. Accuracy: 25.798\n",
            "Testing: Iteration: 729000. Loss: 3.2048068046569824. Accuracy: 18.43\n",
            "Training: Iteration: 729500. Loss: 3.1972105503082275. Accuracy: 25.76\n",
            "Testing: Iteration: 729500. Loss: 3.1972105503082275. Accuracy: 18.45\n",
            "Epoch:  933\n",
            "Training: Iteration: 730000. Loss: 3.26332950592041. Accuracy: 25.742\n",
            "Testing: Iteration: 730000. Loss: 3.26332950592041. Accuracy: 18.31\n",
            "Epoch:  934\n",
            "Training: Iteration: 730500. Loss: 2.9876108169555664. Accuracy: 25.828\n",
            "Testing: Iteration: 730500. Loss: 2.9876108169555664. Accuracy: 18.4\n",
            "Training: Iteration: 731000. Loss: 3.2344112396240234. Accuracy: 25.804\n",
            "Testing: Iteration: 731000. Loss: 3.2344112396240234. Accuracy: 18.46\n",
            "Epoch:  935\n",
            "Training: Iteration: 731500. Loss: 2.984549045562744. Accuracy: 25.75\n",
            "Testing: Iteration: 731500. Loss: 2.984549045562744. Accuracy: 18.28\n",
            "Epoch:  936\n",
            "Training: Iteration: 732000. Loss: 3.404707908630371. Accuracy: 25.806\n",
            "Testing: Iteration: 732000. Loss: 3.404707908630371. Accuracy: 18.31\n",
            "Training: Iteration: 732500. Loss: 3.447037935256958. Accuracy: 25.75\n",
            "Testing: Iteration: 732500. Loss: 3.447037935256958. Accuracy: 18.36\n",
            "Epoch:  937\n",
            "Training: Iteration: 733000. Loss: 3.431569814682007. Accuracy: 25.794\n",
            "Testing: Iteration: 733000. Loss: 3.431569814682007. Accuracy: 18.34\n",
            "Training: Iteration: 733500. Loss: 3.3508849143981934. Accuracy: 25.828\n",
            "Testing: Iteration: 733500. Loss: 3.3508849143981934. Accuracy: 18.37\n",
            "Epoch:  938\n",
            "Training: Iteration: 734000. Loss: 3.615119457244873. Accuracy: 25.786\n",
            "Testing: Iteration: 734000. Loss: 3.615119457244873. Accuracy: 18.34\n",
            "Epoch:  939\n",
            "Training: Iteration: 734500. Loss: 3.3125882148742676. Accuracy: 25.784\n",
            "Testing: Iteration: 734500. Loss: 3.3125882148742676. Accuracy: 18.4\n",
            "Training: Iteration: 735000. Loss: 3.2673110961914062. Accuracy: 25.772\n",
            "Testing: Iteration: 735000. Loss: 3.2673110961914062. Accuracy: 18.42\n",
            "Epoch:  940\n",
            "Training: Iteration: 735500. Loss: 3.033154010772705. Accuracy: 25.786\n",
            "Testing: Iteration: 735500. Loss: 3.033154010772705. Accuracy: 18.31\n",
            "Epoch:  941\n",
            "Training: Iteration: 736000. Loss: 3.1145663261413574. Accuracy: 25.782\n",
            "Testing: Iteration: 736000. Loss: 3.1145663261413574. Accuracy: 18.4\n",
            "Training: Iteration: 736500. Loss: 3.3450164794921875. Accuracy: 25.768\n",
            "Testing: Iteration: 736500. Loss: 3.3450164794921875. Accuracy: 18.41\n",
            "Epoch:  942\n",
            "Training: Iteration: 737000. Loss: 2.7442288398742676. Accuracy: 25.752\n",
            "Testing: Iteration: 737000. Loss: 2.7442288398742676. Accuracy: 18.33\n",
            "Epoch:  943\n",
            "Training: Iteration: 737500. Loss: 3.3417766094207764. Accuracy: 25.846\n",
            "Testing: Iteration: 737500. Loss: 3.3417766094207764. Accuracy: 18.37\n",
            "Training: Iteration: 738000. Loss: 3.304753303527832. Accuracy: 25.778\n",
            "Testing: Iteration: 738000. Loss: 3.304753303527832. Accuracy: 18.42\n",
            "Epoch:  944\n",
            "Training: Iteration: 738500. Loss: 3.1553328037261963. Accuracy: 25.748\n",
            "Testing: Iteration: 738500. Loss: 3.1553328037261963. Accuracy: 18.31\n",
            "Epoch:  945\n",
            "Training: Iteration: 739000. Loss: 3.027151346206665. Accuracy: 25.846\n",
            "Testing: Iteration: 739000. Loss: 3.027151346206665. Accuracy: 18.37\n",
            "Training: Iteration: 739500. Loss: 3.3360533714294434. Accuracy: 25.726\n",
            "Testing: Iteration: 739500. Loss: 3.3360533714294434. Accuracy: 18.38\n",
            "Epoch:  946\n",
            "Training: Iteration: 740000. Loss: 3.356045722961426. Accuracy: 25.798\n",
            "Testing: Iteration: 740000. Loss: 3.356045722961426. Accuracy: 18.38\n",
            "Training: Iteration: 740500. Loss: 3.2176625728607178. Accuracy: 25.812\n",
            "Testing: Iteration: 740500. Loss: 3.2176625728607178. Accuracy: 18.45\n",
            "Epoch:  947\n",
            "Training: Iteration: 741000. Loss: 3.176133155822754. Accuracy: 25.794\n",
            "Testing: Iteration: 741000. Loss: 3.176133155822754. Accuracy: 18.45\n",
            "Epoch:  948\n",
            "Training: Iteration: 741500. Loss: 3.2237937450408936. Accuracy: 25.778\n",
            "Testing: Iteration: 741500. Loss: 3.2237937450408936. Accuracy: 18.37\n",
            "Training: Iteration: 742000. Loss: 3.2602381706237793. Accuracy: 25.766\n",
            "Testing: Iteration: 742000. Loss: 3.2602381706237793. Accuracy: 18.45\n",
            "Epoch:  949\n",
            "Training: Iteration: 742500. Loss: 3.194333553314209. Accuracy: 25.738\n",
            "Testing: Iteration: 742500. Loss: 3.194333553314209. Accuracy: 18.33\n",
            "Epoch:  950\n",
            "Training: Iteration: 743000. Loss: 3.463561534881592. Accuracy: 25.836\n",
            "Testing: Iteration: 743000. Loss: 3.463561534881592. Accuracy: 18.42\n",
            "Training: Iteration: 743500. Loss: 3.052891492843628. Accuracy: 25.788\n",
            "Testing: Iteration: 743500. Loss: 3.052891492843628. Accuracy: 18.39\n",
            "Epoch:  951\n",
            "Training: Iteration: 744000. Loss: 2.9431498050689697. Accuracy: 25.746\n",
            "Testing: Iteration: 744000. Loss: 2.9431498050689697. Accuracy: 18.26\n",
            "Epoch:  952\n",
            "Training: Iteration: 744500. Loss: 3.4058637619018555. Accuracy: 25.79\n",
            "Testing: Iteration: 744500. Loss: 3.4058637619018555. Accuracy: 18.31\n",
            "Training: Iteration: 745000. Loss: 3.2642502784729004. Accuracy: 25.732\n",
            "Testing: Iteration: 745000. Loss: 3.2642502784729004. Accuracy: 18.37\n",
            "Epoch:  953\n",
            "Training: Iteration: 745500. Loss: 3.200778007507324. Accuracy: 25.786\n",
            "Testing: Iteration: 745500. Loss: 3.200778007507324. Accuracy: 18.35\n",
            "Training: Iteration: 746000. Loss: 2.8781275749206543. Accuracy: 25.816\n",
            "Testing: Iteration: 746000. Loss: 2.8781275749206543. Accuracy: 18.43\n",
            "Epoch:  954\n",
            "Training: Iteration: 746500. Loss: 3.2485625743865967. Accuracy: 25.794\n",
            "Testing: Iteration: 746500. Loss: 3.2485625743865967. Accuracy: 18.36\n",
            "Epoch:  955\n",
            "Training: Iteration: 747000. Loss: 3.297694683074951. Accuracy: 25.788\n",
            "Testing: Iteration: 747000. Loss: 3.297694683074951. Accuracy: 18.43\n",
            "Training: Iteration: 747500. Loss: 3.6882574558258057. Accuracy: 25.784\n",
            "Testing: Iteration: 747500. Loss: 3.6882574558258057. Accuracy: 18.44\n",
            "Epoch:  956\n",
            "Training: Iteration: 748000. Loss: 3.3003623485565186. Accuracy: 25.798\n",
            "Testing: Iteration: 748000. Loss: 3.3003623485565186. Accuracy: 18.34\n",
            "Epoch:  957\n",
            "Training: Iteration: 748500. Loss: 3.048128128051758. Accuracy: 25.836\n",
            "Testing: Iteration: 748500. Loss: 3.048128128051758. Accuracy: 18.35\n",
            "Training: Iteration: 749000. Loss: 3.327129602432251. Accuracy: 25.786\n",
            "Testing: Iteration: 749000. Loss: 3.327129602432251. Accuracy: 18.39\n",
            "Epoch:  958\n",
            "Training: Iteration: 749500. Loss: 3.266695976257324. Accuracy: 25.734\n",
            "Testing: Iteration: 749500. Loss: 3.266695976257324. Accuracy: 18.31\n",
            "Epoch:  959\n",
            "Training: Iteration: 750000. Loss: 3.5550057888031006. Accuracy: 25.856\n",
            "Testing: Iteration: 750000. Loss: 3.5550057888031006. Accuracy: 18.36\n",
            "Training: Iteration: 750500. Loss: 3.2108402252197266. Accuracy: 25.802\n",
            "Testing: Iteration: 750500. Loss: 3.2108402252197266. Accuracy: 18.35\n",
            "Epoch:  960\n",
            "Training: Iteration: 751000. Loss: 2.9303154945373535. Accuracy: 25.752\n",
            "Testing: Iteration: 751000. Loss: 2.9303154945373535. Accuracy: 18.31\n",
            "Training: Iteration: 751500. Loss: 3.1423418521881104. Accuracy: 25.852\n",
            "Testing: Iteration: 751500. Loss: 3.1423418521881104. Accuracy: 18.43\n",
            "Epoch:  961\n",
            "Training: Iteration: 752000. Loss: 3.2768056392669678. Accuracy: 25.774\n",
            "Testing: Iteration: 752000. Loss: 3.2768056392669678. Accuracy: 18.33\n",
            "Epoch:  962\n",
            "Training: Iteration: 752500. Loss: 3.206697702407837. Accuracy: 25.772\n",
            "Testing: Iteration: 752500. Loss: 3.206697702407837. Accuracy: 18.38\n",
            "Training: Iteration: 753000. Loss: 2.983583927154541. Accuracy: 25.812\n",
            "Testing: Iteration: 753000. Loss: 2.983583927154541. Accuracy: 18.45\n",
            "Epoch:  963\n",
            "Training: Iteration: 753500. Loss: 3.3780760765075684. Accuracy: 25.798\n",
            "Testing: Iteration: 753500. Loss: 3.3780760765075684. Accuracy: 18.34\n",
            "Epoch:  964\n",
            "Training: Iteration: 754000. Loss: 2.9301371574401855. Accuracy: 25.806\n",
            "Testing: Iteration: 754000. Loss: 2.9301371574401855. Accuracy: 18.37\n",
            "Training: Iteration: 754500. Loss: 3.4234814643859863. Accuracy: 25.782\n",
            "Testing: Iteration: 754500. Loss: 3.4234814643859863. Accuracy: 18.49\n",
            "Epoch:  965\n",
            "Training: Iteration: 755000. Loss: 3.1017885208129883. Accuracy: 25.748\n",
            "Testing: Iteration: 755000. Loss: 3.1017885208129883. Accuracy: 18.35\n",
            "Epoch:  966\n",
            "Training: Iteration: 755500. Loss: 3.2123923301696777. Accuracy: 25.824\n",
            "Testing: Iteration: 755500. Loss: 3.2123923301696777. Accuracy: 18.39\n",
            "Training: Iteration: 756000. Loss: 2.9419028759002686. Accuracy: 25.796\n",
            "Testing: Iteration: 756000. Loss: 2.9419028759002686. Accuracy: 18.41\n",
            "Epoch:  967\n",
            "Training: Iteration: 756500. Loss: 3.3949761390686035. Accuracy: 25.792\n",
            "Testing: Iteration: 756500. Loss: 3.3949761390686035. Accuracy: 18.26\n",
            "Epoch:  968\n",
            "Training: Iteration: 757000. Loss: 2.944666624069214. Accuracy: 25.86\n",
            "Testing: Iteration: 757000. Loss: 2.944666624069214. Accuracy: 18.41\n",
            "Training: Iteration: 757500. Loss: 3.279291868209839. Accuracy: 25.75\n",
            "Testing: Iteration: 757500. Loss: 3.279291868209839. Accuracy: 18.37\n",
            "Epoch:  969\n",
            "Training: Iteration: 758000. Loss: 3.026641607284546. Accuracy: 25.814\n",
            "Testing: Iteration: 758000. Loss: 3.026641607284546. Accuracy: 18.3\n",
            "Training: Iteration: 758500. Loss: 3.6071693897247314. Accuracy: 25.832\n",
            "Testing: Iteration: 758500. Loss: 3.6071693897247314. Accuracy: 18.4\n",
            "Epoch:  970\n",
            "Training: Iteration: 759000. Loss: 3.3968393802642822. Accuracy: 25.784\n",
            "Testing: Iteration: 759000. Loss: 3.3968393802642822. Accuracy: 18.41\n",
            "Epoch:  971\n",
            "Training: Iteration: 759500. Loss: 3.1614131927490234. Accuracy: 25.802\n",
            "Testing: Iteration: 759500. Loss: 3.1614131927490234. Accuracy: 18.36\n",
            "Training: Iteration: 760000. Loss: 3.4437146186828613. Accuracy: 25.816\n",
            "Testing: Iteration: 760000. Loss: 3.4437146186828613. Accuracy: 18.44\n",
            "Epoch:  972\n",
            "Training: Iteration: 760500. Loss: 3.3499019145965576. Accuracy: 25.804\n",
            "Testing: Iteration: 760500. Loss: 3.3499019145965576. Accuracy: 18.29\n",
            "Epoch:  973\n",
            "Training: Iteration: 761000. Loss: 3.108509063720703. Accuracy: 25.826\n",
            "Testing: Iteration: 761000. Loss: 3.108509063720703. Accuracy: 18.41\n",
            "Training: Iteration: 761500. Loss: 3.3346333503723145. Accuracy: 25.798\n",
            "Testing: Iteration: 761500. Loss: 3.3346333503723145. Accuracy: 18.43\n",
            "Epoch:  974\n",
            "Training: Iteration: 762000. Loss: 3.1641929149627686. Accuracy: 25.764\n",
            "Testing: Iteration: 762000. Loss: 3.1641929149627686. Accuracy: 18.29\n",
            "Epoch:  975\n",
            "Training: Iteration: 762500. Loss: 3.1008245944976807. Accuracy: 25.838\n",
            "Testing: Iteration: 762500. Loss: 3.1008245944976807. Accuracy: 18.34\n",
            "Training: Iteration: 763000. Loss: 3.284079074859619. Accuracy: 25.784\n",
            "Testing: Iteration: 763000. Loss: 3.284079074859619. Accuracy: 18.31\n",
            "Epoch:  976\n",
            "Training: Iteration: 763500. Loss: 3.241201639175415. Accuracy: 25.796\n",
            "Testing: Iteration: 763500. Loss: 3.241201639175415. Accuracy: 18.27\n",
            "Training: Iteration: 764000. Loss: 3.2784361839294434. Accuracy: 25.844\n",
            "Testing: Iteration: 764000. Loss: 3.2784361839294434. Accuracy: 18.4\n",
            "Epoch:  977\n",
            "Training: Iteration: 764500. Loss: 3.1654155254364014. Accuracy: 25.778\n",
            "Testing: Iteration: 764500. Loss: 3.1654155254364014. Accuracy: 18.33\n",
            "Epoch:  978\n",
            "Training: Iteration: 765000. Loss: 3.571387529373169. Accuracy: 25.786\n",
            "Testing: Iteration: 765000. Loss: 3.571387529373169. Accuracy: 18.39\n",
            "Training: Iteration: 765500. Loss: 2.8423759937286377. Accuracy: 25.796\n",
            "Testing: Iteration: 765500. Loss: 2.8423759937286377. Accuracy: 18.41\n",
            "Epoch:  979\n",
            "Training: Iteration: 766000. Loss: 3.2484560012817383. Accuracy: 25.83\n",
            "Testing: Iteration: 766000. Loss: 3.2484560012817383. Accuracy: 18.31\n",
            "Epoch:  980\n",
            "Training: Iteration: 766500. Loss: 3.483295202255249. Accuracy: 25.796\n",
            "Testing: Iteration: 766500. Loss: 3.483295202255249. Accuracy: 18.34\n",
            "Training: Iteration: 767000. Loss: 3.303149700164795. Accuracy: 25.8\n",
            "Testing: Iteration: 767000. Loss: 3.303149700164795. Accuracy: 18.36\n",
            "Epoch:  981\n",
            "Training: Iteration: 767500. Loss: 3.3298630714416504. Accuracy: 25.744\n",
            "Testing: Iteration: 767500. Loss: 3.3298630714416504. Accuracy: 18.3\n",
            "Epoch:  982\n",
            "Training: Iteration: 768000. Loss: 3.3274459838867188. Accuracy: 25.866\n",
            "Testing: Iteration: 768000. Loss: 3.3274459838867188. Accuracy: 18.33\n",
            "Training: Iteration: 768500. Loss: 3.228024959564209. Accuracy: 25.786\n",
            "Testing: Iteration: 768500. Loss: 3.228024959564209. Accuracy: 18.39\n",
            "Epoch:  983\n",
            "Training: Iteration: 769000. Loss: 3.389104127883911. Accuracy: 25.748\n",
            "Testing: Iteration: 769000. Loss: 3.389104127883911. Accuracy: 18.23\n",
            "Epoch:  984\n",
            "Training: Iteration: 769500. Loss: 3.312948703765869. Accuracy: 25.856\n",
            "Testing: Iteration: 769500. Loss: 3.312948703765869. Accuracy: 18.4\n",
            "Training: Iteration: 770000. Loss: 3.6756134033203125. Accuracy: 25.746\n",
            "Testing: Iteration: 770000. Loss: 3.6756134033203125. Accuracy: 18.34\n",
            "Epoch:  985\n",
            "Training: Iteration: 770500. Loss: 3.2230517864227295. Accuracy: 25.802\n",
            "Testing: Iteration: 770500. Loss: 3.2230517864227295. Accuracy: 18.3\n",
            "Training: Iteration: 771000. Loss: 3.2248849868774414. Accuracy: 25.812\n",
            "Testing: Iteration: 771000. Loss: 3.2248849868774414. Accuracy: 18.44\n",
            "Epoch:  986\n",
            "Training: Iteration: 771500. Loss: 3.3230082988739014. Accuracy: 25.81\n",
            "Testing: Iteration: 771500. Loss: 3.3230082988739014. Accuracy: 18.41\n",
            "Epoch:  987\n",
            "Training: Iteration: 772000. Loss: 2.90932035446167. Accuracy: 25.788\n",
            "Testing: Iteration: 772000. Loss: 2.90932035446167. Accuracy: 18.34\n",
            "Training: Iteration: 772500. Loss: 3.2721574306488037. Accuracy: 25.778\n",
            "Testing: Iteration: 772500. Loss: 3.2721574306488037. Accuracy: 18.42\n",
            "Epoch:  988\n",
            "Training: Iteration: 773000. Loss: 3.2757699489593506. Accuracy: 25.76\n",
            "Testing: Iteration: 773000. Loss: 3.2757699489593506. Accuracy: 18.35\n",
            "Epoch:  989\n",
            "Training: Iteration: 773500. Loss: 3.651850938796997. Accuracy: 25.84\n",
            "Testing: Iteration: 773500. Loss: 3.651850938796997. Accuracy: 18.4\n",
            "Training: Iteration: 774000. Loss: 3.3045263290405273. Accuracy: 25.806\n",
            "Testing: Iteration: 774000. Loss: 3.3045263290405273. Accuracy: 18.31\n",
            "Epoch:  990\n",
            "Training: Iteration: 774500. Loss: 3.154494285583496. Accuracy: 25.728\n",
            "Testing: Iteration: 774500. Loss: 3.154494285583496. Accuracy: 18.32\n",
            "Epoch:  991\n",
            "Training: Iteration: 775000. Loss: 3.194875955581665. Accuracy: 25.818\n",
            "Testing: Iteration: 775000. Loss: 3.194875955581665. Accuracy: 18.28\n",
            "Training: Iteration: 775500. Loss: 3.419644832611084. Accuracy: 25.77\n",
            "Testing: Iteration: 775500. Loss: 3.419644832611084. Accuracy: 18.32\n",
            "Epoch:  992\n",
            "Training: Iteration: 776000. Loss: 2.9432406425476074. Accuracy: 25.82\n",
            "Testing: Iteration: 776000. Loss: 2.9432406425476074. Accuracy: 18.32\n",
            "Training: Iteration: 776500. Loss: 3.3107635974884033. Accuracy: 25.824\n",
            "Testing: Iteration: 776500. Loss: 3.3107635974884033. Accuracy: 18.39\n",
            "Epoch:  993\n",
            "Training: Iteration: 777000. Loss: 3.1992225646972656. Accuracy: 25.8\n",
            "Testing: Iteration: 777000. Loss: 3.1992225646972656. Accuracy: 18.37\n",
            "Epoch:  994\n",
            "Training: Iteration: 777500. Loss: 2.767559289932251. Accuracy: 25.78\n",
            "Testing: Iteration: 777500. Loss: 2.767559289932251. Accuracy: 18.38\n",
            "Training: Iteration: 778000. Loss: 3.316162347793579. Accuracy: 25.81\n",
            "Testing: Iteration: 778000. Loss: 3.316162347793579. Accuracy: 18.44\n",
            "Epoch:  995\n",
            "Training: Iteration: 778500. Loss: 3.3294198513031006. Accuracy: 25.826\n",
            "Testing: Iteration: 778500. Loss: 3.3294198513031006. Accuracy: 18.34\n",
            "Epoch:  996\n",
            "Training: Iteration: 779000. Loss: 3.4686667919158936. Accuracy: 25.822\n",
            "Testing: Iteration: 779000. Loss: 3.4686667919158936. Accuracy: 18.39\n",
            "Training: Iteration: 779500. Loss: 3.607149362564087. Accuracy: 25.828\n",
            "Testing: Iteration: 779500. Loss: 3.607149362564087. Accuracy: 18.35\n",
            "Epoch:  997\n",
            "Training: Iteration: 780000. Loss: 3.1181294918060303. Accuracy: 25.732\n",
            "Testing: Iteration: 780000. Loss: 3.1181294918060303. Accuracy: 18.35\n",
            "Epoch:  998\n",
            "Training: Iteration: 780500. Loss: 3.0373215675354004. Accuracy: 25.876\n",
            "Testing: Iteration: 780500. Loss: 3.0373215675354004. Accuracy: 18.38\n",
            "Training: Iteration: 781000. Loss: 3.2429049015045166. Accuracy: 25.8\n",
            "Testing: Iteration: 781000. Loss: 3.2429049015045166. Accuracy: 18.35\n",
            "Epoch:  999\n",
            "Training: Iteration: 781500. Loss: 3.4847841262817383. Accuracy: 25.754\n",
            "Testing: Iteration: 781500. Loss: 3.4847841262817383. Accuracy: 18.32\n",
            "Training: Iteration: 782000. Loss: 2.991288661956787. Accuracy: 25.848\n",
            "Testing: Iteration: 782000. Loss: 2.991288661956787. Accuracy: 18.42\n",
            "Epoch:  1000\n",
            "Training: Iteration: 782500. Loss: 3.180724620819092. Accuracy: 25.78\n",
            "Testing: Iteration: 782500. Loss: 3.180724620819092. Accuracy: 18.3\n",
            "Epoch:  1001\n",
            "Training: Iteration: 783000. Loss: 2.9225964546203613. Accuracy: 25.764\n",
            "Testing: Iteration: 783000. Loss: 2.9225964546203613. Accuracy: 18.32\n",
            "Training: Iteration: 783500. Loss: 2.752399444580078. Accuracy: 25.82\n",
            "Testing: Iteration: 783500. Loss: 2.752399444580078. Accuracy: 18.39\n",
            "Epoch:  1002\n",
            "Training: Iteration: 784000. Loss: 3.3025646209716797. Accuracy: 25.838\n",
            "Testing: Iteration: 784000. Loss: 3.3025646209716797. Accuracy: 18.34\n",
            "Epoch:  1003\n",
            "Training: Iteration: 784500. Loss: 3.4194815158843994. Accuracy: 25.816\n",
            "Testing: Iteration: 784500. Loss: 3.4194815158843994. Accuracy: 18.39\n",
            "Training: Iteration: 785000. Loss: 3.0432395935058594. Accuracy: 25.798\n",
            "Testing: Iteration: 785000. Loss: 3.0432395935058594. Accuracy: 18.37\n",
            "Epoch:  1004\n",
            "Training: Iteration: 785500. Loss: 3.2342731952667236. Accuracy: 25.778\n",
            "Testing: Iteration: 785500. Loss: 3.2342731952667236. Accuracy: 18.3\n",
            "Epoch:  1005\n",
            "Training: Iteration: 786000. Loss: 3.0936825275421143. Accuracy: 25.858\n",
            "Testing: Iteration: 786000. Loss: 3.0936825275421143. Accuracy: 18.4\n",
            "Training: Iteration: 786500. Loss: 3.1077475547790527. Accuracy: 25.79\n",
            "Testing: Iteration: 786500. Loss: 3.1077475547790527. Accuracy: 18.34\n",
            "Epoch:  1006\n",
            "Training: Iteration: 787000. Loss: 3.533627510070801. Accuracy: 25.782\n",
            "Testing: Iteration: 787000. Loss: 3.533627510070801. Accuracy: 18.27\n",
            "Epoch:  1007\n",
            "Training: Iteration: 787500. Loss: 3.314439535140991. Accuracy: 25.85\n",
            "Testing: Iteration: 787500. Loss: 3.314439535140991. Accuracy: 18.41\n",
            "Training: Iteration: 788000. Loss: 3.5299158096313477. Accuracy: 25.754\n",
            "Testing: Iteration: 788000. Loss: 3.5299158096313477. Accuracy: 18.41\n",
            "Epoch:  1008\n",
            "Training: Iteration: 788500. Loss: 3.2895781993865967. Accuracy: 25.798\n",
            "Testing: Iteration: 788500. Loss: 3.2895781993865967. Accuracy: 18.31\n",
            "Training: Iteration: 789000. Loss: 3.1425976753234863. Accuracy: 25.83\n",
            "Testing: Iteration: 789000. Loss: 3.1425976753234863. Accuracy: 18.39\n",
            "Epoch:  1009\n",
            "Training: Iteration: 789500. Loss: 3.4691336154937744. Accuracy: 25.798\n",
            "Testing: Iteration: 789500. Loss: 3.4691336154937744. Accuracy: 18.42\n",
            "Epoch:  1010\n",
            "Training: Iteration: 790000. Loss: 3.131312608718872. Accuracy: 25.812\n",
            "Testing: Iteration: 790000. Loss: 3.131312608718872. Accuracy: 18.31\n",
            "Training: Iteration: 790500. Loss: 3.3550143241882324. Accuracy: 25.822\n",
            "Testing: Iteration: 790500. Loss: 3.3550143241882324. Accuracy: 18.43\n",
            "Epoch:  1011\n",
            "Training: Iteration: 791000. Loss: 3.259673833847046. Accuracy: 25.842\n",
            "Testing: Iteration: 791000. Loss: 3.259673833847046. Accuracy: 18.29\n",
            "Epoch:  1012\n",
            "Training: Iteration: 791500. Loss: 3.3266823291778564. Accuracy: 25.844\n",
            "Testing: Iteration: 791500. Loss: 3.3266823291778564. Accuracy: 18.41\n",
            "Training: Iteration: 792000. Loss: 3.0810415744781494. Accuracy: 25.8\n",
            "Testing: Iteration: 792000. Loss: 3.0810415744781494. Accuracy: 18.39\n",
            "Epoch:  1013\n",
            "Training: Iteration: 792500. Loss: 2.9562642574310303. Accuracy: 25.746\n",
            "Testing: Iteration: 792500. Loss: 2.9562642574310303. Accuracy: 18.32\n",
            "Epoch:  1014\n",
            "Training: Iteration: 793000. Loss: 2.9451966285705566. Accuracy: 25.86\n",
            "Testing: Iteration: 793000. Loss: 2.9451966285705566. Accuracy: 18.3\n",
            "Training: Iteration: 793500. Loss: 3.0919406414031982. Accuracy: 25.794\n",
            "Testing: Iteration: 793500. Loss: 3.0919406414031982. Accuracy: 18.31\n",
            "Epoch:  1015\n",
            "Training: Iteration: 794000. Loss: 3.2771177291870117. Accuracy: 25.8\n",
            "Testing: Iteration: 794000. Loss: 3.2771177291870117. Accuracy: 18.3\n",
            "Training: Iteration: 794500. Loss: 3.3387789726257324. Accuracy: 25.824\n",
            "Testing: Iteration: 794500. Loss: 3.3387789726257324. Accuracy: 18.4\n",
            "Epoch:  1016\n",
            "Training: Iteration: 795000. Loss: 3.317201852798462. Accuracy: 25.804\n",
            "Testing: Iteration: 795000. Loss: 3.317201852798462. Accuracy: 18.37\n",
            "Epoch:  1017\n",
            "Training: Iteration: 795500. Loss: 3.0059401988983154. Accuracy: 25.8\n",
            "Testing: Iteration: 795500. Loss: 3.0059401988983154. Accuracy: 18.35\n",
            "Training: Iteration: 796000. Loss: 3.4412426948547363. Accuracy: 25.83\n",
            "Testing: Iteration: 796000. Loss: 3.4412426948547363. Accuracy: 18.41\n",
            "Epoch:  1018\n",
            "Training: Iteration: 796500. Loss: 3.327967643737793. Accuracy: 25.836\n",
            "Testing: Iteration: 796500. Loss: 3.327967643737793. Accuracy: 18.34\n",
            "Epoch:  1019\n",
            "Training: Iteration: 797000. Loss: 3.051173686981201. Accuracy: 25.83\n",
            "Testing: Iteration: 797000. Loss: 3.051173686981201. Accuracy: 18.35\n",
            "Training: Iteration: 797500. Loss: 2.943938732147217. Accuracy: 25.802\n",
            "Testing: Iteration: 797500. Loss: 2.943938732147217. Accuracy: 18.36\n",
            "Epoch:  1020\n",
            "Training: Iteration: 798000. Loss: 2.808605670928955. Accuracy: 25.79\n",
            "Testing: Iteration: 798000. Loss: 2.808605670928955. Accuracy: 18.26\n",
            "Epoch:  1021\n",
            "Training: Iteration: 798500. Loss: 3.004132032394409. Accuracy: 25.88\n",
            "Testing: Iteration: 798500. Loss: 3.004132032394409. Accuracy: 18.37\n",
            "Training: Iteration: 799000. Loss: 3.330935001373291. Accuracy: 25.776\n",
            "Testing: Iteration: 799000. Loss: 3.330935001373291. Accuracy: 18.42\n",
            "Epoch:  1022\n",
            "Training: Iteration: 799500. Loss: 3.1571156978607178. Accuracy: 25.792\n",
            "Testing: Iteration: 799500. Loss: 3.1571156978607178. Accuracy: 18.26\n",
            "Epoch:  1023\n",
            "Training: Iteration: 800000. Loss: 3.105734348297119. Accuracy: 25.818\n",
            "Testing: Iteration: 800000. Loss: 3.105734348297119. Accuracy: 18.36\n",
            "Training: Iteration: 800500. Loss: 3.333375930786133. Accuracy: 25.756\n",
            "Testing: Iteration: 800500. Loss: 3.333375930786133. Accuracy: 18.34\n",
            "Epoch:  1024\n",
            "Training: Iteration: 801000. Loss: 3.091671943664551. Accuracy: 25.822\n",
            "Testing: Iteration: 801000. Loss: 3.091671943664551. Accuracy: 18.3\n",
            "Training: Iteration: 801500. Loss: 3.2057864665985107. Accuracy: 25.798\n",
            "Testing: Iteration: 801500. Loss: 3.2057864665985107. Accuracy: 18.43\n",
            "Epoch:  1025\n",
            "Training: Iteration: 802000. Loss: 2.8179800510406494. Accuracy: 25.82\n",
            "Testing: Iteration: 802000. Loss: 2.8179800510406494. Accuracy: 18.39\n",
            "Epoch:  1026\n",
            "Training: Iteration: 802500. Loss: 3.149484872817993. Accuracy: 25.79\n",
            "Testing: Iteration: 802500. Loss: 3.149484872817993. Accuracy: 18.35\n",
            "Training: Iteration: 803000. Loss: 3.532453775405884. Accuracy: 25.792\n",
            "Testing: Iteration: 803000. Loss: 3.532453775405884. Accuracy: 18.42\n",
            "Epoch:  1027\n",
            "Training: Iteration: 803500. Loss: 2.929827928543091. Accuracy: 25.764\n",
            "Testing: Iteration: 803500. Loss: 2.929827928543091. Accuracy: 18.33\n",
            "Epoch:  1028\n",
            "Training: Iteration: 804000. Loss: 3.3567609786987305. Accuracy: 25.83\n",
            "Testing: Iteration: 804000. Loss: 3.3567609786987305. Accuracy: 18.35\n",
            "Training: Iteration: 804500. Loss: 3.3004653453826904. Accuracy: 25.824\n",
            "Testing: Iteration: 804500. Loss: 3.3004653453826904. Accuracy: 18.39\n",
            "Epoch:  1029\n",
            "Training: Iteration: 805000. Loss: 3.265997886657715. Accuracy: 25.75\n",
            "Testing: Iteration: 805000. Loss: 3.265997886657715. Accuracy: 18.31\n",
            "Epoch:  1030\n",
            "Training: Iteration: 805500. Loss: 3.0208542346954346. Accuracy: 25.824\n",
            "Testing: Iteration: 805500. Loss: 3.0208542346954346. Accuracy: 18.31\n",
            "Training: Iteration: 806000. Loss: 3.3886232376098633. Accuracy: 25.8\n",
            "Testing: Iteration: 806000. Loss: 3.3886232376098633. Accuracy: 18.32\n",
            "Epoch:  1031\n",
            "Training: Iteration: 806500. Loss: 3.059485673904419. Accuracy: 25.836\n",
            "Testing: Iteration: 806500. Loss: 3.059485673904419. Accuracy: 18.29\n",
            "Training: Iteration: 807000. Loss: 3.6850316524505615. Accuracy: 25.812\n",
            "Testing: Iteration: 807000. Loss: 3.6850316524505615. Accuracy: 18.4\n",
            "Epoch:  1032\n",
            "Training: Iteration: 807500. Loss: 3.6297852993011475. Accuracy: 25.832\n",
            "Testing: Iteration: 807500. Loss: 3.6297852993011475. Accuracy: 18.34\n",
            "Epoch:  1033\n",
            "Training: Iteration: 808000. Loss: 3.0658416748046875. Accuracy: 25.816\n",
            "Testing: Iteration: 808000. Loss: 3.0658416748046875. Accuracy: 18.35\n",
            "Training: Iteration: 808500. Loss: 3.500535488128662. Accuracy: 25.83\n",
            "Testing: Iteration: 808500. Loss: 3.500535488128662. Accuracy: 18.44\n",
            "Epoch:  1034\n",
            "Training: Iteration: 809000. Loss: 3.2657127380371094. Accuracy: 25.838\n",
            "Testing: Iteration: 809000. Loss: 3.2657127380371094. Accuracy: 18.31\n",
            "Epoch:  1035\n",
            "Training: Iteration: 809500. Loss: 3.2202870845794678. Accuracy: 25.84\n",
            "Testing: Iteration: 809500. Loss: 3.2202870845794678. Accuracy: 18.38\n",
            "Training: Iteration: 810000. Loss: 3.2868306636810303. Accuracy: 25.83\n",
            "Testing: Iteration: 810000. Loss: 3.2868306636810303. Accuracy: 18.33\n",
            "Epoch:  1036\n",
            "Training: Iteration: 810500. Loss: 3.417616367340088. Accuracy: 25.75\n",
            "Testing: Iteration: 810500. Loss: 3.417616367340088. Accuracy: 18.3\n",
            "Epoch:  1037\n",
            "Training: Iteration: 811000. Loss: 3.095728874206543. Accuracy: 25.86\n",
            "Testing: Iteration: 811000. Loss: 3.095728874206543. Accuracy: 18.36\n",
            "Training: Iteration: 811500. Loss: 3.000044584274292. Accuracy: 25.794\n",
            "Testing: Iteration: 811500. Loss: 3.000044584274292. Accuracy: 18.37\n",
            "Epoch:  1038\n",
            "Training: Iteration: 812000. Loss: 3.30911922454834. Accuracy: 25.772\n",
            "Testing: Iteration: 812000. Loss: 3.30911922454834. Accuracy: 18.27\n",
            "Epoch:  1039\n",
            "Training: Iteration: 812500. Loss: 3.200467586517334. Accuracy: 25.824\n",
            "Testing: Iteration: 812500. Loss: 3.200467586517334. Accuracy: 18.42\n",
            "Training: Iteration: 813000. Loss: 3.1529812812805176. Accuracy: 25.788\n",
            "Testing: Iteration: 813000. Loss: 3.1529812812805176. Accuracy: 18.3\n",
            "Epoch:  1040\n",
            "Training: Iteration: 813500. Loss: 3.5693790912628174. Accuracy: 25.802\n",
            "Testing: Iteration: 813500. Loss: 3.5693790912628174. Accuracy: 18.33\n",
            "Training: Iteration: 814000. Loss: 3.170372486114502. Accuracy: 25.842\n",
            "Testing: Iteration: 814000. Loss: 3.170372486114502. Accuracy: 18.38\n",
            "Epoch:  1041\n",
            "Training: Iteration: 814500. Loss: 3.0955991744995117. Accuracy: 25.84\n",
            "Testing: Iteration: 814500. Loss: 3.0955991744995117. Accuracy: 18.32\n",
            "Epoch:  1042\n",
            "Training: Iteration: 815000. Loss: 3.485935926437378. Accuracy: 25.814\n",
            "Testing: Iteration: 815000. Loss: 3.485935926437378. Accuracy: 18.36\n",
            "Training: Iteration: 815500. Loss: 3.160625457763672. Accuracy: 25.798\n",
            "Testing: Iteration: 815500. Loss: 3.160625457763672. Accuracy: 18.38\n",
            "Epoch:  1043\n",
            "Training: Iteration: 816000. Loss: 3.147604465484619. Accuracy: 25.794\n",
            "Testing: Iteration: 816000. Loss: 3.147604465484619. Accuracy: 18.31\n",
            "Epoch:  1044\n",
            "Training: Iteration: 816500. Loss: 3.5502166748046875. Accuracy: 25.86\n",
            "Testing: Iteration: 816500. Loss: 3.5502166748046875. Accuracy: 18.34\n",
            "Training: Iteration: 817000. Loss: 3.611224412918091. Accuracy: 25.812\n",
            "Testing: Iteration: 817000. Loss: 3.611224412918091. Accuracy: 18.34\n",
            "Epoch:  1045\n",
            "Training: Iteration: 817500. Loss: 3.294760227203369. Accuracy: 25.804\n",
            "Testing: Iteration: 817500. Loss: 3.294760227203369. Accuracy: 18.29\n",
            "Epoch:  1046\n",
            "Training: Iteration: 818000. Loss: 3.3573553562164307. Accuracy: 25.85\n",
            "Testing: Iteration: 818000. Loss: 3.3573553562164307. Accuracy: 18.41\n",
            "Training: Iteration: 818500. Loss: 3.5285093784332275. Accuracy: 25.776\n",
            "Testing: Iteration: 818500. Loss: 3.5285093784332275. Accuracy: 18.35\n",
            "Epoch:  1047\n",
            "Training: Iteration: 819000. Loss: 2.7837936878204346. Accuracy: 25.814\n",
            "Testing: Iteration: 819000. Loss: 2.7837936878204346. Accuracy: 18.27\n",
            "Training: Iteration: 819500. Loss: 3.135859966278076. Accuracy: 25.83\n",
            "Testing: Iteration: 819500. Loss: 3.135859966278076. Accuracy: 18.37\n",
            "Epoch:  1048\n",
            "Training: Iteration: 820000. Loss: 3.0184383392333984. Accuracy: 25.824\n",
            "Testing: Iteration: 820000. Loss: 3.0184383392333984. Accuracy: 18.35\n",
            "Epoch:  1049\n",
            "Training: Iteration: 820500. Loss: 3.3889338970184326. Accuracy: 25.81\n",
            "Testing: Iteration: 820500. Loss: 3.3889338970184326. Accuracy: 18.34\n",
            "Training: Iteration: 821000. Loss: 2.725010871887207. Accuracy: 25.836\n",
            "Testing: Iteration: 821000. Loss: 2.725010871887207. Accuracy: 18.41\n",
            "Epoch:  1050\n",
            "Training: Iteration: 821500. Loss: 3.7349205017089844. Accuracy: 25.832\n",
            "Testing: Iteration: 821500. Loss: 3.7349205017089844. Accuracy: 18.29\n",
            "Epoch:  1051\n",
            "Training: Iteration: 822000. Loss: 2.6395442485809326. Accuracy: 25.846\n",
            "Testing: Iteration: 822000. Loss: 2.6395442485809326. Accuracy: 18.38\n",
            "Training: Iteration: 822500. Loss: 3.5181148052215576. Accuracy: 25.818\n",
            "Testing: Iteration: 822500. Loss: 3.5181148052215576. Accuracy: 18.35\n",
            "Epoch:  1052\n",
            "Training: Iteration: 823000. Loss: 3.374796152114868. Accuracy: 25.748\n",
            "Testing: Iteration: 823000. Loss: 3.374796152114868. Accuracy: 18.29\n",
            "Epoch:  1053\n",
            "Training: Iteration: 823500. Loss: 2.923189640045166. Accuracy: 25.882\n",
            "Testing: Iteration: 823500. Loss: 2.923189640045166. Accuracy: 18.37\n",
            "Training: Iteration: 824000. Loss: 3.1687488555908203. Accuracy: 25.794\n",
            "Testing: Iteration: 824000. Loss: 3.1687488555908203. Accuracy: 18.3\n",
            "Epoch:  1054\n",
            "Training: Iteration: 824500. Loss: 3.127363920211792. Accuracy: 25.828\n",
            "Testing: Iteration: 824500. Loss: 3.127363920211792. Accuracy: 18.29\n",
            "Training: Iteration: 825000. Loss: 3.5947065353393555. Accuracy: 25.852\n",
            "Testing: Iteration: 825000. Loss: 3.5947065353393555. Accuracy: 18.41\n",
            "Epoch:  1055\n",
            "Training: Iteration: 825500. Loss: 3.1736321449279785. Accuracy: 25.81\n",
            "Testing: Iteration: 825500. Loss: 3.1736321449279785. Accuracy: 18.34\n",
            "Epoch:  1056\n",
            "Training: Iteration: 826000. Loss: 3.2937450408935547. Accuracy: 25.808\n",
            "Testing: Iteration: 826000. Loss: 3.2937450408935547. Accuracy: 18.34\n",
            "Training: Iteration: 826500. Loss: 3.1167397499084473. Accuracy: 25.83\n",
            "Testing: Iteration: 826500. Loss: 3.1167397499084473. Accuracy: 18.44\n",
            "Epoch:  1057\n",
            "Training: Iteration: 827000. Loss: 3.136378049850464. Accuracy: 25.862\n",
            "Testing: Iteration: 827000. Loss: 3.136378049850464. Accuracy: 18.33\n",
            "Epoch:  1058\n",
            "Training: Iteration: 827500. Loss: 3.0765697956085205. Accuracy: 25.852\n",
            "Testing: Iteration: 827500. Loss: 3.0765697956085205. Accuracy: 18.31\n",
            "Training: Iteration: 828000. Loss: 3.4244890213012695. Accuracy: 25.796\n",
            "Testing: Iteration: 828000. Loss: 3.4244890213012695. Accuracy: 18.35\n",
            "Epoch:  1059\n",
            "Training: Iteration: 828500. Loss: 3.371823787689209. Accuracy: 25.8\n",
            "Testing: Iteration: 828500. Loss: 3.371823787689209. Accuracy: 18.31\n",
            "Epoch:  1060\n",
            "Training: Iteration: 829000. Loss: 3.183729410171509. Accuracy: 25.862\n",
            "Testing: Iteration: 829000. Loss: 3.183729410171509. Accuracy: 18.36\n",
            "Training: Iteration: 829500. Loss: 3.1357789039611816. Accuracy: 25.79\n",
            "Testing: Iteration: 829500. Loss: 3.1357789039611816. Accuracy: 18.35\n",
            "Epoch:  1061\n",
            "Training: Iteration: 830000. Loss: 2.691348075866699. Accuracy: 25.788\n",
            "Testing: Iteration: 830000. Loss: 2.691348075866699. Accuracy: 18.25\n",
            "Epoch:  1062\n",
            "Training: Iteration: 830500. Loss: 3.089693069458008. Accuracy: 25.84\n",
            "Testing: Iteration: 830500. Loss: 3.089693069458008. Accuracy: 18.4\n",
            "Training: Iteration: 831000. Loss: 3.336250066757202. Accuracy: 25.788\n",
            "Testing: Iteration: 831000. Loss: 3.336250066757202. Accuracy: 18.32\n",
            "Epoch:  1063\n",
            "Training: Iteration: 831500. Loss: 3.3914616107940674. Accuracy: 25.818\n",
            "Testing: Iteration: 831500. Loss: 3.3914616107940674. Accuracy: 18.24\n",
            "Training: Iteration: 832000. Loss: 3.4138782024383545. Accuracy: 25.804\n",
            "Testing: Iteration: 832000. Loss: 3.4138782024383545. Accuracy: 18.4\n",
            "Epoch:  1064\n",
            "Training: Iteration: 832500. Loss: 3.399718761444092. Accuracy: 25.862\n",
            "Testing: Iteration: 832500. Loss: 3.399718761444092. Accuracy: 18.36\n",
            "Epoch:  1065\n",
            "Training: Iteration: 833000. Loss: 3.2331907749176025. Accuracy: 25.8\n",
            "Testing: Iteration: 833000. Loss: 3.2331907749176025. Accuracy: 18.31\n",
            "Training: Iteration: 833500. Loss: 3.101778030395508. Accuracy: 25.81\n",
            "Testing: Iteration: 833500. Loss: 3.101778030395508. Accuracy: 18.4\n",
            "Epoch:  1066\n",
            "Training: Iteration: 834000. Loss: 3.5410304069519043. Accuracy: 25.778\n",
            "Testing: Iteration: 834000. Loss: 3.5410304069519043. Accuracy: 18.26\n",
            "Epoch:  1067\n",
            "Training: Iteration: 834500. Loss: 3.0934817790985107. Accuracy: 25.864\n",
            "Testing: Iteration: 834500. Loss: 3.0934817790985107. Accuracy: 18.35\n",
            "Training: Iteration: 835000. Loss: 3.5956079959869385. Accuracy: 25.836\n",
            "Testing: Iteration: 835000. Loss: 3.5956079959869385. Accuracy: 18.38\n",
            "Epoch:  1068\n",
            "Training: Iteration: 835500. Loss: 3.3614251613616943. Accuracy: 25.764\n",
            "Testing: Iteration: 835500. Loss: 3.3614251613616943. Accuracy: 18.26\n",
            "Epoch:  1069\n",
            "Training: Iteration: 836000. Loss: 3.3472952842712402. Accuracy: 25.846\n",
            "Testing: Iteration: 836000. Loss: 3.3472952842712402. Accuracy: 18.34\n",
            "Training: Iteration: 836500. Loss: 3.2934041023254395. Accuracy: 25.798\n",
            "Testing: Iteration: 836500. Loss: 3.2934041023254395. Accuracy: 18.38\n",
            "Epoch:  1070\n",
            "Training: Iteration: 837000. Loss: 3.093529462814331. Accuracy: 25.83\n",
            "Testing: Iteration: 837000. Loss: 3.093529462814331. Accuracy: 18.27\n",
            "Training: Iteration: 837500. Loss: 2.915147542953491. Accuracy: 25.84\n",
            "Testing: Iteration: 837500. Loss: 2.915147542953491. Accuracy: 18.34\n",
            "Epoch:  1071\n",
            "Training: Iteration: 838000. Loss: 2.8675267696380615. Accuracy: 25.854\n",
            "Testing: Iteration: 838000. Loss: 2.8675267696380615. Accuracy: 18.33\n",
            "Epoch:  1072\n",
            "Training: Iteration: 838500. Loss: 3.011655807495117. Accuracy: 25.83\n",
            "Testing: Iteration: 838500. Loss: 3.011655807495117. Accuracy: 18.32\n",
            "Training: Iteration: 839000. Loss: 3.5432212352752686. Accuracy: 25.828\n",
            "Testing: Iteration: 839000. Loss: 3.5432212352752686. Accuracy: 18.4\n",
            "Epoch:  1073\n",
            "Training: Iteration: 839500. Loss: 3.158262014389038. Accuracy: 25.85\n",
            "Testing: Iteration: 839500. Loss: 3.158262014389038. Accuracy: 18.32\n",
            "Epoch:  1074\n",
            "Training: Iteration: 840000. Loss: 3.2311761379241943. Accuracy: 25.836\n",
            "Testing: Iteration: 840000. Loss: 3.2311761379241943. Accuracy: 18.38\n",
            "Training: Iteration: 840500. Loss: 3.4491209983825684. Accuracy: 25.82\n",
            "Testing: Iteration: 840500. Loss: 3.4491209983825684. Accuracy: 18.34\n",
            "Epoch:  1075\n",
            "Training: Iteration: 841000. Loss: 3.5067713260650635. Accuracy: 25.78\n",
            "Testing: Iteration: 841000. Loss: 3.5067713260650635. Accuracy: 18.29\n",
            "Epoch:  1076\n",
            "Training: Iteration: 841500. Loss: 3.2763187885284424. Accuracy: 25.854\n",
            "Testing: Iteration: 841500. Loss: 3.2763187885284424. Accuracy: 18.27\n",
            "Training: Iteration: 842000. Loss: 2.871166229248047. Accuracy: 25.804\n",
            "Testing: Iteration: 842000. Loss: 2.871166229248047. Accuracy: 18.35\n",
            "Epoch:  1077\n",
            "Training: Iteration: 842500. Loss: 3.053698778152466. Accuracy: 25.792\n",
            "Testing: Iteration: 842500. Loss: 3.053698778152466. Accuracy: 18.24\n",
            "Epoch:  1078\n",
            "Training: Iteration: 843000. Loss: 3.12673282623291. Accuracy: 25.846\n",
            "Testing: Iteration: 843000. Loss: 3.12673282623291. Accuracy: 18.43\n",
            "Training: Iteration: 843500. Loss: 3.6509504318237305. Accuracy: 25.784\n",
            "Testing: Iteration: 843500. Loss: 3.6509504318237305. Accuracy: 18.31\n",
            "Epoch:  1079\n",
            "Training: Iteration: 844000. Loss: 3.064950704574585. Accuracy: 25.852\n",
            "Testing: Iteration: 844000. Loss: 3.064950704574585. Accuracy: 18.34\n",
            "Training: Iteration: 844500. Loss: 2.940596103668213. Accuracy: 25.838\n",
            "Testing: Iteration: 844500. Loss: 2.940596103668213. Accuracy: 18.44\n",
            "Epoch:  1080\n",
            "Training: Iteration: 845000. Loss: 3.5010550022125244. Accuracy: 25.834\n",
            "Testing: Iteration: 845000. Loss: 3.5010550022125244. Accuracy: 18.35\n",
            "Epoch:  1081\n",
            "Training: Iteration: 845500. Loss: 3.1865034103393555. Accuracy: 25.834\n",
            "Testing: Iteration: 845500. Loss: 3.1865034103393555. Accuracy: 18.3\n",
            "Training: Iteration: 846000. Loss: 3.1548924446105957. Accuracy: 25.804\n",
            "Testing: Iteration: 846000. Loss: 3.1548924446105957. Accuracy: 18.35\n",
            "Epoch:  1082\n",
            "Training: Iteration: 846500. Loss: 3.0866775512695312. Accuracy: 25.822\n",
            "Testing: Iteration: 846500. Loss: 3.0866775512695312. Accuracy: 18.28\n",
            "Epoch:  1083\n",
            "Training: Iteration: 847000. Loss: 3.3990650177001953. Accuracy: 25.88\n",
            "Testing: Iteration: 847000. Loss: 3.3990650177001953. Accuracy: 18.33\n",
            "Training: Iteration: 847500. Loss: 3.1684200763702393. Accuracy: 25.798\n",
            "Testing: Iteration: 847500. Loss: 3.1684200763702393. Accuracy: 18.34\n",
            "Epoch:  1084\n",
            "Training: Iteration: 848000. Loss: 3.3768913745880127. Accuracy: 25.796\n",
            "Testing: Iteration: 848000. Loss: 3.3768913745880127. Accuracy: 18.24\n",
            "Epoch:  1085\n",
            "Training: Iteration: 848500. Loss: 3.4317355155944824. Accuracy: 25.864\n",
            "Testing: Iteration: 848500. Loss: 3.4317355155944824. Accuracy: 18.32\n",
            "Training: Iteration: 849000. Loss: 3.327528238296509. Accuracy: 25.798\n",
            "Testing: Iteration: 849000. Loss: 3.327528238296509. Accuracy: 18.35\n",
            "Epoch:  1086\n",
            "Training: Iteration: 849500. Loss: 3.2264299392700195. Accuracy: 25.832\n",
            "Testing: Iteration: 849500. Loss: 3.2264299392700195. Accuracy: 18.24\n",
            "Training: Iteration: 850000. Loss: 3.5357418060302734. Accuracy: 25.832\n",
            "Testing: Iteration: 850000. Loss: 3.5357418060302734. Accuracy: 18.35\n",
            "Epoch:  1087\n",
            "Training: Iteration: 850500. Loss: 3.113243341445923. Accuracy: 25.842\n",
            "Testing: Iteration: 850500. Loss: 3.113243341445923. Accuracy: 18.35\n",
            "Epoch:  1088\n",
            "Training: Iteration: 851000. Loss: 3.1559829711914062. Accuracy: 25.842\n",
            "Testing: Iteration: 851000. Loss: 3.1559829711914062. Accuracy: 18.35\n",
            "Training: Iteration: 851500. Loss: 3.406576633453369. Accuracy: 25.836\n",
            "Testing: Iteration: 851500. Loss: 3.406576633453369. Accuracy: 18.38\n",
            "Epoch:  1089\n",
            "Training: Iteration: 852000. Loss: 3.250075101852417. Accuracy: 25.848\n",
            "Testing: Iteration: 852000. Loss: 3.250075101852417. Accuracy: 18.26\n",
            "Epoch:  1090\n",
            "Training: Iteration: 852500. Loss: 2.907224416732788. Accuracy: 25.87\n",
            "Testing: Iteration: 852500. Loss: 2.907224416732788. Accuracy: 18.33\n",
            "Training: Iteration: 853000. Loss: 3.153515577316284. Accuracy: 25.822\n",
            "Testing: Iteration: 853000. Loss: 3.153515577316284. Accuracy: 18.31\n",
            "Epoch:  1091\n",
            "Training: Iteration: 853500. Loss: 3.4148364067077637. Accuracy: 25.772\n",
            "Testing: Iteration: 853500. Loss: 3.4148364067077637. Accuracy: 18.28\n",
            "Epoch:  1092\n",
            "Training: Iteration: 854000. Loss: 3.337404727935791. Accuracy: 25.89\n",
            "Testing: Iteration: 854000. Loss: 3.337404727935791. Accuracy: 18.3\n",
            "Training: Iteration: 854500. Loss: 3.36954927444458. Accuracy: 25.786\n",
            "Testing: Iteration: 854500. Loss: 3.36954927444458. Accuracy: 18.33\n",
            "Epoch:  1093\n",
            "Training: Iteration: 855000. Loss: 3.3880839347839355. Accuracy: 25.798\n",
            "Testing: Iteration: 855000. Loss: 3.3880839347839355. Accuracy: 18.25\n",
            "Training: Iteration: 855500. Loss: 3.2055976390838623. Accuracy: 25.84\n",
            "Testing: Iteration: 855500. Loss: 3.2055976390838623. Accuracy: 18.37\n",
            "Epoch:  1094\n",
            "Training: Iteration: 856000. Loss: 3.0217227935791016. Accuracy: 25.82\n",
            "Testing: Iteration: 856000. Loss: 3.0217227935791016. Accuracy: 18.32\n",
            "Epoch:  1095\n",
            "Training: Iteration: 856500. Loss: 2.732964038848877. Accuracy: 25.848\n",
            "Testing: Iteration: 856500. Loss: 2.732964038848877. Accuracy: 18.32\n",
            "Training: Iteration: 857000. Loss: 3.275407075881958. Accuracy: 25.874\n",
            "Testing: Iteration: 857000. Loss: 3.275407075881958. Accuracy: 18.34\n",
            "Epoch:  1096\n",
            "Training: Iteration: 857500. Loss: 3.267693042755127. Accuracy: 25.862\n",
            "Testing: Iteration: 857500. Loss: 3.267693042755127. Accuracy: 18.34\n",
            "Epoch:  1097\n",
            "Training: Iteration: 858000. Loss: 3.4470338821411133. Accuracy: 25.854\n",
            "Testing: Iteration: 858000. Loss: 3.4470338821411133. Accuracy: 18.35\n",
            "Training: Iteration: 858500. Loss: 3.175696849822998. Accuracy: 25.792\n",
            "Testing: Iteration: 858500. Loss: 3.175696849822998. Accuracy: 18.39\n",
            "Epoch:  1098\n",
            "Training: Iteration: 859000. Loss: 3.3475708961486816. Accuracy: 25.8\n",
            "Testing: Iteration: 859000. Loss: 3.3475708961486816. Accuracy: 18.25\n",
            "Epoch:  1099\n",
            "Training: Iteration: 859500. Loss: 3.3174986839294434. Accuracy: 25.876\n",
            "Testing: Iteration: 859500. Loss: 3.3174986839294434. Accuracy: 18.27\n",
            "Training: Iteration: 860000. Loss: 2.9298105239868164. Accuracy: 25.814\n",
            "Testing: Iteration: 860000. Loss: 2.9298105239868164. Accuracy: 18.38\n",
            "Epoch:  1100\n",
            "Training: Iteration: 860500. Loss: 3.393496036529541. Accuracy: 25.81\n",
            "Testing: Iteration: 860500. Loss: 3.393496036529541. Accuracy: 18.28\n",
            "Epoch:  1101\n",
            "Training: Iteration: 861000. Loss: 3.0167324542999268. Accuracy: 25.85\n",
            "Testing: Iteration: 861000. Loss: 3.0167324542999268. Accuracy: 18.34\n",
            "Training: Iteration: 861500. Loss: 2.8433570861816406. Accuracy: 25.798\n",
            "Testing: Iteration: 861500. Loss: 2.8433570861816406. Accuracy: 18.3\n",
            "Epoch:  1102\n",
            "Training: Iteration: 862000. Loss: 3.1434249877929688. Accuracy: 25.834\n",
            "Testing: Iteration: 862000. Loss: 3.1434249877929688. Accuracy: 18.25\n",
            "Training: Iteration: 862500. Loss: 2.93393874168396. Accuracy: 25.824\n",
            "Testing: Iteration: 862500. Loss: 2.93393874168396. Accuracy: 18.41\n",
            "Epoch:  1103\n",
            "Training: Iteration: 863000. Loss: 3.260474920272827. Accuracy: 25.864\n",
            "Testing: Iteration: 863000. Loss: 3.260474920272827. Accuracy: 18.36\n",
            "Epoch:  1104\n",
            "Training: Iteration: 863500. Loss: 2.8456313610076904. Accuracy: 25.844\n",
            "Testing: Iteration: 863500. Loss: 2.8456313610076904. Accuracy: 18.32\n",
            "Training: Iteration: 864000. Loss: 3.321629047393799. Accuracy: 25.812\n",
            "Testing: Iteration: 864000. Loss: 3.321629047393799. Accuracy: 18.41\n",
            "Epoch:  1105\n",
            "Training: Iteration: 864500. Loss: 3.215287446975708. Accuracy: 25.83\n",
            "Testing: Iteration: 864500. Loss: 3.215287446975708. Accuracy: 18.27\n",
            "Epoch:  1106\n",
            "Training: Iteration: 865000. Loss: 3.091714859008789. Accuracy: 25.878\n",
            "Testing: Iteration: 865000. Loss: 3.091714859008789. Accuracy: 18.32\n",
            "Training: Iteration: 865500. Loss: 3.3392562866210938. Accuracy: 25.834\n",
            "Testing: Iteration: 865500. Loss: 3.3392562866210938. Accuracy: 18.28\n",
            "Epoch:  1107\n",
            "Training: Iteration: 866000. Loss: 2.8580546379089355. Accuracy: 25.768\n",
            "Testing: Iteration: 866000. Loss: 2.8580546379089355. Accuracy: 18.26\n",
            "Epoch:  1108\n",
            "Training: Iteration: 866500. Loss: 2.9852614402770996. Accuracy: 25.872\n",
            "Testing: Iteration: 866500. Loss: 2.9852614402770996. Accuracy: 18.27\n",
            "Training: Iteration: 867000. Loss: 3.1144356727600098. Accuracy: 25.818\n",
            "Testing: Iteration: 867000. Loss: 3.1144356727600098. Accuracy: 18.29\n",
            "Epoch:  1109\n",
            "Training: Iteration: 867500. Loss: 3.0573902130126953. Accuracy: 25.854\n",
            "Testing: Iteration: 867500. Loss: 3.0573902130126953. Accuracy: 18.27\n",
            "Training: Iteration: 868000. Loss: 2.917454957962036. Accuracy: 25.842\n",
            "Testing: Iteration: 868000. Loss: 2.917454957962036. Accuracy: 18.33\n",
            "Epoch:  1110\n",
            "Training: Iteration: 868500. Loss: 3.225167751312256. Accuracy: 25.814\n",
            "Testing: Iteration: 868500. Loss: 3.225167751312256. Accuracy: 18.32\n",
            "Epoch:  1111\n",
            "Training: Iteration: 869000. Loss: 3.359768867492676. Accuracy: 25.864\n",
            "Testing: Iteration: 869000. Loss: 3.359768867492676. Accuracy: 18.3\n",
            "Training: Iteration: 869500. Loss: 3.2388455867767334. Accuracy: 25.812\n",
            "Testing: Iteration: 869500. Loss: 3.2388455867767334. Accuracy: 18.31\n",
            "Epoch:  1112\n",
            "Training: Iteration: 870000. Loss: 3.0882747173309326. Accuracy: 25.852\n",
            "Testing: Iteration: 870000. Loss: 3.0882747173309326. Accuracy: 18.3\n",
            "Epoch:  1113\n",
            "Training: Iteration: 870500. Loss: 3.3198564052581787. Accuracy: 25.85\n",
            "Testing: Iteration: 870500. Loss: 3.3198564052581787. Accuracy: 18.33\n",
            "Training: Iteration: 871000. Loss: 3.039094924926758. Accuracy: 25.83\n",
            "Testing: Iteration: 871000. Loss: 3.039094924926758. Accuracy: 18.34\n",
            "Epoch:  1114\n",
            "Training: Iteration: 871500. Loss: 3.1085751056671143. Accuracy: 25.784\n",
            "Testing: Iteration: 871500. Loss: 3.1085751056671143. Accuracy: 18.25\n",
            "Epoch:  1115\n",
            "Training: Iteration: 872000. Loss: 3.632866382598877. Accuracy: 25.884\n",
            "Testing: Iteration: 872000. Loss: 3.632866382598877. Accuracy: 18.23\n",
            "Training: Iteration: 872500. Loss: 3.7460949420928955. Accuracy: 25.8\n",
            "Testing: Iteration: 872500. Loss: 3.7460949420928955. Accuracy: 18.34\n",
            "Epoch:  1116\n",
            "Training: Iteration: 873000. Loss: 3.0982666015625. Accuracy: 25.796\n",
            "Testing: Iteration: 873000. Loss: 3.0982666015625. Accuracy: 18.25\n",
            "Epoch:  1117\n",
            "Training: Iteration: 873500. Loss: 3.046363353729248. Accuracy: 25.878\n",
            "Testing: Iteration: 873500. Loss: 3.046363353729248. Accuracy: 18.35\n",
            "Training: Iteration: 874000. Loss: 2.9495444297790527. Accuracy: 25.798\n",
            "Testing: Iteration: 874000. Loss: 2.9495444297790527. Accuracy: 18.31\n",
            "Epoch:  1118\n",
            "Training: Iteration: 874500. Loss: 3.337827682495117. Accuracy: 25.846\n",
            "Testing: Iteration: 874500. Loss: 3.337827682495117. Accuracy: 18.26\n",
            "Training: Iteration: 875000. Loss: 3.154567241668701. Accuracy: 25.852\n",
            "Testing: Iteration: 875000. Loss: 3.154567241668701. Accuracy: 18.36\n",
            "Epoch:  1119\n",
            "Training: Iteration: 875500. Loss: 3.292165517807007. Accuracy: 25.866\n",
            "Testing: Iteration: 875500. Loss: 3.292165517807007. Accuracy: 18.35\n",
            "Epoch:  1120\n",
            "Training: Iteration: 876000. Loss: 3.3895351886749268. Accuracy: 25.864\n",
            "Testing: Iteration: 876000. Loss: 3.3895351886749268. Accuracy: 18.32\n",
            "Training: Iteration: 876500. Loss: 3.0002083778381348. Accuracy: 25.804\n",
            "Testing: Iteration: 876500. Loss: 3.0002083778381348. Accuracy: 18.31\n",
            "Epoch:  1121\n",
            "Training: Iteration: 877000. Loss: 3.612196683883667. Accuracy: 25.86\n",
            "Testing: Iteration: 877000. Loss: 3.612196683883667. Accuracy: 18.3\n",
            "Epoch:  1122\n",
            "Training: Iteration: 877500. Loss: 3.3769121170043945. Accuracy: 25.892\n",
            "Testing: Iteration: 877500. Loss: 3.3769121170043945. Accuracy: 18.25\n",
            "Training: Iteration: 878000. Loss: 3.419696807861328. Accuracy: 25.818\n",
            "Testing: Iteration: 878000. Loss: 3.419696807861328. Accuracy: 18.31\n",
            "Epoch:  1123\n",
            "Training: Iteration: 878500. Loss: 3.2688536643981934. Accuracy: 25.816\n",
            "Testing: Iteration: 878500. Loss: 3.2688536643981934. Accuracy: 18.28\n",
            "Epoch:  1124\n",
            "Training: Iteration: 879000. Loss: 3.224677324295044. Accuracy: 25.862\n",
            "Testing: Iteration: 879000. Loss: 3.224677324295044. Accuracy: 18.27\n",
            "Training: Iteration: 879500. Loss: 3.1301181316375732. Accuracy: 25.802\n",
            "Testing: Iteration: 879500. Loss: 3.1301181316375732. Accuracy: 18.34\n",
            "Epoch:  1125\n",
            "Training: Iteration: 880000. Loss: 3.026843786239624. Accuracy: 25.838\n",
            "Testing: Iteration: 880000. Loss: 3.026843786239624. Accuracy: 18.26\n",
            "Training: Iteration: 880500. Loss: 2.842071771621704. Accuracy: 25.824\n",
            "Testing: Iteration: 880500. Loss: 2.842071771621704. Accuracy: 18.31\n",
            "Epoch:  1126\n",
            "Training: Iteration: 881000. Loss: 3.3498473167419434. Accuracy: 25.86\n",
            "Testing: Iteration: 881000. Loss: 3.3498473167419434. Accuracy: 18.36\n",
            "Epoch:  1127\n",
            "Training: Iteration: 881500. Loss: 3.0528297424316406. Accuracy: 25.868\n",
            "Testing: Iteration: 881500. Loss: 3.0528297424316406. Accuracy: 18.32\n",
            "Training: Iteration: 882000. Loss: 3.5027358531951904. Accuracy: 25.858\n",
            "Testing: Iteration: 882000. Loss: 3.5027358531951904. Accuracy: 18.34\n",
            "Epoch:  1128\n",
            "Training: Iteration: 882500. Loss: 3.1406986713409424. Accuracy: 25.864\n",
            "Testing: Iteration: 882500. Loss: 3.1406986713409424. Accuracy: 18.29\n",
            "Epoch:  1129\n",
            "Training: Iteration: 883000. Loss: 3.205270767211914. Accuracy: 25.884\n",
            "Testing: Iteration: 883000. Loss: 3.205270767211914. Accuracy: 18.26\n",
            "Training: Iteration: 883500. Loss: 3.2211503982543945. Accuracy: 25.83\n",
            "Testing: Iteration: 883500. Loss: 3.2211503982543945. Accuracy: 18.36\n",
            "Epoch:  1130\n",
            "Training: Iteration: 884000. Loss: 3.2973973751068115. Accuracy: 25.808\n",
            "Testing: Iteration: 884000. Loss: 3.2973973751068115. Accuracy: 18.25\n",
            "Epoch:  1131\n",
            "Training: Iteration: 884500. Loss: 3.4460105895996094. Accuracy: 25.872\n",
            "Testing: Iteration: 884500. Loss: 3.4460105895996094. Accuracy: 18.23\n",
            "Training: Iteration: 885000. Loss: 2.9942872524261475. Accuracy: 25.804\n",
            "Testing: Iteration: 885000. Loss: 2.9942872524261475. Accuracy: 18.29\n",
            "Epoch:  1132\n",
            "Training: Iteration: 885500. Loss: 3.113265037536621. Accuracy: 25.826\n",
            "Testing: Iteration: 885500. Loss: 3.113265037536621. Accuracy: 18.25\n",
            "Training: Iteration: 886000. Loss: 3.6801373958587646. Accuracy: 25.864\n",
            "Testing: Iteration: 886000. Loss: 3.6801373958587646. Accuracy: 18.33\n",
            "Epoch:  1133\n",
            "Training: Iteration: 886500. Loss: 3.321164131164551. Accuracy: 25.812\n",
            "Testing: Iteration: 886500. Loss: 3.321164131164551. Accuracy: 18.32\n",
            "Epoch:  1134\n",
            "Training: Iteration: 887000. Loss: 3.196840763092041. Accuracy: 25.852\n",
            "Testing: Iteration: 887000. Loss: 3.196840763092041. Accuracy: 18.27\n",
            "Training: Iteration: 887500. Loss: 3.1337602138519287. Accuracy: 25.854\n",
            "Testing: Iteration: 887500. Loss: 3.1337602138519287. Accuracy: 18.3\n",
            "Epoch:  1135\n",
            "Training: Iteration: 888000. Loss: 3.187925100326538. Accuracy: 25.896\n",
            "Testing: Iteration: 888000. Loss: 3.187925100326538. Accuracy: 18.34\n",
            "Epoch:  1136\n",
            "Training: Iteration: 888500. Loss: 3.1983745098114014. Accuracy: 25.852\n",
            "Testing: Iteration: 888500. Loss: 3.1983745098114014. Accuracy: 18.3\n",
            "Training: Iteration: 889000. Loss: 3.090891122817993. Accuracy: 25.814\n",
            "Testing: Iteration: 889000. Loss: 3.090891122817993. Accuracy: 18.36\n",
            "Epoch:  1137\n",
            "Training: Iteration: 889500. Loss: 3.2801966667175293. Accuracy: 25.858\n",
            "Testing: Iteration: 889500. Loss: 3.2801966667175293. Accuracy: 18.22\n",
            "Epoch:  1138\n",
            "Training: Iteration: 890000. Loss: 3.199094295501709. Accuracy: 25.9\n",
            "Testing: Iteration: 890000. Loss: 3.199094295501709. Accuracy: 18.24\n",
            "Training: Iteration: 890500. Loss: 3.322319507598877. Accuracy: 25.812\n",
            "Testing: Iteration: 890500. Loss: 3.322319507598877. Accuracy: 18.3\n",
            "Epoch:  1139\n",
            "Training: Iteration: 891000. Loss: 2.900895833969116. Accuracy: 25.804\n",
            "Testing: Iteration: 891000. Loss: 2.900895833969116. Accuracy: 18.25\n",
            "Epoch:  1140\n",
            "Training: Iteration: 891500. Loss: 3.1659605503082275. Accuracy: 25.868\n",
            "Testing: Iteration: 891500. Loss: 3.1659605503082275. Accuracy: 18.31\n",
            "Training: Iteration: 892000. Loss: 3.1646368503570557. Accuracy: 25.798\n",
            "Testing: Iteration: 892000. Loss: 3.1646368503570557. Accuracy: 18.26\n",
            "Epoch:  1141\n",
            "Training: Iteration: 892500. Loss: 3.10434627532959. Accuracy: 25.854\n",
            "Testing: Iteration: 892500. Loss: 3.10434627532959. Accuracy: 18.23\n",
            "Training: Iteration: 893000. Loss: 3.7963178157806396. Accuracy: 25.834\n",
            "Testing: Iteration: 893000. Loss: 3.7963178157806396. Accuracy: 18.33\n",
            "Epoch:  1142\n",
            "Training: Iteration: 893500. Loss: 3.0163588523864746. Accuracy: 25.866\n",
            "Testing: Iteration: 893500. Loss: 3.0163588523864746. Accuracy: 18.35\n",
            "Epoch:  1143\n",
            "Training: Iteration: 894000. Loss: 2.903088331222534. Accuracy: 25.84\n",
            "Testing: Iteration: 894000. Loss: 2.903088331222534. Accuracy: 18.27\n",
            "Training: Iteration: 894500. Loss: 3.1691079139709473. Accuracy: 25.842\n",
            "Testing: Iteration: 894500. Loss: 3.1691079139709473. Accuracy: 18.36\n",
            "Epoch:  1144\n",
            "Training: Iteration: 895000. Loss: 3.4914627075195312. Accuracy: 25.868\n",
            "Testing: Iteration: 895000. Loss: 3.4914627075195312. Accuracy: 18.21\n",
            "Epoch:  1145\n",
            "Training: Iteration: 895500. Loss: 3.0664572715759277. Accuracy: 25.878\n",
            "Testing: Iteration: 895500. Loss: 3.0664572715759277. Accuracy: 18.29\n",
            "Training: Iteration: 896000. Loss: 3.110316038131714. Accuracy: 25.84\n",
            "Testing: Iteration: 896000. Loss: 3.110316038131714. Accuracy: 18.24\n",
            "Epoch:  1146\n",
            "Training: Iteration: 896500. Loss: 2.8532586097717285. Accuracy: 25.808\n",
            "Testing: Iteration: 896500. Loss: 2.8532586097717285. Accuracy: 18.23\n",
            "Epoch:  1147\n",
            "Training: Iteration: 897000. Loss: 3.38666033744812. Accuracy: 25.878\n",
            "Testing: Iteration: 897000. Loss: 3.38666033744812. Accuracy: 18.22\n",
            "Training: Iteration: 897500. Loss: 3.4928975105285645. Accuracy: 25.814\n",
            "Testing: Iteration: 897500. Loss: 3.4928975105285645. Accuracy: 18.26\n",
            "Epoch:  1148\n",
            "Training: Iteration: 898000. Loss: 2.972069263458252. Accuracy: 25.872\n",
            "Testing: Iteration: 898000. Loss: 2.972069263458252. Accuracy: 18.31\n",
            "Training: Iteration: 898500. Loss: 3.294290065765381. Accuracy: 25.848\n",
            "Testing: Iteration: 898500. Loss: 3.294290065765381. Accuracy: 18.27\n",
            "Epoch:  1149\n",
            "Training: Iteration: 899000. Loss: 2.9097602367401123. Accuracy: 25.788\n",
            "Testing: Iteration: 899000. Loss: 2.9097602367401123. Accuracy: 18.31\n",
            "Epoch:  1150\n",
            "Training: Iteration: 899500. Loss: 3.3304667472839355. Accuracy: 25.876\n",
            "Testing: Iteration: 899500. Loss: 3.3304667472839355. Accuracy: 18.27\n",
            "Training: Iteration: 900000. Loss: 3.518345594406128. Accuracy: 25.84\n",
            "Testing: Iteration: 900000. Loss: 3.518345594406128. Accuracy: 18.3\n",
            "Epoch:  1151\n",
            "Training: Iteration: 900500. Loss: 3.4155242443084717. Accuracy: 25.906\n",
            "Testing: Iteration: 900500. Loss: 3.4155242443084717. Accuracy: 18.25\n",
            "Epoch:  1152\n",
            "Training: Iteration: 901000. Loss: 3.274465799331665. Accuracy: 25.87\n",
            "Testing: Iteration: 901000. Loss: 3.274465799331665. Accuracy: 18.24\n",
            "Training: Iteration: 901500. Loss: 2.860675811767578. Accuracy: 25.81\n",
            "Testing: Iteration: 901500. Loss: 2.860675811767578. Accuracy: 18.27\n",
            "Epoch:  1153\n",
            "Training: Iteration: 902000. Loss: 3.26479434967041. Accuracy: 25.804\n",
            "Testing: Iteration: 902000. Loss: 3.26479434967041. Accuracy: 18.23\n",
            "Epoch:  1154\n",
            "Training: Iteration: 902500. Loss: 3.156809091567993. Accuracy: 25.918\n",
            "Testing: Iteration: 902500. Loss: 3.156809091567993. Accuracy: 18.23\n",
            "Training: Iteration: 903000. Loss: 3.2394676208496094. Accuracy: 25.814\n",
            "Testing: Iteration: 903000. Loss: 3.2394676208496094. Accuracy: 18.26\n",
            "Epoch:  1155\n",
            "Training: Iteration: 903500. Loss: 3.4194438457489014. Accuracy: 25.842\n",
            "Testing: Iteration: 903500. Loss: 3.4194438457489014. Accuracy: 18.24\n",
            "Epoch:  1156\n",
            "Training: Iteration: 904000. Loss: 3.000377655029297. Accuracy: 25.882\n",
            "Testing: Iteration: 904000. Loss: 3.000377655029297. Accuracy: 18.28\n",
            "Training: Iteration: 904500. Loss: 3.3504836559295654. Accuracy: 25.812\n",
            "Testing: Iteration: 904500. Loss: 3.3504836559295654. Accuracy: 18.27\n",
            "Epoch:  1157\n",
            "Training: Iteration: 905000. Loss: 3.370300531387329. Accuracy: 25.856\n",
            "Testing: Iteration: 905000. Loss: 3.370300531387329. Accuracy: 18.24\n",
            "Training: Iteration: 905500. Loss: 3.1983015537261963. Accuracy: 25.856\n",
            "Testing: Iteration: 905500. Loss: 3.1983015537261963. Accuracy: 18.33\n",
            "Epoch:  1158\n",
            "Training: Iteration: 906000. Loss: 3.3270480632781982. Accuracy: 25.89\n",
            "Testing: Iteration: 906000. Loss: 3.3270480632781982. Accuracy: 18.33\n",
            "Epoch:  1159\n",
            "Training: Iteration: 906500. Loss: 2.955854892730713. Accuracy: 25.858\n",
            "Testing: Iteration: 906500. Loss: 2.955854892730713. Accuracy: 18.26\n",
            "Training: Iteration: 907000. Loss: 3.2479746341705322. Accuracy: 25.836\n",
            "Testing: Iteration: 907000. Loss: 3.2479746341705322. Accuracy: 18.29\n",
            "Epoch:  1160\n",
            "Training: Iteration: 907500. Loss: 3.143869161605835. Accuracy: 25.848\n",
            "Testing: Iteration: 907500. Loss: 3.143869161605835. Accuracy: 18.24\n",
            "Epoch:  1161\n",
            "Training: Iteration: 908000. Loss: 3.5294454097747803. Accuracy: 25.892\n",
            "Testing: Iteration: 908000. Loss: 3.5294454097747803. Accuracy: 18.3\n",
            "Training: Iteration: 908500. Loss: 3.0174100399017334. Accuracy: 25.828\n",
            "Testing: Iteration: 908500. Loss: 3.0174100399017334. Accuracy: 18.2\n",
            "Epoch:  1162\n",
            "Training: Iteration: 909000. Loss: 3.7211666107177734. Accuracy: 25.814\n",
            "Testing: Iteration: 909000. Loss: 3.7211666107177734. Accuracy: 18.27\n",
            "Epoch:  1163\n",
            "Training: Iteration: 909500. Loss: 3.0680980682373047. Accuracy: 25.87\n",
            "Testing: Iteration: 909500. Loss: 3.0680980682373047. Accuracy: 18.19\n",
            "Training: Iteration: 910000. Loss: 3.0145435333251953. Accuracy: 25.794\n",
            "Testing: Iteration: 910000. Loss: 3.0145435333251953. Accuracy: 18.33\n",
            "Epoch:  1164\n",
            "Training: Iteration: 910500. Loss: 3.633106231689453. Accuracy: 25.896\n",
            "Testing: Iteration: 910500. Loss: 3.633106231689453. Accuracy: 18.25\n",
            "Training: Iteration: 911000. Loss: 3.498485565185547. Accuracy: 25.882\n",
            "Testing: Iteration: 911000. Loss: 3.498485565185547. Accuracy: 18.29\n",
            "Epoch:  1165\n",
            "Training: Iteration: 911500. Loss: 3.1617841720581055. Accuracy: 25.862\n",
            "Testing: Iteration: 911500. Loss: 3.1617841720581055. Accuracy: 18.32\n",
            "Epoch:  1166\n",
            "Training: Iteration: 912000. Loss: 3.5081422328948975. Accuracy: 25.882\n",
            "Testing: Iteration: 912000. Loss: 3.5081422328948975. Accuracy: 18.27\n",
            "Training: Iteration: 912500. Loss: 2.9925906658172607. Accuracy: 25.866\n",
            "Testing: Iteration: 912500. Loss: 2.9925906658172607. Accuracy: 18.3\n",
            "Epoch:  1167\n",
            "Training: Iteration: 913000. Loss: 3.819636344909668. Accuracy: 25.898\n",
            "Testing: Iteration: 913000. Loss: 3.819636344909668. Accuracy: 18.19\n",
            "Epoch:  1168\n",
            "Training: Iteration: 913500. Loss: 3.1785359382629395. Accuracy: 25.894\n",
            "Testing: Iteration: 913500. Loss: 3.1785359382629395. Accuracy: 18.21\n",
            "Training: Iteration: 914000. Loss: 2.9563941955566406. Accuracy: 25.822\n",
            "Testing: Iteration: 914000. Loss: 2.9563941955566406. Accuracy: 18.3\n",
            "Epoch:  1169\n",
            "Training: Iteration: 914500. Loss: 3.5062131881713867. Accuracy: 25.822\n",
            "Testing: Iteration: 914500. Loss: 3.5062131881713867. Accuracy: 18.19\n",
            "Epoch:  1170\n",
            "Training: Iteration: 915000. Loss: 3.0119683742523193. Accuracy: 25.886\n",
            "Testing: Iteration: 915000. Loss: 3.0119683742523193. Accuracy: 18.16\n",
            "Training: Iteration: 915500. Loss: 3.221461057662964. Accuracy: 25.834\n",
            "Testing: Iteration: 915500. Loss: 3.221461057662964. Accuracy: 18.22\n",
            "Epoch:  1171\n",
            "Training: Iteration: 916000. Loss: 3.393871784210205. Accuracy: 25.848\n",
            "Testing: Iteration: 916000. Loss: 3.393871784210205. Accuracy: 18.2\n",
            "Training: Iteration: 916500. Loss: 3.283221960067749. Accuracy: 25.876\n",
            "Testing: Iteration: 916500. Loss: 3.283221960067749. Accuracy: 18.27\n",
            "Epoch:  1172\n",
            "Training: Iteration: 917000. Loss: 3.403655529022217. Accuracy: 25.836\n",
            "Testing: Iteration: 917000. Loss: 3.403655529022217. Accuracy: 18.26\n",
            "Epoch:  1173\n",
            "Training: Iteration: 917500. Loss: 3.5074286460876465. Accuracy: 25.878\n",
            "Testing: Iteration: 917500. Loss: 3.5074286460876465. Accuracy: 18.25\n",
            "Training: Iteration: 918000. Loss: 3.2655251026153564. Accuracy: 25.884\n",
            "Testing: Iteration: 918000. Loss: 3.2655251026153564. Accuracy: 18.29\n",
            "Epoch:  1174\n",
            "Training: Iteration: 918500. Loss: 3.6961374282836914. Accuracy: 25.886\n",
            "Testing: Iteration: 918500. Loss: 3.6961374282836914. Accuracy: 18.32\n",
            "Epoch:  1175\n",
            "Training: Iteration: 919000. Loss: 3.3828423023223877. Accuracy: 25.898\n",
            "Testing: Iteration: 919000. Loss: 3.3828423023223877. Accuracy: 18.25\n",
            "Training: Iteration: 919500. Loss: 3.237355947494507. Accuracy: 25.838\n",
            "Testing: Iteration: 919500. Loss: 3.237355947494507. Accuracy: 18.27\n",
            "Epoch:  1176\n",
            "Training: Iteration: 920000. Loss: 3.253931760787964. Accuracy: 25.876\n",
            "Testing: Iteration: 920000. Loss: 3.253931760787964. Accuracy: 18.18\n",
            "Epoch:  1177\n",
            "Training: Iteration: 920500. Loss: 3.3374104499816895. Accuracy: 25.926\n",
            "Testing: Iteration: 920500. Loss: 3.3374104499816895. Accuracy: 18.25\n",
            "Training: Iteration: 921000. Loss: 3.116488456726074. Accuracy: 25.834\n",
            "Testing: Iteration: 921000. Loss: 3.116488456726074. Accuracy: 18.26\n",
            "Epoch:  1178\n",
            "Training: Iteration: 921500. Loss: 3.587348461151123. Accuracy: 25.826\n",
            "Testing: Iteration: 921500. Loss: 3.587348461151123. Accuracy: 18.24\n",
            "Epoch:  1179\n",
            "Training: Iteration: 922000. Loss: 3.4445881843566895. Accuracy: 25.872\n",
            "Testing: Iteration: 922000. Loss: 3.4445881843566895. Accuracy: 18.29\n",
            "Training: Iteration: 922500. Loss: 3.023480176925659. Accuracy: 25.842\n",
            "Testing: Iteration: 922500. Loss: 3.023480176925659. Accuracy: 18.22\n",
            "Epoch:  1180\n",
            "Training: Iteration: 923000. Loss: 3.1317620277404785. Accuracy: 25.89\n",
            "Testing: Iteration: 923000. Loss: 3.1317620277404785. Accuracy: 18.22\n",
            "Training: Iteration: 923500. Loss: 3.2112903594970703. Accuracy: 25.852\n",
            "Testing: Iteration: 923500. Loss: 3.2112903594970703. Accuracy: 18.26\n",
            "Epoch:  1181\n",
            "Training: Iteration: 924000. Loss: 3.0557150840759277. Accuracy: 25.86\n",
            "Testing: Iteration: 924000. Loss: 3.0557150840759277. Accuracy: 18.31\n",
            "Epoch:  1182\n",
            "Training: Iteration: 924500. Loss: 3.1958043575286865. Accuracy: 25.892\n",
            "Testing: Iteration: 924500. Loss: 3.1958043575286865. Accuracy: 18.28\n",
            "Training: Iteration: 925000. Loss: 3.1927547454833984. Accuracy: 25.85\n",
            "Testing: Iteration: 925000. Loss: 3.1927547454833984. Accuracy: 18.31\n",
            "Epoch:  1183\n",
            "Training: Iteration: 925500. Loss: 3.2530407905578613. Accuracy: 25.878\n",
            "Testing: Iteration: 925500. Loss: 3.2530407905578613. Accuracy: 18.19\n",
            "Epoch:  1184\n",
            "Training: Iteration: 926000. Loss: 2.971228837966919. Accuracy: 25.898\n",
            "Testing: Iteration: 926000. Loss: 2.971228837966919. Accuracy: 18.28\n",
            "Training: Iteration: 926500. Loss: 3.2266526222229004. Accuracy: 25.866\n",
            "Testing: Iteration: 926500. Loss: 3.2266526222229004. Accuracy: 18.29\n",
            "Epoch:  1185\n",
            "Training: Iteration: 927000. Loss: 2.970308542251587. Accuracy: 25.836\n",
            "Testing: Iteration: 927000. Loss: 2.970308542251587. Accuracy: 18.21\n",
            "Epoch:  1186\n",
            "Training: Iteration: 927500. Loss: 3.4014909267425537. Accuracy: 25.908\n",
            "Testing: Iteration: 927500. Loss: 3.4014909267425537. Accuracy: 18.18\n",
            "Training: Iteration: 928000. Loss: 3.442682981491089. Accuracy: 25.826\n",
            "Testing: Iteration: 928000. Loss: 3.442682981491089. Accuracy: 18.25\n",
            "Epoch:  1187\n",
            "Training: Iteration: 928500. Loss: 3.432194471359253. Accuracy: 25.87\n",
            "Testing: Iteration: 928500. Loss: 3.432194471359253. Accuracy: 18.28\n",
            "Training: Iteration: 929000. Loss: 3.3469810485839844. Accuracy: 25.892\n",
            "Testing: Iteration: 929000. Loss: 3.3469810485839844. Accuracy: 18.27\n",
            "Epoch:  1188\n",
            "Training: Iteration: 929500. Loss: 3.607839584350586. Accuracy: 25.818\n",
            "Testing: Iteration: 929500. Loss: 3.607839584350586. Accuracy: 18.26\n",
            "Epoch:  1189\n",
            "Training: Iteration: 930000. Loss: 3.3128252029418945. Accuracy: 25.892\n",
            "Testing: Iteration: 930000. Loss: 3.3128252029418945. Accuracy: 18.25\n",
            "Training: Iteration: 930500. Loss: 3.255154848098755. Accuracy: 25.868\n",
            "Testing: Iteration: 930500. Loss: 3.255154848098755. Accuracy: 18.24\n",
            "Epoch:  1190\n",
            "Training: Iteration: 931000. Loss: 3.0226738452911377. Accuracy: 25.92\n",
            "Testing: Iteration: 931000. Loss: 3.0226738452911377. Accuracy: 18.18\n",
            "Epoch:  1191\n",
            "Training: Iteration: 931500. Loss: 3.107496976852417. Accuracy: 25.878\n",
            "Testing: Iteration: 931500. Loss: 3.107496976852417. Accuracy: 18.19\n",
            "Training: Iteration: 932000. Loss: 3.3331828117370605. Accuracy: 25.836\n",
            "Testing: Iteration: 932000. Loss: 3.3331828117370605. Accuracy: 18.21\n",
            "Epoch:  1192\n",
            "Training: Iteration: 932500. Loss: 2.7309253215789795. Accuracy: 25.808\n",
            "Testing: Iteration: 932500. Loss: 2.7309253215789795. Accuracy: 18.2\n",
            "Epoch:  1193\n",
            "Training: Iteration: 933000. Loss: 3.3336219787597656. Accuracy: 25.918\n",
            "Testing: Iteration: 933000. Loss: 3.3336219787597656. Accuracy: 18.21\n",
            "Training: Iteration: 933500. Loss: 3.2974393367767334. Accuracy: 25.858\n",
            "Testing: Iteration: 933500. Loss: 3.2974393367767334. Accuracy: 18.24\n",
            "Epoch:  1194\n",
            "Training: Iteration: 934000. Loss: 3.157607316970825. Accuracy: 25.888\n",
            "Testing: Iteration: 934000. Loss: 3.157607316970825. Accuracy: 18.21\n",
            "Epoch:  1195\n",
            "Training: Iteration: 934500. Loss: 3.029890537261963. Accuracy: 25.898\n",
            "Testing: Iteration: 934500. Loss: 3.029890537261963. Accuracy: 18.24\n",
            "Training: Iteration: 935000. Loss: 3.3317208290100098. Accuracy: 25.836\n",
            "Testing: Iteration: 935000. Loss: 3.3317208290100098. Accuracy: 18.24\n",
            "Epoch:  1196\n",
            "Training: Iteration: 935500. Loss: 3.3529038429260254. Accuracy: 25.88\n",
            "Testing: Iteration: 935500. Loss: 3.3529038429260254. Accuracy: 18.25\n",
            "Training: Iteration: 936000. Loss: 3.205695867538452. Accuracy: 25.878\n",
            "Testing: Iteration: 936000. Loss: 3.205695867538452. Accuracy: 18.3\n",
            "Epoch:  1197\n",
            "Training: Iteration: 936500. Loss: 3.16660213470459. Accuracy: 25.928\n",
            "Testing: Iteration: 936500. Loss: 3.16660213470459. Accuracy: 18.34\n",
            "Epoch:  1198\n",
            "Training: Iteration: 937000. Loss: 3.2197422981262207. Accuracy: 25.88\n",
            "Testing: Iteration: 937000. Loss: 3.2197422981262207. Accuracy: 18.22\n",
            "Training: Iteration: 937500. Loss: 3.250889539718628. Accuracy: 25.842\n",
            "Testing: Iteration: 937500. Loss: 3.250889539718628. Accuracy: 18.29\n",
            "Epoch:  1199\n",
            "Training: Iteration: 938000. Loss: 3.191797971725464. Accuracy: 25.864\n",
            "Testing: Iteration: 938000. Loss: 3.191797971725464. Accuracy: 18.2\n",
            "Epoch:  1200\n",
            "Training: Iteration: 938500. Loss: 3.4697256088256836. Accuracy: 25.904\n",
            "Testing: Iteration: 938500. Loss: 3.4697256088256836. Accuracy: 18.27\n",
            "Training: Iteration: 939000. Loss: 3.0517776012420654. Accuracy: 25.862\n",
            "Testing: Iteration: 939000. Loss: 3.0517776012420654. Accuracy: 18.17\n",
            "Epoch:  1201\n",
            "Training: Iteration: 939500. Loss: 2.933277130126953. Accuracy: 25.856\n",
            "Testing: Iteration: 939500. Loss: 2.933277130126953. Accuracy: 18.24\n",
            "Epoch:  1202\n",
            "Training: Iteration: 940000. Loss: 3.405132532119751. Accuracy: 25.876\n",
            "Testing: Iteration: 940000. Loss: 3.405132532119751. Accuracy: 18.19\n",
            "Training: Iteration: 940500. Loss: 3.252999782562256. Accuracy: 25.806\n",
            "Testing: Iteration: 940500. Loss: 3.252999782562256. Accuracy: 18.27\n",
            "Epoch:  1203\n",
            "Training: Iteration: 941000. Loss: 3.2053067684173584. Accuracy: 25.892\n",
            "Testing: Iteration: 941000. Loss: 3.2053067684173584. Accuracy: 18.28\n",
            "Training: Iteration: 941500. Loss: 2.8667776584625244. Accuracy: 25.87\n",
            "Testing: Iteration: 941500. Loss: 2.8667776584625244. Accuracy: 18.25\n",
            "Epoch:  1204\n",
            "Training: Iteration: 942000. Loss: 3.2327141761779785. Accuracy: 25.89\n",
            "Testing: Iteration: 942000. Loss: 3.2327141761779785. Accuracy: 18.21\n",
            "Epoch:  1205\n",
            "Training: Iteration: 942500. Loss: 3.2862589359283447. Accuracy: 25.874\n",
            "Testing: Iteration: 942500. Loss: 3.2862589359283447. Accuracy: 18.26\n",
            "Training: Iteration: 943000. Loss: 3.6836113929748535. Accuracy: 25.858\n",
            "Testing: Iteration: 943000. Loss: 3.6836113929748535. Accuracy: 18.29\n",
            "Epoch:  1206\n",
            "Training: Iteration: 943500. Loss: 3.28723406791687. Accuracy: 25.902\n",
            "Testing: Iteration: 943500. Loss: 3.28723406791687. Accuracy: 18.23\n",
            "Epoch:  1207\n",
            "Training: Iteration: 944000. Loss: 3.0421345233917236. Accuracy: 25.922\n",
            "Testing: Iteration: 944000. Loss: 3.0421345233917236. Accuracy: 18.22\n",
            "Training: Iteration: 944500. Loss: 3.3196232318878174. Accuracy: 25.872\n",
            "Testing: Iteration: 944500. Loss: 3.3196232318878174. Accuracy: 18.27\n",
            "Epoch:  1208\n",
            "Training: Iteration: 945000. Loss: 3.263418674468994. Accuracy: 25.846\n",
            "Testing: Iteration: 945000. Loss: 3.263418674468994. Accuracy: 18.22\n",
            "Epoch:  1209\n",
            "Training: Iteration: 945500. Loss: 3.5500681400299072. Accuracy: 25.894\n",
            "Testing: Iteration: 945500. Loss: 3.5500681400299072. Accuracy: 18.18\n",
            "Training: Iteration: 946000. Loss: 3.2044320106506348. Accuracy: 25.854\n",
            "Testing: Iteration: 946000. Loss: 3.2044320106506348. Accuracy: 18.16\n",
            "Epoch:  1210\n",
            "Training: Iteration: 946500. Loss: 2.916118860244751. Accuracy: 25.876\n",
            "Testing: Iteration: 946500. Loss: 2.916118860244751. Accuracy: 18.23\n",
            "Training: Iteration: 947000. Loss: 3.1339669227600098. Accuracy: 25.912\n",
            "Testing: Iteration: 947000. Loss: 3.1339669227600098. Accuracy: 18.23\n",
            "Epoch:  1211\n",
            "Training: Iteration: 947500. Loss: 3.258758783340454. Accuracy: 25.854\n",
            "Testing: Iteration: 947500. Loss: 3.258758783340454. Accuracy: 18.19\n",
            "Epoch:  1212\n",
            "Training: Iteration: 948000. Loss: 3.1924612522125244. Accuracy: 25.884\n",
            "Testing: Iteration: 948000. Loss: 3.1924612522125244. Accuracy: 18.24\n",
            "Training: Iteration: 948500. Loss: 2.987513542175293. Accuracy: 25.902\n",
            "Testing: Iteration: 948500. Loss: 2.987513542175293. Accuracy: 18.26\n",
            "Epoch:  1213\n",
            "Training: Iteration: 949000. Loss: 3.370079517364502. Accuracy: 25.904\n",
            "Testing: Iteration: 949000. Loss: 3.370079517364502. Accuracy: 18.29\n",
            "Epoch:  1214\n",
            "Training: Iteration: 949500. Loss: 2.9230668544769287. Accuracy: 25.902\n",
            "Testing: Iteration: 949500. Loss: 2.9230668544769287. Accuracy: 18.22\n",
            "Training: Iteration: 950000. Loss: 3.4177393913269043. Accuracy: 25.834\n",
            "Testing: Iteration: 950000. Loss: 3.4177393913269043. Accuracy: 18.21\n",
            "Epoch:  1215\n",
            "Training: Iteration: 950500. Loss: 3.094893217086792. Accuracy: 25.866\n",
            "Testing: Iteration: 950500. Loss: 3.094893217086792. Accuracy: 18.21\n",
            "Epoch:  1216\n",
            "Training: Iteration: 951000. Loss: 3.217736005783081. Accuracy: 25.896\n",
            "Testing: Iteration: 951000. Loss: 3.217736005783081. Accuracy: 18.22\n",
            "Training: Iteration: 951500. Loss: 2.928684711456299. Accuracy: 25.87\n",
            "Testing: Iteration: 951500. Loss: 2.928684711456299. Accuracy: 18.32\n",
            "Epoch:  1217\n",
            "Training: Iteration: 952000. Loss: 3.382692337036133. Accuracy: 25.862\n",
            "Testing: Iteration: 952000. Loss: 3.382692337036133. Accuracy: 18.22\n",
            "Epoch:  1218\n",
            "Training: Iteration: 952500. Loss: 2.935045003890991. Accuracy: 25.906\n",
            "Testing: Iteration: 952500. Loss: 2.935045003890991. Accuracy: 18.26\n",
            "Training: Iteration: 953000. Loss: 3.266782522201538. Accuracy: 25.846\n",
            "Testing: Iteration: 953000. Loss: 3.266782522201538. Accuracy: 18.19\n",
            "Epoch:  1219\n",
            "Training: Iteration: 953500. Loss: 3.020596504211426. Accuracy: 25.888\n",
            "Testing: Iteration: 953500. Loss: 3.020596504211426. Accuracy: 18.24\n",
            "Training: Iteration: 954000. Loss: 3.5945639610290527. Accuracy: 25.858\n",
            "Testing: Iteration: 954000. Loss: 3.5945639610290527. Accuracy: 18.25\n",
            "Epoch:  1220\n",
            "Training: Iteration: 954500. Loss: 3.3967761993408203. Accuracy: 25.886\n",
            "Testing: Iteration: 954500. Loss: 3.3967761993408203. Accuracy: 18.28\n",
            "Epoch:  1221\n",
            "Training: Iteration: 955000. Loss: 3.1572208404541016. Accuracy: 25.934\n",
            "Testing: Iteration: 955000. Loss: 3.1572208404541016. Accuracy: 18.24\n",
            "Training: Iteration: 955500. Loss: 3.4361813068389893. Accuracy: 25.83\n",
            "Testing: Iteration: 955500. Loss: 3.4361813068389893. Accuracy: 18.24\n",
            "Epoch:  1222\n",
            "Training: Iteration: 956000. Loss: 3.3454222679138184. Accuracy: 25.906\n",
            "Testing: Iteration: 956000. Loss: 3.3454222679138184. Accuracy: 18.21\n",
            "Epoch:  1223\n",
            "Training: Iteration: 956500. Loss: 3.111820936203003. Accuracy: 25.878\n",
            "Testing: Iteration: 956500. Loss: 3.111820936203003. Accuracy: 18.3\n",
            "Training: Iteration: 957000. Loss: 3.336630344390869. Accuracy: 25.872\n",
            "Testing: Iteration: 957000. Loss: 3.336630344390869. Accuracy: 18.26\n",
            "Epoch:  1224\n",
            "Training: Iteration: 957500. Loss: 3.151858329772949. Accuracy: 25.872\n",
            "Testing: Iteration: 957500. Loss: 3.151858329772949. Accuracy: 18.17\n",
            "Epoch:  1225\n",
            "Training: Iteration: 958000. Loss: 3.091188907623291. Accuracy: 25.928\n",
            "Testing: Iteration: 958000. Loss: 3.091188907623291. Accuracy: 18.12\n",
            "Training: Iteration: 958500. Loss: 3.2768349647521973. Accuracy: 25.826\n",
            "Testing: Iteration: 958500. Loss: 3.2768349647521973. Accuracy: 18.23\n",
            "Epoch:  1226\n",
            "Training: Iteration: 959000. Loss: 3.231545925140381. Accuracy: 25.884\n",
            "Testing: Iteration: 959000. Loss: 3.231545925140381. Accuracy: 18.21\n",
            "Training: Iteration: 959500. Loss: 3.263918399810791. Accuracy: 25.886\n",
            "Testing: Iteration: 959500. Loss: 3.263918399810791. Accuracy: 18.24\n",
            "Epoch:  1227\n",
            "Training: Iteration: 960000. Loss: 3.157884120941162. Accuracy: 25.844\n",
            "Testing: Iteration: 960000. Loss: 3.157884120941162. Accuracy: 18.16\n",
            "Epoch:  1228\n",
            "Training: Iteration: 960500. Loss: 3.56550931930542. Accuracy: 25.89\n",
            "Testing: Iteration: 960500. Loss: 3.56550931930542. Accuracy: 18.25\n",
            "Training: Iteration: 961000. Loss: 2.834169864654541. Accuracy: 25.894\n",
            "Testing: Iteration: 961000. Loss: 2.834169864654541. Accuracy: 18.26\n",
            "Epoch:  1229\n",
            "Training: Iteration: 961500. Loss: 3.2354559898376465. Accuracy: 25.92\n",
            "Testing: Iteration: 961500. Loss: 3.2354559898376465. Accuracy: 18.26\n",
            "Epoch:  1230\n",
            "Training: Iteration: 962000. Loss: 3.478977680206299. Accuracy: 25.904\n",
            "Testing: Iteration: 962000. Loss: 3.478977680206299. Accuracy: 18.18\n",
            "Training: Iteration: 962500. Loss: 3.2954325675964355. Accuracy: 25.856\n",
            "Testing: Iteration: 962500. Loss: 3.2954325675964355. Accuracy: 18.23\n",
            "Epoch:  1231\n",
            "Training: Iteration: 963000. Loss: 3.3228564262390137. Accuracy: 25.842\n",
            "Testing: Iteration: 963000. Loss: 3.3228564262390137. Accuracy: 18.18\n",
            "Epoch:  1232\n",
            "Training: Iteration: 963500. Loss: 3.311577081680298. Accuracy: 25.9\n",
            "Testing: Iteration: 963500. Loss: 3.311577081680298. Accuracy: 18.17\n",
            "Training: Iteration: 964000. Loss: 3.225137948989868. Accuracy: 25.85\n",
            "Testing: Iteration: 964000. Loss: 3.225137948989868. Accuracy: 18.23\n",
            "Epoch:  1233\n",
            "Training: Iteration: 964500. Loss: 3.3806045055389404. Accuracy: 25.882\n",
            "Testing: Iteration: 964500. Loss: 3.3806045055389404. Accuracy: 18.22\n",
            "Epoch:  1234\n",
            "Training: Iteration: 965000. Loss: 3.3024494647979736. Accuracy: 25.926\n",
            "Testing: Iteration: 965000. Loss: 3.3024494647979736. Accuracy: 18.27\n",
            "Training: Iteration: 965500. Loss: 3.6750500202178955. Accuracy: 25.842\n",
            "Testing: Iteration: 965500. Loss: 3.6750500202178955. Accuracy: 18.18\n",
            "Epoch:  1235\n",
            "Training: Iteration: 966000. Loss: 3.221693754196167. Accuracy: 25.858\n",
            "Testing: Iteration: 966000. Loss: 3.221693754196167. Accuracy: 18.22\n",
            "Training: Iteration: 966500. Loss: 3.2148597240448. Accuracy: 25.87\n",
            "Testing: Iteration: 966500. Loss: 3.2148597240448. Accuracy: 18.25\n",
            "Epoch:  1236\n",
            "Training: Iteration: 967000. Loss: 3.315979480743408. Accuracy: 25.95\n",
            "Testing: Iteration: 967000. Loss: 3.315979480743408. Accuracy: 18.27\n",
            "Epoch:  1237\n",
            "Training: Iteration: 967500. Loss: 2.9027228355407715. Accuracy: 25.926\n",
            "Testing: Iteration: 967500. Loss: 2.9027228355407715. Accuracy: 18.21\n",
            "Training: Iteration: 968000. Loss: 3.2665421962738037. Accuracy: 25.852\n",
            "Testing: Iteration: 968000. Loss: 3.2665421962738037. Accuracy: 18.25\n",
            "Epoch:  1238\n",
            "Training: Iteration: 968500. Loss: 3.2689285278320312. Accuracy: 25.896\n",
            "Testing: Iteration: 968500. Loss: 3.2689285278320312. Accuracy: 18.26\n",
            "Epoch:  1239\n",
            "Training: Iteration: 969000. Loss: 3.6452176570892334. Accuracy: 25.894\n",
            "Testing: Iteration: 969000. Loss: 3.6452176570892334. Accuracy: 18.3\n",
            "Training: Iteration: 969500. Loss: 3.291137218475342. Accuracy: 25.896\n",
            "Testing: Iteration: 969500. Loss: 3.291137218475342. Accuracy: 18.21\n",
            "Epoch:  1240\n",
            "Training: Iteration: 970000. Loss: 3.145887613296509. Accuracy: 25.87\n",
            "Testing: Iteration: 970000. Loss: 3.145887613296509. Accuracy: 18.2\n",
            "Epoch:  1241\n",
            "Training: Iteration: 970500. Loss: 3.176435708999634. Accuracy: 25.898\n",
            "Testing: Iteration: 970500. Loss: 3.176435708999634. Accuracy: 18.22\n",
            "Training: Iteration: 971000. Loss: 3.4117867946624756. Accuracy: 25.828\n",
            "Testing: Iteration: 971000. Loss: 3.4117867946624756. Accuracy: 18.21\n",
            "Epoch:  1242\n",
            "Training: Iteration: 971500. Loss: 2.934516429901123. Accuracy: 25.908\n",
            "Testing: Iteration: 971500. Loss: 2.934516429901123. Accuracy: 18.27\n",
            "Training: Iteration: 972000. Loss: 3.3110084533691406. Accuracy: 25.874\n",
            "Testing: Iteration: 972000. Loss: 3.3110084533691406. Accuracy: 18.24\n",
            "Epoch:  1243\n",
            "Training: Iteration: 972500. Loss: 3.1900107860565186. Accuracy: 25.906\n",
            "Testing: Iteration: 972500. Loss: 3.1900107860565186. Accuracy: 18.21\n",
            "Epoch:  1244\n",
            "Training: Iteration: 973000. Loss: 2.7609283924102783. Accuracy: 25.896\n",
            "Testing: Iteration: 973000. Loss: 2.7609283924102783. Accuracy: 18.23\n",
            "Training: Iteration: 973500. Loss: 3.3144848346710205. Accuracy: 25.896\n",
            "Testing: Iteration: 973500. Loss: 3.3144848346710205. Accuracy: 18.28\n",
            "Epoch:  1245\n",
            "Training: Iteration: 974000. Loss: 3.3316707611083984. Accuracy: 25.902\n",
            "Testing: Iteration: 974000. Loss: 3.3316707611083984. Accuracy: 18.26\n",
            "Epoch:  1246\n",
            "Training: Iteration: 974500. Loss: 3.464998245239258. Accuracy: 25.914\n",
            "Testing: Iteration: 974500. Loss: 3.464998245239258. Accuracy: 18.21\n",
            "Training: Iteration: 975000. Loss: 3.603945255279541. Accuracy: 25.864\n",
            "Testing: Iteration: 975000. Loss: 3.603945255279541. Accuracy: 18.2\n",
            "Epoch:  1247\n",
            "Training: Iteration: 975500. Loss: 3.114750385284424. Accuracy: 25.858\n",
            "Testing: Iteration: 975500. Loss: 3.114750385284424. Accuracy: 18.21\n",
            "Epoch:  1248\n",
            "Training: Iteration: 976000. Loss: 3.0390946865081787. Accuracy: 25.904\n",
            "Testing: Iteration: 976000. Loss: 3.0390946865081787. Accuracy: 18.18\n",
            "Training: Iteration: 976500. Loss: 3.2378644943237305. Accuracy: 25.87\n",
            "Testing: Iteration: 976500. Loss: 3.2378644943237305. Accuracy: 18.15\n",
            "Epoch:  1249\n",
            "Training: Iteration: 977000. Loss: 3.486496925354004. Accuracy: 25.872\n",
            "Testing: Iteration: 977000. Loss: 3.486496925354004. Accuracy: 18.17\n",
            "Training: Iteration: 977500. Loss: 2.9620847702026367. Accuracy: 25.9\n",
            "Testing: Iteration: 977500. Loss: 2.9620847702026367. Accuracy: 18.24\n",
            "Epoch:  1250\n",
            "Training: Iteration: 978000. Loss: 3.168292999267578. Accuracy: 25.888\n",
            "Testing: Iteration: 978000. Loss: 3.168292999267578. Accuracy: 18.18\n",
            "Epoch:  1251\n",
            "Training: Iteration: 978500. Loss: 2.9125168323516846. Accuracy: 25.882\n",
            "Testing: Iteration: 978500. Loss: 2.9125168323516846. Accuracy: 18.21\n",
            "Training: Iteration: 979000. Loss: 2.739895820617676. Accuracy: 25.904\n",
            "Testing: Iteration: 979000. Loss: 2.739895820617676. Accuracy: 18.28\n",
            "Epoch:  1252\n",
            "Training: Iteration: 979500. Loss: 3.2913687229156494. Accuracy: 25.912\n",
            "Testing: Iteration: 979500. Loss: 3.2913687229156494. Accuracy: 18.21\n",
            "Epoch:  1253\n",
            "Training: Iteration: 980000. Loss: 3.415522575378418. Accuracy: 25.922\n",
            "Testing: Iteration: 980000. Loss: 3.415522575378418. Accuracy: 18.17\n",
            "Training: Iteration: 980500. Loss: 3.0312864780426025. Accuracy: 25.862\n",
            "Testing: Iteration: 980500. Loss: 3.0312864780426025. Accuracy: 18.17\n",
            "Epoch:  1254\n",
            "Training: Iteration: 981000. Loss: 3.2218575477600098. Accuracy: 25.88\n",
            "Testing: Iteration: 981000. Loss: 3.2218575477600098. Accuracy: 18.21\n",
            "Epoch:  1255\n",
            "Training: Iteration: 981500. Loss: 3.0907516479492188. Accuracy: 25.896\n",
            "Testing: Iteration: 981500. Loss: 3.0907516479492188. Accuracy: 18.22\n",
            "Training: Iteration: 982000. Loss: 3.1045022010803223. Accuracy: 25.88\n",
            "Testing: Iteration: 982000. Loss: 3.1045022010803223. Accuracy: 18.28\n",
            "Epoch:  1256\n",
            "Training: Iteration: 982500. Loss: 3.531541109085083. Accuracy: 25.874\n",
            "Testing: Iteration: 982500. Loss: 3.531541109085083. Accuracy: 18.16\n",
            "Epoch:  1257\n",
            "Training: Iteration: 983000. Loss: 3.3137123584747314. Accuracy: 25.91\n",
            "Testing: Iteration: 983000. Loss: 3.3137123584747314. Accuracy: 18.21\n",
            "Training: Iteration: 983500. Loss: 3.526116371154785. Accuracy: 25.828\n",
            "Testing: Iteration: 983500. Loss: 3.526116371154785. Accuracy: 18.19\n",
            "Epoch:  1258\n",
            "Training: Iteration: 984000. Loss: 3.2794675827026367. Accuracy: 25.9\n",
            "Testing: Iteration: 984000. Loss: 3.2794675827026367. Accuracy: 18.21\n",
            "Training: Iteration: 984500. Loss: 3.1434895992279053. Accuracy: 25.852\n",
            "Testing: Iteration: 984500. Loss: 3.1434895992279053. Accuracy: 18.25\n",
            "Epoch:  1259\n",
            "Training: Iteration: 985000. Loss: 3.469513177871704. Accuracy: 25.94\n",
            "Testing: Iteration: 985000. Loss: 3.469513177871704. Accuracy: 18.24\n",
            "Epoch:  1260\n",
            "Training: Iteration: 985500. Loss: 3.126720666885376. Accuracy: 25.93\n",
            "Testing: Iteration: 985500. Loss: 3.126720666885376. Accuracy: 18.17\n",
            "Training: Iteration: 986000. Loss: 3.3616812229156494. Accuracy: 25.856\n",
            "Testing: Iteration: 986000. Loss: 3.3616812229156494. Accuracy: 18.2\n",
            "Epoch:  1261\n",
            "Training: Iteration: 986500. Loss: 3.2554376125335693. Accuracy: 25.924\n",
            "Testing: Iteration: 986500. Loss: 3.2554376125335693. Accuracy: 18.2\n",
            "Epoch:  1262\n",
            "Training: Iteration: 987000. Loss: 3.3263518810272217. Accuracy: 25.89\n",
            "Testing: Iteration: 987000. Loss: 3.3263518810272217. Accuracy: 18.24\n",
            "Training: Iteration: 987500. Loss: 3.081709861755371. Accuracy: 25.886\n",
            "Testing: Iteration: 987500. Loss: 3.081709861755371. Accuracy: 18.23\n",
            "Epoch:  1263\n",
            "Training: Iteration: 988000. Loss: 2.955650568008423. Accuracy: 25.868\n",
            "Testing: Iteration: 988000. Loss: 2.955650568008423. Accuracy: 18.14\n",
            "Epoch:  1264\n",
            "Training: Iteration: 988500. Loss: 2.937703847885132. Accuracy: 25.9\n",
            "Testing: Iteration: 988500. Loss: 2.937703847885132. Accuracy: 18.11\n",
            "Training: Iteration: 989000. Loss: 3.0768165588378906. Accuracy: 25.868\n",
            "Testing: Iteration: 989000. Loss: 3.0768165588378906. Accuracy: 18.18\n",
            "Epoch:  1265\n",
            "Training: Iteration: 989500. Loss: 3.2728872299194336. Accuracy: 25.89\n",
            "Testing: Iteration: 989500. Loss: 3.2728872299194336. Accuracy: 18.21\n",
            "Training: Iteration: 990000. Loss: 3.329343557357788. Accuracy: 25.862\n",
            "Testing: Iteration: 990000. Loss: 3.329343557357788. Accuracy: 18.25\n",
            "Epoch:  1266\n",
            "Training: Iteration: 990500. Loss: 3.312035083770752. Accuracy: 25.866\n",
            "Testing: Iteration: 990500. Loss: 3.312035083770752. Accuracy: 18.2\n",
            "Epoch:  1267\n",
            "Training: Iteration: 991000. Loss: 3.0009820461273193. Accuracy: 25.902\n",
            "Testing: Iteration: 991000. Loss: 3.0009820461273193. Accuracy: 18.2\n",
            "Training: Iteration: 991500. Loss: 3.4352240562438965. Accuracy: 25.926\n",
            "Testing: Iteration: 991500. Loss: 3.4352240562438965. Accuracy: 18.25\n",
            "Epoch:  1268\n",
            "Training: Iteration: 992000. Loss: 3.3225064277648926. Accuracy: 25.922\n",
            "Testing: Iteration: 992000. Loss: 3.3225064277648926. Accuracy: 18.24\n",
            "Epoch:  1269\n",
            "Training: Iteration: 992500. Loss: 3.045032501220703. Accuracy: 25.952\n",
            "Testing: Iteration: 992500. Loss: 3.045032501220703. Accuracy: 18.21\n",
            "Training: Iteration: 993000. Loss: 2.9346954822540283. Accuracy: 25.874\n",
            "Testing: Iteration: 993000. Loss: 2.9346954822540283. Accuracy: 18.17\n",
            "Epoch:  1270\n",
            "Training: Iteration: 993500. Loss: 2.801622152328491. Accuracy: 25.882\n",
            "Testing: Iteration: 993500. Loss: 2.801622152328491. Accuracy: 18.11\n",
            "Epoch:  1271\n",
            "Training: Iteration: 994000. Loss: 2.9895031452178955. Accuracy: 25.89\n",
            "Testing: Iteration: 994000. Loss: 2.9895031452178955. Accuracy: 18.14\n",
            "Training: Iteration: 994500. Loss: 3.324373483657837. Accuracy: 25.862\n",
            "Testing: Iteration: 994500. Loss: 3.324373483657837. Accuracy: 18.29\n",
            "Epoch:  1272\n",
            "Training: Iteration: 995000. Loss: 3.1500930786132812. Accuracy: 25.876\n",
            "Testing: Iteration: 995000. Loss: 3.1500930786132812. Accuracy: 18.18\n",
            "Epoch:  1273\n",
            "Training: Iteration: 995500. Loss: 3.097463846206665. Accuracy: 25.926\n",
            "Testing: Iteration: 995500. Loss: 3.097463846206665. Accuracy: 18.27\n",
            "Training: Iteration: 996000. Loss: 3.3208930492401123. Accuracy: 25.856\n",
            "Testing: Iteration: 996000. Loss: 3.3208930492401123. Accuracy: 18.15\n",
            "Epoch:  1274\n",
            "Training: Iteration: 996500. Loss: 3.0871357917785645. Accuracy: 25.882\n",
            "Testing: Iteration: 996500. Loss: 3.0871357917785645. Accuracy: 18.14\n",
            "Training: Iteration: 997000. Loss: 3.1976161003112793. Accuracy: 25.88\n",
            "Testing: Iteration: 997000. Loss: 3.1976161003112793. Accuracy: 18.27\n",
            "Epoch:  1275\n",
            "Training: Iteration: 997500. Loss: 2.803966999053955. Accuracy: 25.924\n",
            "Testing: Iteration: 997500. Loss: 2.803966999053955. Accuracy: 18.26\n",
            "Epoch:  1276\n",
            "Training: Iteration: 998000. Loss: 3.1463370323181152. Accuracy: 25.924\n",
            "Testing: Iteration: 998000. Loss: 3.1463370323181152. Accuracy: 18.16\n",
            "Training: Iteration: 998500. Loss: 3.534470558166504. Accuracy: 25.874\n",
            "Testing: Iteration: 998500. Loss: 3.534470558166504. Accuracy: 18.23\n",
            "Epoch:  1277\n",
            "Training: Iteration: 999000. Loss: 2.9219205379486084. Accuracy: 25.876\n",
            "Testing: Iteration: 999000. Loss: 2.9219205379486084. Accuracy: 18.22\n",
            "Epoch:  1278\n",
            "Training: Iteration: 999500. Loss: 3.3545196056365967. Accuracy: 25.898\n",
            "Testing: Iteration: 999500. Loss: 3.3545196056365967. Accuracy: 18.24\n",
            "Training: Iteration: 1000000. Loss: 3.294597625732422. Accuracy: 25.926\n",
            "Testing: Iteration: 1000000. Loss: 3.294597625732422. Accuracy: 18.2\n",
            "Epoch:  1279\n",
            "Training: Iteration: 1000500. Loss: 3.2608304023742676. Accuracy: 25.87\n",
            "Testing: Iteration: 1000500. Loss: 3.2608304023742676. Accuracy: 18.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIvsgNUesuPu"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHLFAUrvsuST"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXmF7kShsuUt"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsZmFyVzsuXO"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}